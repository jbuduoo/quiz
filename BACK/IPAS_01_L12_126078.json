{
  "metadata": {
    "testName": "IPAS_01",
    "subject": "L12",
    "series_no": "126078",
    "sourceFile": "114年_-_iPAS_AI應用規劃師初級能力(科目二)_51-100#126078-阿摩線上測驗.xlsx",
    "count": 50
  },
  "questions": [
    {
      "id": "IPAS_01_L12_126078_1",
      "content": "一家新聞機構希望利用 AI 來判斷新聞的真偽，應該使用哪種技術？",
      "A": "計算機視覺",
      "B": "自然語言處理",
      "C": "生成對抗網路 (GAN)",
      "D": "AI 聊天機器人",
      "Ans": "B",
      "exp": "判斷新聞真偽主要涉及對文本內容的理解、分析與分類，屬於自然語言處理 (NLP) 的範疇。計算機視覺主要處理圖像和影片，生成對抗網路 (GAN) 主要用於生成內容，AI 聊天機器人是應用而非核心技術。"
    },
    {
      "id": "IPAS_01_L12_126078_2",
      "content": "企業希望透過 AI 技術來進行語音詐騙辨識，應該使用哪種技術？",
      "A": "語音辨識",
      "B": "機器學習與語音辨識",
      "C": "3D 擴增 AI",
      "D": "遊戲 AI",
      "Ans": "B",
      "exp": "語音詐騙辨識不僅需要將語音轉換為文本（語音辨識），更需要使用機器學習技術來分析語音特徵、語言模式、語義等，以判斷其是否具有詐騙意圖或異常模式，因此結合**機器學習**和**語音辨識**才是完整的解決方案。"
    },
    {
      "id": "IPAS_01_L12_126078_3",
      "content": "企業希望建構 AI 聊天機器人來提升客服效率，應該使用哪種工具？",
      "A": "Power Virtual Agents",
      "B": "DataRobot",
      "C": "Midjourney",
      "D": "H2O.ai",
      "Ans": "A",
      "exp": "Microsoft **Power Virtual Agents** 是一個低程式碼/無程式碼的平台，專門用於快速建立和部署 AI 聊天機器人。DataRobot 和 H2O.ai 主要用於自動化機器學習 (AutoML)，Midjourney 則是用於 AI 繪圖。"
    },
    {
      "id": "IPAS_01_L12_126078_4",
      "content": "如果企業希望開發 AI 繪圖應用，應該選擇哪種工具？",
      "A": "Midjourney。 解析：...",
      "B": "Zapier",
      "C": "Shopify",
      "D": "Webflow",
      "Ans": "A",
      "exp": "**Midjourney** 是一款知名的文字轉圖片 (Text-to-Image) 生成式 AI 工具，專門用於 AI 繪圖應用。Zapier 是工作流程自動化工具，Shopify 是電商平台，Webflow 是網頁設計工具。"
    },
    {
      "id": "IPAS_01_L12_126078_5",
      "content": "Google DeepMind 的 GraphCast 主要應用在哪個領域？",
      "A": "氣象預測",
      "B": "財務報表生成",
      "C": "自動駕駛",
      "D": "音樂創作",
      "Ans": "A",
      "exp": "Google DeepMind 的 **GraphCast** 是一種基於圖形神經網路 (GNN) 的大型 AI 模型，專門用於**高精度、快速的全球氣象預測**，被認為在預測精度上超越了傳統方法。"
    },
    {
      "id": "IPAS_01_L12_126078_6",
      "content": "企業希望透過 AI 來自動生成影片，應該選擇哪種工具？",
      "A": "Stable Video Diffusion",
      "B": "Webflow",
      "C": "Power Virtual Agents",
      "D": "DataRobot",
      "Ans": "A",
      "exp": "**Stable Video Diffusion (SVD)** 是 Stability AI 推出的生成式模型，專門用於**文字轉影片 (Text-to-Video) 或圖片轉影片**的應用，屬於影片生成工具。其他選項則分別是用於網頁設計、聊天機器人和自動化機器學習。"
    },
    {
      "id": "IPAS_01_L12_126078_7",
      "content": "Microsoft Copilot 的主要目標是什麼？",
      "A": "取代所有員工",
      "B": "提升工作智慧、效率和創造力",
      "C": "用於娛樂應用",
      "D": "限制用戶對 AI 的使用",
      "Ans": "B",
      "exp": "Microsoft **Copilot** 的設計定位是作為一個 AI 助手，整合到 Microsoft 365 應用中，目的是幫助用戶**提升工作智慧、效率和創造力**，而不是取代員工。"
    },
    {
      "id": "IPAS_01_L12_126078_8",
      "content": "Copilot 與 Microsoft 必應 (Bing) 結合的優勢是？",
      "A": "提供上下文相關答案",
      "B": "限制搜索結果",
      "C": "只提供固定的回答",
      "D": "只適用於技術人員",
      "Ans": "A",
      "exp": "Copilot 結合 Bing 搜索引擎，可以從最新的網路資訊中獲取資料，並結合當前的對話或文件**提供上下文相關、即時且準確的答案**，克服了大型語言模型知識庫可能不是最新的限制。"
    },
    {
      "id": "IPAS_01_L12_126078_9",
      "content": "提示工程 (Prompt Engineering) 的主要作用是？",
      "A": "處理模糊問題",
      "B": "優化提示來提升 AI 輸出 品質",
      "C": "限制 AI 的創造力",
      "D": "讓 AI 自行學習無限制的內容",
      "Ans": "B",
      "exp": "**提示工程**是設計和優化提供給大型語言模型 (LLM) 的輸入（即提示/Prompt）的過程，目的在於**提升 AI 輸出的相關性、準確性與品質**。"
    },
    {
      "id": "IPAS_01_L12_126078_10",
      "content": "系統提示 (System Message) 在 AI 交互中的作用是？",
      "A": "限制 AI 只能回答特定問題",
      "B": "為 AI 提供上下文和回應風格",
      "C": "讓 AI 自行決定回答者如何提問",
      "D": "讓 AI 變得無法使用",
      "Ans": "B",
      "exp": "**系統提示** (或稱系統指令) 是在對話開始前給予 LLM 的指令，用於**定義 AI 的角色、個性、任務目標、限制條件以及期望的回應風格**，從而控制 AI 的行為。"
    },
    {
      "id": "IPAS_01_L12_126078_11",
      "content": "為何在提示中提供具體上下文資訊很重要？",
      "A": "避免 AI 產生錯誤答案",
      "B": "限制 AI 的回答選項",
      "C": "減少 AI 模型的回應速度",
      "D": "無需使用訓練數據",
      "Ans": "A",
      "exp": "在提示中提供**具體上下文資訊**，可以幫助 AI 模型**更準確地理解用戶意圖**，從而減少產生不相關、模糊或錯誤答案 (即幻覺/Hallucination) 的可能性。"
    },
    {
      "id": "IPAS_01_L12_126078_12",
      "content": "LLM (大型語言模型) 如何進行學習？",
      "A": "透過大量文本數據訓練",
      "B": "只能透過人工標註",
      "C": "只能依賴單一來源",
      "D": "無法進行學習",
      "Ans": "A",
      "exp": "大型語言模型 (LLM) 的基礎是**透過對網路、書籍等來源的數十億甚至數萬億個詞彙的**大量文本數據**進行自我監督或半監督訓練**，來學習語言的結構、語義和世界知識。"
    },
    {
      "id": "IPAS_01_L12_126078_13",
      "content": "Azure OpenAI 與 Azure AI 服務的主要區別是？",
      "A": "Azure OpenAI 主要用於複雜的制定化 AI 應用",
      "B": "Azure AI 服務無法用於翻譯",
      "C": "Azure AI 只能用於個人用途",
      "D": "兩者無任何區別",
      "Ans": "A",
      "exp": "**Azure OpenAI** 服務提供對 OpenAI 的強大模型 (如 GPT-4, GPT-3.5, DALL-E) 的存取權限，**主要用於構建複雜的生成式 AI 或聊天應用**。**Azure AI 服務** (Cognitive Services) 則提供一系列預建的 AI API，如翻譯、語音辨識、視覺辨識等，通常用於標準化的 AI 任務。因此，Azure OpenAI 更側重於複雜和制定化的應用。"
    },
    {
      "id": "IPAS_01_L12_126078_14",
      "content": "選擇機器學習模型時應考慮哪些因素？",
      "A": "訓練時間與資源需求",
      "B": "只考慮演算法名稱",
      "C": "忽略資料清理過程",
      "D": "選擇最便宜的模型",
      "Ans": "A",
      "exp": "在選擇機器學習模型時，除了準確度外，還必須考慮**實際部署的成本**，包括**模型的訓練時間、所需的運算資源 (CPU/GPU/記憶體) 和資料量**，以及模型預測的速度和效率。"
    },
    {
      "id": "IPAS_01_L12_126078_15",
      "content": "如何透過示例提升 AI 的回應準確性？",
      "A": "提供範例以進行一次性學習",
      "B": "限制 AI 只能回答固定問題",
      "C": "讓 AI 自行選擇回應範圍",
      "D": "讓 AI 依賴預設回答",
      "Ans": "A",
      "exp": "在大型語言模型中，透過**提供少數或一次性學習 (Few-shot or One-shot Learning) 的輸入和輸出的範例**，模型可以在不進行額外訓練的情況下，立即理解並模仿所需的任務格式和風格，從而**提升回應的準確性**。"
    },
    {
      "id": "IPAS_01_L12_126078_16",
      "content": "語言模型的主要功能是？",
      "A": "分析和生成自然語言",
      "B": "識別物體圖像",
      "C": "控制機器手臂",
      "D": "處理 DNA 序列",
      "Ans": "A",
      "exp": "語言模型 (Language Model) 專門用於處理和理解人類的語言，其核心功能是**分析輸入的自然語言文本並生成連貫、符合語義的自然語言輸出**。"
    },
    {
      "id": "IPAS_01_L12_126078_17",
      "content": "LLM (大型語言模型) 相較於一般語言模型的差異是什麼？",
      "A": "更小的數據集與參數",
      "B": "更強的語言理解和生成能力",
      "C": "只能處理結構化數據",
      "D": "只能翻譯語言",
      "Ans": "B",
      "exp": "**大型語言模型 (LLM)** 擁有**龐大的參數數量和訓練數據集**，這使其相較於一般語言模型，具備**更強大的語言理解、複雜推理和文本生成能力**，能夠執行更廣泛和更複雜的 NLP 任務。"
    },
    {
      "id": "IPAS_01_L12_126078_18",
      "content": "哪一種技術是語言模型發展的關鍵？",
      "A": "傳統規則式編程",
      "B": "神經網路與深度學習",
      "C": "機械工程",
      "D": "硬體晶片設計",
      "Ans": "B",
      "exp": "現代語言模型，特別是大型語言模型 (LLM)，其發展的基礎和關鍵技術是**神經網路 (Neural Networks)**，尤其是深度學習中的 **Transformer 架構**，這使得模型能夠處理和理解複雜的語言模式。"
    },
    {
      "id": "IPAS_01_L12_126078_19",
      "content": "LLM 可以應用於哪些自然語言處理 (NLP) 任務？",
      "A": "文字分類、摘要、文本比較、內容創作",
      "B": "設計電子電路",
      "C": "計算數學公式",
      "D": "分析基因序列",
      "Ans": "A",
      "exp": "大型語言模型 (LLM) 是自然語言處理 (NLP) 領域的核心，應用範圍極廣，包括**文本分類、自動摘要、情感分析、語言翻譯**以及**內容創作 (如寫作、編程)**等。"
    },
    {
      "id": "IPAS_01_L12_126078_20",
      "content": "語彙基元化 (Tokenization) 在 Transformer 訓練中的主要目的是什麼？",
      "A": "將文本拆分為最小單位，讓模型更好理解語言",
      "B": "讓模型只學習單字詞",
      "C": "讓模型只處理完整的句子",
      "D": "讓模型只處理單個字母",
      "Ans": "A",
      "exp": "**語彙基元化 (Tokenization)** 是將原始文本切割成模型可以處理的**最小有意義單位 (Token)** 的過程，這些單位可能是單詞、子詞或字元，目的是**將非結構化的語言轉換成模型能理解的數值表示**。"
    },
    {
      "id": "IPAS_01_L12_126078_21",
      "content": "Tokenization 如何幫助 Transformer 模型處理複雜語義？",
      "A": "透過將文本轉標記，讓模型更靈活處理語言",
      "B": "讓模型忽略淺層的語法結構",
      "C": "讓 Transformer 模型只能處理固定長度的文本",
      "D": "讓 Transformer 只能用於單一語言",
      "Ans": "A",
      "exp": "Tokenization (例如使用子詞切割) 能將罕見或複雜的詞彙分解成常見的子單位，**讓模型能透過組合這些標記來理解詞彙的語義**，從而提高模型處理**詞彙多樣性和複雜語義**的靈活性。"
    },
    {
      "id": "IPAS_01_L12_126078_22",
      "content": "語彙基元化 (Tokenization) 在 Transformer 訓練中的作用是什麼？",
      "A": "幫助模型理解語言結構和生成自然語言",
      "B": "讓模型無需學習詞性標註",
      "C": "使模型只能處理固定長度的文本",
      "D": "讓 Transformer 忽略標點符號",
      "Ans": "A",
      "exp": "Tokenization 將文本轉換為模型可以處理的數值序列，是模型理解語言結構的起點，並**允許模型學習不同單詞/標記之間的統計和語義關聯**，進而生成連貫的自然語言。"
    },
    {
      "id": "IPAS_01_L12_126078_23",
      "content": "語彙基元化 (Tokenization) 為何對自然語言處理 (NLP) 重要？",
      "A": "允許模型識別和處理不同 的詞語",
      "B": "只對英語有效",
      "C": "讓模型完全不需要訓練數據",
      "D": "只影響字母排序",
      "Ans": "A",
      "exp": "Tokenization 的核心重要性在於它將連續的文本流分割成離散的標記 (Token)，這些標記是模型訓練和學習的基礎，從而**讓模型能夠有效地識別、表示和處理語言中的不同詞語及其變體**。"
    },
    {
      "id": "IPAS_01_L12_126078_24",
      "content": "Transformer 模型的核心組件是什麼？",
      "A": "池化層與捲積層 (CNN)",
      "B": "循環神經網路 (RNN)",
      "C": "統計模型",
      "D": "編碼器與解碼器",
      "Ans": "D",
      "exp": "Transformer 架構的核心是其**編碼器 (Encoder) 和解碼器 (Decoder)**，兩者都包含多層的自注意力機制 (Self-Attention) 和前饋網路，用於處理輸入序列並生成輸出序列。A 和 B 是其他類型的神經網路組件。"
    },
    {
      "id": "IPAS_01_L12_126078_25",
      "content": "Transformer 模型如何理解輸入的文字？",
      "A": "透過手工標註",
      "B": "透過將文本拆分成標記， 並透過注意力機制判關聯性",
      "C": "依賴詞頻統計",
      "D": "逐字對照詞典",
      "Ans": "B",
      "exp": "Transformer 模型理解文字的過程：首先透過 **Tokenization** 將文字拆分成標記並轉換為**內嵌向量**；接著，利用**自注意力機制 (Self-Attention)** 來**計算這些標記在句子中的相互關聯性和重要性**，從而捕捉語義。"
    },
    {
      "id": "IPAS_01_L12_126078_26",
      "content": "在 Transformer 模型中，哪個部份負責學習單詞與句子之間的關聯？",
      "A": "池化層 (Pooling)",
      "B": "自注意力機制 (Self-Attention)",
      "C": "接續層 (Feed-Forward)",
      "D": "隱藏層 (Hidden Layer)",
      "Ans": "B",
      "exp": "在 Transformer 模型中，**自注意力機制 (Self-Attention)** 是核心，它能夠讓模型在處理序列中的一個詞時，**同時關注序列中的其他所有詞**，並計算它們之間的**關聯性或相對重要性**，從而捕捉長距離的依賴關係。"
    },
    {
      "id": "IPAS_01_L12_126078_27",
      "content": "Transformer 如何判斷句子中單詞的相對重要性？",
      "A": "只考慮詞語出現次數",
      "B": "透過注意力機制判斷詞語的關聯性",
      "C": "只考慮詞語詞性",
      "D": "隨機排列單詞",
      "Ans": "B",
      "exp": "Transformer 使用**注意力機制 (Attention Mechanism)**，特別是**自注意力機制 (Self-Attention)**，來**計算句子中每個單詞與其他所有單詞之間的關聯分數**。這個分數代表了單詞在形成當前語義時的相對重要性或影響力。"
    },
    {
      "id": "IPAS_01_L12_126078_28",
      "content": "Transformer 的編碼器 (Encoder) 主要負責什麼？",
      "A": "轉換輸入文本為語義表示",
      "B": "生成最終輸出",
      "C": "記憶數據庫內容",
      "D": "產生新的語言序列",
      "Ans": "A",
      "exp": "Transformer 的**編碼器 (Encoder)** 負責**接收輸入序列** (例如原始文本)，並透過多層的自注意力機制將其**轉換成豐富、高維度的語義表示 (Semantic Representation)**，以供解碼器使用。"
    },
    {
      "id": "IPAS_01_L12_126078_29",
      "content": "內嵌向量 (Embedding) 在自然語言處理 (NLP) 中的主要作用是什麼？",
      "A": "將詞彙轉換為向量，以捕捉語意關聯性",
      "B": "捕捉語意的順序",
      "C": "讓模型記憶每個單詞的拼寫",
      "D": "限制模型只能處理固定長度的文本",
      "Ans": "A",
      "exp": "**內嵌向量 (Embedding)** 的作用是將離散的詞彙或標記**轉換成低維度的連續數值向量**。在這種向量空間中，語義相近的詞彙在空間中的距離也較近，從而**捕捉到詞彙之間的語義和上下文關聯性**。"
    },
    {
      "id": "IPAS_01_L12_126078_30",
      "content": "內嵌向量如何幫助模型理解單詞之間的關聯性？",
      "A": "透過多維空間得向量表示",
      "B": "透過詞彙的字母順序",
      "C": "只考慮詞彙在字典中的定義",
      "D": "只考慮詞彙的長度",
      "Ans": "A",
      "exp": "內嵌向量將每個單詞表示為**多維空間中的一個點**。模型在訓練過程中，會調整這些向量，使得**在語義上相似或經常在相似上下文出現的詞彙，其向量在空間中的距離也更接近**，從而讓模型可以理解單詞之間的關聯性。"
    },
    {
      "id": "IPAS_01_L12_126078_31",
      "content": "內嵌向量在 NLP 任務中如何影響模型的性能？",
      "A": "提高模型理解和生成語言的準確性",
      "B": "影響模型的訓練速度",
      "C": "限制模型只能處理固定數量的詞彙",
      "D": "限制模型的上下文理解",
      "Ans": "A",
      "exp": "高品質的內嵌向量能夠**準確地捕捉詞彙的語義信息和上下文關係**，為後續的模型層提供良好的輸入表示，這對於**提高模型理解和生成語言的準確性**至關重要。"
    },
    {
      "id": "IPAS_01_L12_126078_32",
      "content": "內嵌向量 (Embedding) 的主要目的是？",
      "A": "將單詞轉換為數值向量，以捕捉語意關聯性",
      "B": "讓模型只學習母語的文字",
      "C": "使模型只能處理固定長度的文本",
      "D": "Transformer 忽略標點符號",
      "Ans": "A",
      "exp": "內嵌向量將非數值的詞彙**轉換為數值向量**，使其可以被深度學習模型處理，並在轉換的過程中**捕捉到詞彙的語義和上下文關聯性**。"
    },
    {
      "id": "IPAS_01_L12_126078_33",
      "content": "自注意力機制 (Self-Attention) 的作用是什麼？",
      "A": "評估序列中標記之間的關聯性",
      "B": "處理文本的固定部分",
      "C": "讓模型忽略單詞順序",
      "D": "使模型僅學習詞頻統計",
      "Ans": "A",
      "exp": "**自注意力機制**允許模型在處理序列中的某個標記時，**計算該標記與序列中所有其他標記的關聯程度 (權重)**，從而有效地**評估序列中不同標記之間的依賴關係和相對重要性**。"
    },
    {
      "id": "IPAS_01_L12_126078_34",
      "content": "位置編碼 (Positional Encoding) 在 Transformer 模型中的作用是？",
      "A": "提供序列中標記的順序資訊",
      "B": "限制模型只能處理固定長度的文本",
      "C": "記錄每個單字在文本中出現的次數",
      "D": "完全忽略上下文含義",
      "Ans": "A",
      "exp": "Transformer 模型中的自注意力機制本身是**不具備序列順序感知能力**的。因此，**位置編碼 (Positional Encoding)** 被加入到內嵌向量中，用來**注入標記在序列中的絕對和相對位置資訊**，確保模型能夠區分語義相同但順序不同的句子。"
    },
    {
      "id": "IPAS_01_L12_126078_35",
      "content": "Transformer 模型解碼器Decoder如何區確定生成的單詞？",
      "A": "利用注意力機制計算關鍵標記的影響力",
      "B": "只考慮詞頻統計",
      "C": "隨機選擇詞彙",
      "D": "忽略上下文,僅基於輸入單詞選擇",
      "Ans": "A",
      "exp": "Transformer 的解碼器 (Decoder) 在生成下一個單詞時，主要依賴**注意力機制** (包括自注意力與編碼器-解碼器注意力)，**計算輸入序列和已生成序列中各個關鍵標記 (Token) 對於當前生成步驟的影響力**，並根據這些影響力來預測最可能的下一個單詞。"
    },
    {
      "id": "IPAS_01_L12_126078_36",
      "content": "LLM 推動了 AI 助理的發展，這些助理的主要作用是什麼？",
      "A": "取代所有人類工作",
      "B": "提供任務輔助，提升效率和創意",
      "C": "只用於娛樂用途",
      "D": "使應用程序無需人類干預即可運行",
      "Ans": "B",
      "exp": "AI 助理 (如 Copilot、ChatGPT) 的核心作用是**作為人類的協作者 (Copilot)**，通過自動化重複性任務、提供即時資訊、協助撰寫文稿或程式碼等方式，來**提供任務輔助，從而顯著提升用戶的工作效率和創造力**。"
    },
    {
      "id": "IPAS_01_L12_126078_37",
      "content": "開發者如何利用 LLM 來構建 AI 助手？",
      "A": "只能使用開源模型，無法自訂",
      "B": "需要手動標註所有數據",
      "C": "可通過聊天室窗進行交互，並根據需求進行定制",
      "D": "只能使用固定的功能，無法修改",
      "Ans": "C",
      "exp": "開發者可以利用 Azure OpenAI 或其他 LLM 平台提供的 API，**通過聊天室窗或類似介面與模型進行交互**，並透過**系統提示、數據增強 (RAG) 或微調 (Fine-tuning)** 等方式，根據具體業務需求來**定制 AI 助理的功能和行為**。"
    },
    {
      "id": "IPAS_01_L12_126078_38",
      "content": "使用 Azure OpenAI 等服務的主要優勢是什麼？",
      "A": "可獲取預訓練模型，直接使用或進行微調",
      "B": "必須從零開始訓練所有 AI 模型",
      "C": "只能用於個人用途，無法商業化",
      "D": "需要購買昂貴的硬體設備來運行模型",
      "Ans": "A",
      "exp": "使用 Azure OpenAI 這類雲端服務的最大優勢是，它提供對**已完成大規模訓練的高性能模型**的存取權，用戶可以**直接將其部署於應用程序中，或進行微調**以適應特定任務，無需從零開始進行耗時且昂貴的基礎模型訓練。"
    },
    {
      "id": "IPAS_01_L12_126078_39",
      "content": "AI 助手如何影響商業用戶的工作方式？",
      "A": "讓員工無需參與決策",
      "B": "主要用於娛樂和遊戲產業",
      "C": "提高效率，幫助撰寫初 稿、資訊蒐集、策略規劃等",
      "D": "使所有人都可能創建自己的 AI 助手，無需學習技術",
      "Ans": "C",
      "exp": "AI 助手能大幅**提高商業用戶的生產力**，應用包括**自動生成文稿、郵件或報告的初稿**，**快速蒐集和總結大量資訊**，以及**協助進行數據分析和策略規劃**，讓員工能專注於更複雜的決策性工作。"
    },
    {
      "id": "IPAS_01_L12_126078_40",
      "content": "部署AI 助手後，開發者可以如何與其交互？",
      "A": "透過聊天室窗發送查詢,並獲取回應",
      "B": "只能透過 API 調用，無法直接進行語音或視覺輸入 並獲取回應",
      "C": "應用程序無需指令，無法主動提供建議",
      "D": "AI 助手只能依賴額外購買 專門的硬體設備來進行交互",
      "Ans": "A",
      "exp": "部署後的 AI 助手通常透過**使用者介面 (如聊天室窗)** 進行交互。用戶可以**發送文字、語音或視覺查詢**，而 AI 助手會即時**處理並提供文字、語音或其他形式的回應**。API 調用是後端機制，而非唯一的交互方式。"
    },
    {
      "id": "IPAS_01_L12_126078_41",
      "content": "生成式 AI 的核心能力是什麼？",
      "A": "僅能執行程式碼",
      "B": "只能進行數據分析",
      "C": "自主互動與內容生成",
      "D": "需要人工輸入大量數據才能運行",
      "Ans": "C",
      "exp": "**生成式 AI (Generative AI)** 的核心能力是**根據學習到的模式和提示，自主地創造和生成全新的內容**，包括文字、圖像、音頻、影片和程式碼等，並能與用戶進行**自然、多輪的互動**。"
    },
    {
      "id": "IPAS_01_L12_126078_42",
      "content": "生成式 AI 不適用於哪種應用場景？",
      "A": "內容生成",
      "B": "語音搜尋",
      "C": "影像辨識",
      "D": "程式碼生成",
      "Ans": "C",
      "exp": "生成式 AI (Generative AI) 主要用於**創造**內容 (A, D) 或基於語義理解的應用 (如語音搜尋的文本理解部分，B)。**影像辨識 (Image Recognition)** 屬於**區分式 AI (Discriminative AI)** 的範疇，其目標是**分類或識別**輸入數據的內容，而非生成新內容。"
    },
    {
      "id": "IPAS_01_L12_126078_43",
      "content": "下列哪一種 AI 模型可用於程式碼生成？",
      "A": "GPT Model",
      "B": "DALL-E",
      "C": "Codex Model",
      "D": "Stable Diffusion",
      "Ans": "C",
      "exp": "**Codex Model** (例如 GitHub Copilot 的基礎) 是 OpenAI 開發的一種大型語言模型，它經過了**大量程式碼數據的訓練**，因此非常擅長**理解自然語言指令並生成、解釋或完成程式碼**。GPT 模型和 DALL-E、Stable Diffusion 主要用於文本和圖像生成。"
    },
    {
      "id": "IPAS_01_L12_126078_44",
      "content": "生成式 AI 可透過何種技術進行語意搜尋？",
      "A": "DALL-E",
      "B": "Embedding Model 嵌入式模型",
      "C": "GAN",
      "D": "Adversarial Networks (對抗網路)",
      "Ans": "B",
      "exp": "**語意搜尋 (Semantic Search)** 依賴於將查詢和文件**轉換為內嵌向量 (Embedding)**。這些向量捕捉了它們的語義含義。通過計算向量之間的相似度 (例如餘弦相似度)，模型可以找到與查詢語義最相關的結果，即使它們不包含完全相同的關鍵詞。"
    },
    {
      "id": "IPAS_01_L12_126078_45",
      "content": "生成式 AI (如 ChatGPT) 能夠生成哪些內 容？",
      "A": "只能進行數據分析",
      "B": "只能執行命令，無法生成內容",
      "C": "詩歌與程式碼",
      "D": "只能分析圖片",
      "Ans": "C",
      "exp": "以 **ChatGPT** 為代表的生成式 AI 模型 (LLM) 具有強大的**文本生成能力**，能夠根據提示生成包括**詩歌、散文、故事、報告、電子郵件**，以及經過訓練的變體模型 (如 Codex) 也能生成**程式碼**。"
    },
    {
      "id": "IPAS_01_L12_126078_46",
      "content": "生成式 AI 的技術基礎是什麼？",
      "A": "純手工編碼",
      "B": "統計學、資料科學和機器學習",
      "C": "物理模型",
      "D": "傳統規則式設計",
      "Ans": "B",
      "exp": "生成式 AI 的技術基礎建立在**統計學、資料科學以及機器學習**（特別是**深度學習**）之上。這些模型通過在龐大數據集上學習底層的統計分布和模式來實現內容生成。"
    },
    {
      "id": "IPAS_01_L12_126078_47",
      "content": "ChatGPT 屬於哪一種 AI 技術？",
      "A": "強人工智慧",
      "B": "生成式 AI",
      "C": "視覺辨識 AI",
      "D": "嵌入式 AI",
      "Ans": "B",
      "exp": "**ChatGPT** 是基於 OpenAI 的 GPT (Generative Pre-trained Transformer) 系列模型，是一種典型的**生成式 AI (Generative AI)**，它能夠生成文本、進行對話和執行各種內容創作任務。"
    },
    {
      "id": "IPAS_01_L12_126078_48",
      "content": "生成式 AI 的工作原理主要基於哪些技術？",
      "A": "電腦視覺",
      "B": "硬體運算優化",
      "C": "自然語言處理與機器學習",
      "D": "傳統規則式編程",
      "Ans": "C",
      "exp": "無論是生成文本 (如 LLM) 還是圖像 (如 Diffusion Model)，生成式 AI 的核心工作原理都依賴於**機器學習** (特別是深度學習中的 Transformer 或 GAN) 來從大量數據中學習模式，並結合**自然語言處理 (NLP)** 技術來理解和生成文本或與人類交互。"
    },
    {
      "id": "IPAS_01_L12_126078_49",
      "content": "下列哪一項是生成式 AI 的典型應用？",
      "A": "硬體工程設計",
      "B": "網路安全監控",
      "C": "聊天機器人與虛擬助理",
      "D": "生物醫學實驗",
      "Ans": "C",
      "exp": "**聊天機器人與虛擬助理** (如 Bard, ChatGPT, Copilot) 是生成式 AI 最普遍和典型的應用，它們利用大型語言模型 (LLM) 的能力來理解人類語言並生成自然、連貫的回應。"
    },
    {
      "id": "IPAS_01_L12_126078_50",
      "content": "生成式 AI 可以創造哪些類型的內容？",
      "A": "建築結構",
      "B": "生物醫學實驗",
      "C": "文字、圖像、程式碼",
      "D": "傳統硬體設計",
      "Ans": "C",
      "exp": "生成式 AI 具有多模態能力，能夠創造多種形式的內容，最常見且成熟的類型包括**文本** (如故事、郵件)、**圖像** (如 Midjourney, Stable Diffusion) 和**程式碼** (如 Codex, Copilot)。"
    }
  ]
}