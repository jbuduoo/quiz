{
  "metadata": {
    "testName": "IPAS_01",
    "subject": "L11",
    "series_no": "133864",
    "sourceFile": "113年_-_113-1_中國工業工程學會_工業工程師等相關證照考試：人工智慧#133864-阿摩線上測驗.xlsx",
    "count": 50
  },
  "questions": [
    {
      "id": "IPAS_01_L11_133864_1",
      "content": "下列哪一個不是常見的類神經網路？",
      "A": "KNN",
      "B": "ANN",
      "C": "RNN",
      "D": "CNN",
      "Ans": "A",
      "exp": "KNN(K-Nearest Neighbors)是K最近鄰居法，屬於分類演算法，不是類神經網路。ANN(人工神經網路)、RNN(遞歸神經網路)、CNN(卷積神經網路)都是常見的類神經網路架構。"
    },
    {
      "id": "IPAS_01_L11_133864_2",
      "content": "下列哪一個作業不屬於圖像識別的預處理程序？",
      "A": "放大縮小",
      "B": "增加雜訊",
      "C": "旋轉",
      "D": "翻轉",
      "Ans": "B",
      "exp": "圖像識別的預處理程序包括：放大縮小、旋轉、翻轉等幾何變換。增加雜訊不是預處理程序，反而會降低圖像品質，通常用於資料增強(data augmentation)來增加模型魯棒性。"
    },
    {
      "id": "IPAS_01_L11_133864_3",
      "content": "人的耳朵能夠聽到的聲音的基本頻率介於",
      "A": "10Hz~10kHz",
      "B": "20Hz~20kHz",
      "C": "30Hz~30kHz",
      "D": "40Hz~40kHz",
      "Ans": "B",
      "exp": "人類耳朵能夠聽到的聲音頻率範圍大約是20Hz到20kHz。低於20Hz的聲音稱為次聲波，高於20kHz的聲音稱為超聲波，人類都無法聽到。"
    },
    {
      "id": "IPAS_01_L11_133864_4",
      "content": "4.KNN 的 K 是什麼意思？",
      "A": "K 個鄰居",
      "B": "K 個群體",
      "C": "K 是百分比",
      "D": "K 次運算",
      "Ans": "A",
      "exp": "KNN中的K代表K個最近鄰居(K-Nearest Neighbors)。KNN演算法根據距離最近的K個鄰居來進行分類或迴歸預測。"
    },
    {
      "id": "IPAS_01_L11_133864_5",
      "content": "5.通常 CNN 結構不包含？",
      "A": "卷積層",
      "B": "池化層",
      "C": "全連結層",
      "D": "遞歸層",
      "Ans": "D",
      "exp": "CNN(卷積神經網路)的標準結構包含：卷積層(Convolutional Layer)、池化層(Pooling Layer)、全連結層(Fully Connected Layer)。遞歸層(Recurrent Layer)是RNN的結構，不屬於CNN。"
    },
    {
      "id": "IPAS_01_L11_133864_6",
      "content": "黑白圖像用灰階代表灰度，黑色的值是?",
      "A": "0",
      "B": "100",
      "C": "200",
      "D": "255",
      "Ans": "A",
      "exp": "在灰階圖像中，黑色的值為0，白色的值為255。灰階值範圍通常是0-255，其中0代表最暗(黑色)，255代表最亮(白色)。"
    },
    {
      "id": "IPAS_01_L11_133864_7",
      "content": "如果一個彩色圖像的某個像素的(R, G, B)=(255, 0, 0)，則該像素是什麼顏色？",
      "A": "紅色",
      "B": "綠色",
      "C": "藍色",
      "D": "白色",
      "Ans": "A",
      "exp": "RGB色彩模型中，(255, 0, 0)表示紅色通道為最大值255，綠色和藍色通道為0，因此該像素是紅色。RGB分別代表紅(Red)、綠(Green)、藍(Blue)三個顏色通道。"
    },
    {
      "id": "IPAS_01_L11_133864_8",
      "content": "卷積層不是使用下列何者與原圖做卷積運算？",
      "A": "濾波器(filter)",
      "B": "遮罩(mask)",
      "C": "核心(kernel)",
      "D": "池化(pool)",
      "Ans": "D",
      "exp": "卷積層使用濾波器(filter)、遮罩(mask)或核心(kernel)與原圖進行卷積運算來提取特徵。池化(pool)是池化層的操作，不是卷積層使用的工具。"
    },
    {
      "id": "IPAS_01_L11_133864_9",
      "content": "激活層的主要目的在於引進什麼到神經網路中？",
      "A": "線性的因素",
      "B": "非線性的因素",
      "C": "特徵圖",
      "D": "準確性",
      "Ans": "B",
      "exp": "激活層(activation layer)的主要目的是引進非線性因素到神經網路中。如果沒有激活函數，多層神經網路就等同於單層線性網路，無法學習複雜的非線性關係。"
    },
    {
      "id": "IPAS_01_L11_133864_10",
      "content": "在人工智慧學習時，會將收集的資料分成哪幾個部分？",
      "A": "訓練集、驗證集",
      "B": "訓練集、測試集",
      "C": "測試集、驗證集",
      "D": "訓練集、測試集、驗證集",
      "Ans": "D",
      "exp": "在人工智慧學習時，通常會將資料分成三個部分：訓練集(用於訓練模型參數)、驗證集(用於調整超參數和選擇最佳模型)、測試集(用於最終評估模型性能)。"
    },
    {
      "id": "IPAS_01_L11_133864_11",
      "content": "監督式學習分類的結果稱為?",
      "A": "特徵",
      "B": "答案",
      "C": "標籤",
      "D": "範圍",
      "Ans": "B",
      "exp": "監督式學習分類的結果稱為標籤(label)。標籤是訓練資料中已知的正確答案，模型學習輸入特徵與標籤之間的對應關係。"
    },
    {
      "id": "IPAS_01_L11_133864_12",
      "content": "使用電腦錄音時，下列哪一項不是需要指定的參數",
      "A": "位元解析度",
      "B": "頻率",
      "C": "取樣率",
      "D": "聲道數",
      "Ans": "B",
      "exp": "電腦錄音時需要指定的參數包括：位元解析度(bit depth)、取樣率(sampling rate)、聲道數(channel)。頻率是聲音的物理屬性，不是錄音參數。"
    },
    {
      "id": "IPAS_01_L11_133864_13",
      "content": "下列哪一個是用 AI 解決問題的步驟：(1)把問題化成函數的形式，(2)打造一個函數學習機，(3)學習，(4)收集歷史資料，(5)問一個問題。",
      "A": "(1)(2)(3)(4)(5)",
      "B": "(5)(1)(4)(2)(3)",
      "C": "(5)(1)(3)(2)(4)",
      "D": "(1)(4)(2)(3)(5)",
      "Ans": "B",
      "exp": "用AI解決問題的標準步驟順序為：(5)問一個問題 -> (1)把問題化成函數的形式 -> (4)收集歷史資料 -> (2)打造一個函數學習機 -> (3)學習。這個流程確保問題定義清晰，資料準備充分。"
    },
    {
      "id": "IPAS_01_L11_133864_14",
      "content": "下列哪一項是平均濾波器的效用？",
      "A": "減少雜訊",
      "B": "凸顯特徵",
      "C": "把圖縮小",
      "D": "邊緣偵測",
      "Ans": "A",
      "exp": "平均濾波器(average filter)的主要效用是減少雜訊。它通過計算鄰近像素的平均值來平滑圖像，去除隨機雜訊，但同時也會使圖像稍微模糊。"
    },
    {
      "id": "IPAS_01_L11_133864_15",
      "content": "下列哪一項不是池化層的作用？",
      "A": "放大卷積層輸出的特徵圖",
      "B": "壓縮卷積層輸出的特徵圖",
      "C": "找出局部的特殊值",
      "D": "降低計算的複雜度",
      "Ans": "A",
      "exp": "池化層的作用包括：壓縮卷積層輸出的特徵圖、找出局部的特殊值(如最大值或平均值)、降低計算的複雜度。池化層不會放大特徵圖，而是縮小特徵圖的尺寸。"
    },
    {
      "id": "IPAS_01_L11_133864_16",
      "content": "sigmoid 函數的輸出範圍？",
      "A": "0～1",
      "B": "-1～+1",
      "C": "0～無窮大",
      "D": "-1～0",
      "Ans": "A",
      "exp": "Sigmoid函數的輸出範圍是0到1之間。Sigmoid函數將任意實數映射到(0,1)區間，常用於二分類問題的輸出層，表示機率。"
    },
    {
      "id": "IPAS_01_L11_133864_17",
      "content": "在「語音識別」的聽寫應用中，包含哪些模型？",
      "A": "聲學模型及語言模型",
      "B": "聲學模型及音學模型",
      "C": "音學模型及語言模型",
      "D": "聲學模型、語言模型及音學模型",
      "Ans": "A",
      "exp": "在語音識別的聽寫應用中，主要包含兩個模型：聲學模型(acoustic model)用於將音訊特徵映射到音素或詞彙，語言模型(language model)用於根據上下文預測最可能的詞序列。"
    },
    {
      "id": "IPAS_01_L11_133864_18",
      "content": "下列有關「動作估計(motion estimation)」的敘述，何者錯誤？",
      "A": "是提取視頻中重要資訊最常使用的方法",
      "B": "目的在估測視頻中像素隨著時間推移在空間中的位置變化",
      "C": "可用於視頻壓縮(video compression)",
      "D": "可用於視頻識別",
      "Ans": "A",
      "exp": "動作估計(motion estimation)是提取視頻中重要資訊的方法之一，但不是最常使用的方法。視頻識別還使用其他方法如特徵提取、深度學習等。動作估計主要用於視頻壓縮和視頻分析。"
    },
    {
      "id": "IPAS_01_L11_133864_19",
      "content": "在圖像識別中，「資料增強(data augmentation)」增加資料量的方式？",
      "A": "只有改變亮度及改變色溫二種方式",
      "B": "只有翻轉及縮放二種方式",
      "C": "只有改變亮度及翻轉、縮放三種方式",
      "D": "改變亮度、翻轉、縮放及改變色溫均可",
      "Ans": "D",
      "exp": "在圖像識別中，資料增強(data augmentation)可以通過多種方式增加資料量：改變亮度、翻轉(水平或垂直)、縮放(放大或縮小)、改變色溫、旋轉、裁剪等。這些變換可以增加資料多樣性。"
    },
    {
      "id": "IPAS_01_L11_133864_20",
      "content": "神經網路學習時，會改變神經網路內的？",
      "A": "輸入值",
      "B": "結構",
      "C": "權重(weight)與偏值(bias)",
      "D": "激活函數",
      "Ans": "C",
      "exp": "神經網路學習時，會改變神經網路內的權重(weight)與偏值(bias)。這些參數在訓練過程中通過反向傳播演算法不斷調整，以最小化損失函數。輸入值、結構和激活函數通常在訓練前就確定。"
    },
    {
      "id": "IPAS_01_L11_133864_21",
      "content": "令我們的卷積核(或稱遮罩)是個3✖3的大小，而圖片是個4✖4的大小，且 stride 為 1，沒有做 padding。那做完卷積運算後，得到的「結果矩陣」的大小為何？",
      "A": "3✖3",
      "B": "4✖4",
      "C": "3✖4",
      "D": "2✖2",
      "Ans": "D",
      "exp": "卷積運算公式：輸出尺寸 = (輸入尺寸 - 卷積核尺寸) / stride + 1。4×4圖片，3×3卷積核，stride=1，無padding：輸出 = (4-3)/1 + 1 = 2。因此結果矩陣大小為2×2。"
    },
    {
      "id": "IPAS_01_L11_133864_22",
      "content": "關於卷積神經網路，還有深度神經網路(deep neural network)的說明，何者錯誤？",
      "A": "兩者都可以透過訓練的過程提升辨識的準確率",
      "B": "神經元相同個數的卷積神經網路通常表現的會比深度神經網路來得出色，大幅降低了訓練需要的參數量。",
      "C": "卷積神經網路中，一個神經元會與它上下層的每一個神經元連結。",
      "D": "在訓練神經網路時，其實就是在調整神經元連線上的權重參數。",
      "Ans": "C",
      "exp": "卷積神經網路(CNN)中，一個神經元只與局部區域的神經元連結(透過卷積操作)，而不是與上下層的每一個神經元連結。全連結神經網路才是每個神經元都與下一層所有神經元連結。"
    },
    {
      "id": "IPAS_01_L11_133864_23",
      "content": "下列何者是 CD 的取樣率？",
      "A": "44.1kHz",
      "B": "44.1Hz",
      "C": "44.1mHz",
      "D": "44.1nHz",
      "Ans": "A",
      "exp": "CD的標準取樣率是44.1kHz。這個頻率是根據奈奎斯特定理(Nyquist theorem)確定的，能夠完整重現20kHz以內的人類聽覺範圍。"
    },
    {
      "id": "IPAS_01_L11_133864_24",
      "content": "給定兩個集合 A 和 B。集合 A 包含元素 {1, 2, 3, 4}，集合 B 包含元素 {3, 4, 5, 6}。請問兩個集合的雅卡爾係數為何？",
      "A": "0.5",
      "B": "0.33",
      "C": "0.67",
      "D": "0.25",
      "Ans": "B",
      "exp": "雅卡爾係數(Jaccard coefficient) = |A∩B| / |A∪B|。A={1,2,3,4}, B={3,4,5,6}。交集A∩B={3,4}，聯集A∪B={1,2,3,4,5,6}。係數 = 2/6 = 0.33。"
    },
    {
      "id": "IPAS_01_L11_133864_25",
      "content": "關於決策樹的描述，何者有誤？",
      "A": "決策樹是一種解釋力很強的分類模型",
      "B": "決策樹的葉節點代表預測的類別",
      "C": "所謂的樹的剪枝，指的是找到包含雜訊的分叉路徑，並將該路徑刪除",
      "D": "決策樹在建構時，是由下往上遞迴地建構",
      "Ans": "D",
      "exp": "決策樹在建構時，是由上往下遞迴地建構，而不是由下往上。從根節點開始，根據特徵選擇準則(如資訊增益)逐步向下分裂，直到達到停止條件。"
    },
    {
      "id": "IPAS_01_L11_133864_26",
      "content": "關於 k-means 方法，何者是錯的？",
      "A": "它是一種非監督式學習的方法",
      "B": "它是一種聚類方法",
      "C": "它希望群內的差異，越大越好",
      "D": "它希望群間差異，越大越好",
      "Ans": "C",
      "exp": "K-means方法希望群內的差異越小越好(群內相似度高)，群間差異越大越好(不同群組差異明顯)。選項C說群內差異越大越好是錯誤的，這與聚類的目標相反。"
    },
    {
      "id": "IPAS_01_L11_133864_27",
      "content": "生成模型的中心思想是？",
      "A": "對抗式學習",
      "B": "非監督式學習",
      "C": "聯邦學習",
      "D": "對比學習",
      "Ans": "A",
      "exp": "生成模型的中心思想是對抗式學習(adversarial learning)，特別是生成對抗網路(GAN)的架構。生成器和判別器通過對抗訓練來學習數據分佈，生成逼真的新數據。"
    },
    {
      "id": "IPAS_01_L11_133864_28",
      "content": "對於生成對抗網路，何者說明有誤？",
      "A": "生成對抗網路可以用來產生以假亂真的圖片",
      "B": "生成對抗網路可以用深度神經網路來實作",
      "C": "生成器 (Generator) 是生成對抗網路的一個元件",
      "D": "在訓練生成器時，我們會固定生成網路，然後訓練生成網路",
      "Ans": "D",
      "exp": "在訓練生成對抗網路時，我們會固定判別器(discriminator)然後訓練生成器(generator)，或固定生成器然後訓練判別器，交替進行。選項D說\"固定生成網路，然後訓練生成網路\"是錯誤的。"
    },
    {
      "id": "IPAS_01_L11_133864_29",
      "content": "關於強化學習的說明，何者有誤",
      "A": "強化學習是一種監督式學習",
      "B": "Q-learning 是一種強化學習的方法",
      "C": "AlphaGo 是一個應用強化學習的例子",
      "D": "在強化學習中，機器被稱為代理人(agent)",
      "Ans": "A",
      "exp": "強化學習不是監督式學習，而是第三種機器學習類型。強化學習通過與環境互動、試錯和獎懲機制來學習，不需要標籤資料。Q-learning和AlphaGo都是強化學習的應用。"
    },
    {
      "id": "IPAS_01_L11_133864_30",
      "content": "關於 SVM 方法的說明中，何者是正確的？",
      "A": "SVM 只能做非線性分類",
      "B": "SVM 是一種非監督式學習",
      "C": "SVM 的分類函數稱為核函數。",
      "D": "SVM 是要找到最小的支持向量",
      "Ans": "C",
      "exp": "SVM(支持向量機)的分類函數稱為核函數(kernel function)。核函數用於將資料映射到高維特徵空間，使得原本線性不可分的問題變成線性可分。SVM可以進行線性和非線性分類。"
    },
    {
      "id": "IPAS_01_L11_133864_31",
      "content": "關於 k-means 以及 kNN 方法的說明，何者有誤？",
      "A": "kNN 是一種分類方法",
      "B": "k-mans 是一種聚類方法",
      "C": "kNN 的 k 一般會指定為奇數",
      "D": "k-means 是一種監督式學習",
      "Ans": "D",
      "exp": "K-means是一種非監督式學習方法，不是監督式學習。K-means用於聚類分析，不需要標籤資料。KNN是分類方法(監督式學習)，K-means是聚類方法(非監督式學習)。"
    },
    {
      "id": "IPAS_01_L11_133864_32",
      "content": "關於視頻視別的相關任務，何者說明有誤？",
      "A": "行為視別(action recognition)是要讓電腦自動地分析視頻，並判別出該視頻的行為標籤。",
      "B": "行為識別較圖像識別更為簡單",
      "C": "動作估計(motion estimation)會計算物件的動作向量(motion vector)",
      "D": "物體追蹤(object tracking)是要找到視頻中某物體的移動軌跡",
      "Ans": "B",
      "exp": "行為識別(action recognition)較圖像識別更為複雜，因為需要處理時間維度的資訊，分析多幀之間的動態變化。圖像識別只處理單一靜態圖像，而行為識別需要理解時間序列的動作模式。"
    },
    {
      "id": "IPAS_01_L11_133864_33",
      "content": "關於神經網路的說明，何者有誤？",
      "A": "CNN 及 RNN 都是一種神經網路",
      "B": "CNN，標準 NN，RNN 都是由輸入層，隱藏層，以及輸出層構成",
      "C": "深度學習，指的是神經網路中有較多的輸入層",
      "D": "神經網路可以視為一個函數學習機",
      "Ans": "C",
      "exp": "深度學習指的是神經網路中有較多的隱藏層(hidden layers)，而不是輸入層。輸入層通常只有一層，深度學習強調的是多層隱藏層來學習層次化的特徵表示。"
    },
    {
      "id": "IPAS_01_L11_133864_34",
      "content": "底下是一張影像，以及一個注意力遮罩，請問影像通過注意力遮罩後的結果為何？",
      "A": "請參考題目附圖",
      "B": "請參考題目附圖",
      "C": "請參考題目附圖",
      "D": "請參考題目附圖",
      "Ans": "A",
      "exp": "此題目需要查看右圖中的影像和注意力遮罩才能確定答案。注意力遮罩會突出圖像的特定區域，需要根據實際圖像內容來判斷結果。"
    },
    {
      "id": "IPAS_01_L11_133864_35",
      "content": "關於強化學習優缺點的說明，何者有誤？",
      "A": "強化學習適合應用在可以試誤的環境",
      "B": "強化學習的強項就是可以跨領域學習",
      "C": "強化學習是一種嚐試讓機器「自動學習」的方法",
      "D": "強化學習是以心理學中行為主義理論為基礎",
      "Ans": "B",
      "exp": "強化學習的強項不是可以跨領域學習，而是可以在特定環境中通過試錯學習最優策略。強化學習通常針對特定任務進行訓練，跨領域遷移需要額外的技術。"
    },
    {
      "id": "IPAS_01_L11_133864_36",
      "content": "關於迴歸模型的評估，以下說明何者錯誤？",
      "A": "平均平方誤差 (MSE) 是一種評估迴歸模型效能的指標",
      "B": "平均絕對百分比誤差(mean absolute percentage error)可以讓我們「解釋」迴歸模型的誤差",
      "C": "平均絕對誤差(MAE)以絕對值的形式來計算迴歸誤差",
      "D": "F1 分數(F1 score)是平衡 MSE 以及 MAE 的指標",
      "Ans": "D",
      "exp": "F1分數(F1 score)不是平衡MSE和MAE的指標。F1分數是精確率(precision)和召回率(recall)的調和平均，用於分類問題。MSE和MAE是迴歸問題的評估指標。"
    },
    {
      "id": "IPAS_01_L11_133864_37",
      "content": "關於精確率(precision)以及召回率(recall)的說明，何者有誤？",
      "A": "兩者在「數據不平衡」下，無法有效評量模型的效能",
      "B": "兩者會呈現一種權衡關係，一個高，另一個就會變低",
      "C": "兩者皆以「正類」為核心檢視模型的預測力",
      "D": "在居家的門禁系統中，假設符合權限的家人為正類，那我們會著重提高模型的精確率。",
      "Ans": "A",
      "exp": "精確率和召回率在數據不平衡的情況下仍然可以有效評量模型的效能，這是它們的優點之一。它們特別適合用於不平衡數據集的評估，因為關注的是正類的預測品質。"
    },
    {
      "id": "IPAS_01_L11_133864_38",
      "content": "在做資料分析時，我們會將資料分成訓練集(training set)，驗證集(validation set)，以及測試集(testing set)，請問底下說法何者有誤？",
      "A": "訓練集用於訓練、適配模型所使用的數據",
      "B": "驗證集用於調整模型的超參數",
      "C": "測試集用於評價模型的表現",
      "D": "測試集會參與模型的訓練以及適配",
      "Ans": "D",
      "exp": "測試集(testing set)不應該參與模型的訓練和適配。測試集只用於最終評估模型在未見過資料上的表現，如果測試集參與訓練會導致過度擬合和評估偏差。"
    },
    {
      "id": "IPAS_01_L11_133864_39",
      "content": "有一個影像如下所示，請問做完 max pooling 後的結果為何？",
      "A": "請參考題目附圖",
      "B": "請參考題目附圖",
      "C": "請參考題目附圖",
      "D": "請參考題目附圖",
      "Ans": "A",
      "exp": "此題目需要查看右圖中的影像內容才能確定max pooling後的結果。Max pooling會選擇每個區域的最大值，需要根據實際圖像數值來計算。"
    },
    {
      "id": "IPAS_01_L11_133864_40",
      "content": "有關影片中物體追蹤的順序為何？a. 進行物體偵測, b. 計算兩影格間物體特徵距離矩陣, c. 特徵配對與物體追蹤",
      "A": "cab",
      "B": "cba",
      "C": "acb",
      "D": "abc",
      "Ans": "D",
      "exp": "物體追蹤的標準流程是：a. 進行物體偵測(在每一幀中檢測物體) -> b. 計算兩影格間物體特徵距離矩陣(比較前後幀的物體特徵) -> c. 特徵配對與物體追蹤(根據特徵相似度進行配對和追蹤)。因此順序為abc。"
    },
    {
      "id": "IPAS_01_L11_133864_41",
      "content": "以下有關分群與分類的描述何者有誤？",
      "A": "分類是將未知的新訊息歸納進已知的資訊中",
      "B": "分群屬於監督式學習，而分類屬於非監督式學習",
      "C": "分類的結果稱為標籤(label)",
      "D": "分群是透過資料所具有的特徵區分類別或群體",
      "Ans": "B",
      "exp": "分群(clustering)屬於非監督式學習，而分類(classification)屬於監督式學習。選項B說反了。分群不需要標籤，分類需要標籤資料來訓練。"
    },
    {
      "id": "IPAS_01_L11_133864_42",
      "content": "下列有關神經網路的敘述何者有誤？",
      "A": "標準神經網路又稱為全連結神經網路",
      "B": "不同神經網路的架構可以混用，建構出功能不同的學習機器",
      "C": "隱藏層達到十層以上才符合深度學習的標準",
      "D": "神經網路由輸入層、隱藏層及輸出層組成",
      "Ans": "C",
      "exp": "深度學習並沒有嚴格的層數標準。雖然深度學習通常指多層神經網路，但並沒有\"十層以上\"的硬性規定。深度學習的定義更側重於能夠學習層次化特徵表示的能力。"
    },
    {
      "id": "IPAS_01_L11_133864_43",
      "content": "下列何者不在生成對抗網路的架構中？",
      "A": "判別器",
      "B": "生成器",
      "C": "對抗器",
      "D": "真實內容/生成內容",
      "Ans": "C",
      "exp": "生成對抗網路(GAN)的架構包含生成器(Generator)和判別器(Discriminator)兩個主要組件，以及真實內容和生成內容作為訓練資料。\"對抗器\"不是GAN架構中的標準組件。"
    },
    {
      "id": "IPAS_01_L11_133864_44",
      "content": "YouTube 的自動字幕產生系統屬於哪種語音識別系統？",
      "A": "對話",
      "B": "關鍵詞偵測",
      "C": "聽寫",
      "D": "語音命令",
      "Ans": "C",
      "exp": "YouTube的自動字幕系統需要將語音轉換為完整文本，這屬於聽寫(dictation)類型的語音識別系統。聽寫系統能夠處理連續語音並轉換為文字，不同於關鍵詞偵測或語音命令等有限詞彙的識別系統。"
    },
    {
      "id": "IPAS_01_L11_133864_45",
      "content": "下列何者關於「K 最近鄰居法」與「K-平均演算法」的描述有誤？",
      "A": "兩者均屬分類演算法",
      "B": "「K-平均演算法」需計算某些樣本點的重心",
      "C": "「K 最近鄰居法」的 k 值設定一般以奇數為原則",
      "D": "兩者皆須計算樣本點間的距離",
      "Ans": "A",
      "exp": "K最近鄰居法(KNN)是分類演算法，但K-平均演算法(K-means)是聚類演算法，不是分類演算法。K-means用於無監督學習，將資料分成k個群組，而KNN用於有監督學習的分類任務。"
    },
    {
      "id": "IPAS_01_L11_133864_46",
      "content": "一個 frame per second (fps)為 30 的影片，總長度為 5 分鐘，其資料量為單張圖像的幾倍？",
      "A": "150",
      "B": "300",
      "C": "1800",
      "D": "9000",
      "Ans": "D",
      "exp": "30fps × 5分鐘 × 60秒/分鐘 = 30 × 300 = 9000倍。一個30fps的5分鐘影片包含9000個影格，因此資料量為單張圖像的9000倍。"
    },
    {
      "id": "IPAS_01_L11_133864_47",
      "content": "若依難度區分語音識別系統，下列何者難度較高？",
      "A": "關鍵詞偵測(keyword spotting)",
      "B": "語音命令(voice command)",
      "C": "對話(dialog)",
      "D": "聽寫(dictation)",
      "Ans": "D",
      "exp": "聽寫(dictation)是語音識別中難度較高的應用，因為需要處理連續語音、大量詞彙、不同口音和語境。關鍵詞偵測、語音命令和對話系統的詞彙範圍較有限，相對簡單。"
    },
    {
      "id": "IPAS_01_L11_133864_48",
      "content": "假設有以下書籍銷售紀錄，關聯規則 B→C 的信賴度(confidence)為何？",
      "A": "75%",
      "B": "85%",
      "C": "95%",
      "D": "100%",
      "Ans": "N/A",
      "exp": "此題目需要查看書籍銷售紀錄的具體數據才能計算關聯規則B→C的信賴度。信賴度計算公式為：confidence(B→C) = support(B∪C) / support(B)。"
    },
    {
      "id": "IPAS_01_L11_133864_49",
      "content": "下列關於音訊的基本聲學特徵何者有誤？",
      "A": "在分析音訊時須先將音訊切成比較短的音框",
      "B": "每秒出現的音框數稱為音框率，音框率越高所需的計算資源越少",
      "C": "一個音框須包含數個基本週期才能充分擷取音訊的特徵",
      "D": "音量、音高及音色等為聲學特徵的一種",
      "Ans": "B",
      "exp": "音框率(frame rate)越高，表示每秒處理的音框數量越多，所需的計算資源越多，而不是越少。較高的音框率可以提供更細緻的時間解析度，但會增加計算負擔。"
    },
    {
      "id": "IPAS_01_L11_133864_50",
      "content": "若以「K 最近鄰居法」將右圖中資料點分群的話，k 設為多少可將*歸類在 O？",
      "A": "9",
      "B": "7",
      "C": "5",
      "D": "3",
      "Ans": "N/A",
      "exp": "此題目需要查看右圖中的資料點分布才能確定k值。K最近鄰居法根據最近的k個鄰居來分類，k值需要根據圖中資料點的分布來決定。"
    }
  ]
}