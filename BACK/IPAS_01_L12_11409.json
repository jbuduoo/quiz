{
  "metadata": {
    "testName": "IPAS_01",
    "subject": "L12",
    "series_no": "11409",
    "sourceFile": "IPAS_01初級_L12生成式AI應用與規劃_11409.xlsx",
    "count": 35
  },
  "questions": [
    {
      "id": "IPAS_01_L12_11409_1",
      "content": "下列何者最能表達 No Code / Low Code 平台的主要特色?",
      "A": "需要撰寫大量程式碼",
      "B": "運用模板快速建立應用程式",
      "C": "僅供專業開發人員使用",
      "D": "只能製作靜態網站",
      "Ans": "B",
      "exp": "* A. No Code / Low Code 的目標是減少或不需要撰寫大量程式碼。* B. 這些平台提供預先建置的模組、組件和模板，讓使用者能透過視覺化界面和拖拉方式，快速建立和部署應用程式，這是其核心特色。* C. 這些平台通常設計給非技術或公民開發者使用。* D. 這些平台可以製作複雜、動態的應用程式和業務流程。"
    },
    {
      "id": "IPAS_01_L12_11409_2",
      "content": "下列何者不是推理模型(Reasoning Model)的主要特點?",
      "A": "具備多步驟邏輯推理能力",
      "B": "具備良好的可解釋性與邏輯一致性",
      "C": "採用強化式學習的訓練方式",
      "D": "回應內容結構清晰、推理脈絡完整",
      "Ans": "C",
      "exp": "* 推理模型（如應用了 Chain-of-Thought 的大型語言模型）的特點是強調邏輯、解釋性和結構化輸出。* A, B, D 都是推理模型致力於達成的目標和特點。* C. 大型語言模型 (LLM) 作為推理模型的基礎，通常採用自監督學習 (Self-Supervised Learning)** 進行預訓練，並可能使用人類回饋強化學習 (RLHF) 進行微調，而非純粹採用強化式學習作為主要的訓練方式。**"
    },
    {
      "id": "IPAS_01_L12_11409_3",
      "content": "下列哪種情況,選擇Low Code 平台可能比 No Code 平台更為適合?",
      "A": "需要技術人員快速進行開發與應用",
      "B": "應用需求簡單,無需自訂功能",
      "C": "需要較複雜的業務邏輯並使用自訂功能",
      "D": "預算和時間極度有限",
      "Ans": "C",
      "exp": "* No Code 平台幾乎不需要編程，但客製化彈性極低。* Low Code 平台提供視覺化工具，但允許開發者在需要時編寫少量程式碼或自訂功能。* C. 當應用涉及較複雜的業務邏輯或需要與企業遺留系統進行深度整合時，Low Code 平台提供的自訂程式碼彈性使其成為比 No Code 更適合的選擇。* B, D. 應用需求簡單或時間極度有限時，通常 No Code 更為快速。"
    },
    {
      "id": "IPAS_01_L12_11409_4",
      "content": "關於生成式 AI 與 No Code / Low Code 平台的應用,下列何者最不適合整合?",
      "A": "自動生成程式碼",
      "B": "自動化生成行銷文案",
      "C": "快速開發個人化 App",
      "D": "自動化生成法律判決",
      "Ans": "D",
      "exp": "* 生成式 AI 擅長內容生成和輔助開發（如生成程式碼、生成文案）。Low Code/No Code 擅長快速建構應用程式。* D. 自動化生成法律判決涉及高度專業、倫理、公平性及準確性要求，且具備高風險，不適合將其核心決策環節交由可能產生幻覺或偏見的生成式 AI 模型自動化處理和部署，尤其不應與著重快速開發的 Low Code/No Code 平台結合。"
    },
    {
      "id": "IPAS_01_L12_11409_5",
      "content": "關於 No Code / Low Code 平台,下列敘述何者較正確?",
      "A": "兩者完全相同",
      "B": "Low Code 平台不需要任何程式設計知識",
      "C": "Low Code 平台更適合開發靈活且可擴展的解決方案",
      "D": "No Code 平台可以無限客製化",
      "Ans": "C",
      "exp": "* A. 兩者概念相似，但 Low Code 允許編寫程式碼，No Code 則否，故不完全相同。* B. Low Code 平台雖然程式碼需求低，但在複雜情況下仍需要一定的程式設計知識。* C. Low Code 平台提供了程式碼的彈性，使其在處理複雜邏輯、系統整合和未來擴展性方面通常優於 No Code 平台。* D. No Code 平台受限於其內建模組，客製化能力是有限的。"
    },
    {
      "id": "IPAS_01_L12_11409_6",
      "content": "在使用生成式 AI模型解決數學或邏輯問題時,若希望引導模型逐步推理以提升答案的準確性與可解釋性,應設計具備思維鏈(Chain-of-Thought)推理特性的提示語。下列哪一組提示語最能有效啟用模型的Chain-of-Thought 推理能力?",
      "A": "請回答這個數學問題,並直接給出答案",
      "B": "幫我算出125 × 12是多少?",
      "C": "請詳細列出每一個思考步驟,最後再給出答案",
      "D": "請用一句話簡要回答問題",
      "Ans": "C",
      "exp": "* 思維鏈 (Chain-of-Thought, CoT) 推理是透過提示詞引導 LLM 模仿人類，將複雜問題分解為中間步驟並逐步思考的過程。* A, B, D. 這些提示詞都要求直接或簡要回答，無法啟用 CoT。* C. 「請詳細列出每一個思考步驟」 是 CoT 提示工程的經典指令，能有效誘導模型產生推理過程，從而提高答案的準確性和可解釋性。"
    },
    {
      "id": "IPAS_01_L12_11409_7",
      "content": "使用 Low-Code 平台進行開發時,企業應特別留意下列哪一項潛在風險?",
      "A": "可能造成企業內部敏感資料的洩露",
      "B": "難以進行大規模的應用擴展和維護",
      "C": "開發成本將大幅增加",
      "D": "可能有未經IT部門管理的應用程式擴散",
      "Ans": "D",
      "exp": "* Low-Code/No-Code 允許業務人員（公民開發者）快速創建應用程式。* D. 這種便利性會導致「影子 IT」（Shadow IT）風險，即未經正式 IT 部門管理、安全審核或治理的應用程式在企業內部擴散，造成安全漏洞、數據孤島或合規問題。* A, B. Low-Code 平台本身通常有安全和擴展的考慮，但影子 IT 的風險更具普遍性。* C. Low-Code/No-Code 的目標是降低開發成本。"
    },
    {
      "id": "IPAS_01_L12_11409_8",
      "content": "下列哪一種技術方案適用於改善客戶體驗?",
      "A": "智慧排程系統",
      "B": "消費行為洞察模型",
      "C": "預測性維護工具",
      "D": "自然語言處理(NLP)和生成式回應模組",
      "Ans": "D",
      "exp": "* 改善客戶體驗通常涉及更快速、更個性化、更自然的互動。* A, C. 智慧排程和預測性維護主要改善營運效率或產品品質，對客戶體驗的改善是間接的。* B. 消費行為洞察用於行銷決策，不是直接改善體驗的技術方案。* D. 自然語言處理 (NLP) 和生成式回應模組是聊天機器人、智能客服的核心，能提供 24/7 的即時、流暢、人性化的對話體驗，直接改善客戶服務體驗。"
    },
    {
      "id": "IPAS_01_L12_11409_9",
      "content": "某公司擬將客戶個人資料傳輸至國外進行雲端儲存,依據《個人資料保護法》規定,下列哪一種情況下,中央目的事業主管機關有權對該國際資料傳輸行為進行限制?",
      "A": "公司規模未達主管機關要求標準,管理能力存疑",
      "B": "公司曾發生個人資料外洩事件紀錄,造成用戶信任流失",
      "C": "傳輸資料包含當事人已公開資訊,但仍涉及隱私風險",
      "D": "接收國家之個人資料保護法規尚未完善,可能損害當事人權益",
      "Ans": "D",
      "exp": "* 依據我國《個人資料保護法》第 21 條規定（國際傳輸限制），中央目的事業主管機關可以限制個人資料的國際傳輸。* D. 其中一個限制條件是：「接收國對於個人資料之保護未有完善之法規，致有損當事人權益之虞」。* A, B, C. 這些情況雖可能引發關注，但 D 項是法律明文規定的國際傳輸限制條件之一。"
    },
    {
      "id": "IPAS_01_L12_11409_10",
      "content": "下列哪一項技術是生成式AI的基礎?",
      "A": "決策樹模型",
      "B": "聚類演算法",
      "C": "生成對抗網路",
      "D": "隨機森林技術",
      "Ans": "C",
      "exp": "* A, B, D (決策樹、聚類、隨機森林) 都是傳統機器學習或鑑別式 AI 的技術。* C. 生成對抗網路 (Generative Adversarial Networks, GAN) 是現代生成式 AI 的三大核心技術（GAN、VAE、Diffusion Model）之一，是訓練模型生成新數據的里程碑技術。"
    },
    {
      "id": "IPAS_01_L12_11409_11",
      "content": "能使用 DALL-E-2生成各式逼真的圖片,最關鍵的應用技術為何?",
      "A": "卷積神經網絡(CNN)",
      "B": "生成對抗網絡(GAN)",
      "C": "擴散模型(Diffusion Model)",
      "D": "自然語言處理(NLP)",
      "Ans": "C",
      "exp": "* DALL-E 2、Stable Diffusion 等頂尖的文本生成圖像模型，其核心機制正是基於擴散模型 (Diffusion Model)。* C. 擴散模型通過學習如何逐步「去噪」圖像（從隨機噪點中恢復圖像），實現了極為高品質和高解析度的圖像生成能力。* A. CNN 是圖像處理的基礎，但不是生成的核心。* B. 雖然 GAN 也是生成式模型，但目前主流的逼真圖像生成多採用擴散模型。* D. NLP 負責理解文本提示，但不是生成圖像的技術。"
    },
    {
      "id": "IPAS_01_L12_11409_12",
      "content": "在企業級數據管道(ETL)中,No Code / Low Code 平台的主要角色為何?",
      "A": "可作為前端數據可視化工具,協助展示與分析結果",
      "B": "取代部分傳統 ETL 解決方案,但可能無法處理過於客製化的邏輯",
      "C": "僅適用於小型數據應用,對大型數據處理的效率較低",
      "D": "無法應用於任何數據處理場景,因整合難度過高",
      "Ans": "B",
      "exp": "* ETL 過程包含數據清洗、轉換、整合等邏輯。* B. No Code / Low Code 平台提供了視覺化流程工具，可以快速配置標準化的數據清洗和轉換步驟，因此可以取代部分傳統的 ETL 解決方案，特別是對於中低複雜度的流程。但對於需要複雜編程的深度客製化轉換，其能力仍有限。* A. 數據可視化是另一個層面的應用。* C. 現代 Low Code 平台已能處理中型規模的數據應用。* D. Low Code 平台在數據處理場景的應用越來越普遍。"
    },
    {
      "id": "IPAS_01_L12_11409_13",
      "content": "下列何者不是生成式AI核心技術?",
      "A": "Variational Autoencoders (VAE)",
      "B": "Generative Adversarial Networks (GAN)",
      "C": "Visual Geometry Group (VGG)",
      "D": "Autoregressive Models (AR Model)",
      "Ans": "C",
      "exp": "* A, B, D (VAE、GAN、自迴歸模型) 是生成式 AI 經典的或核心的生成模型。* C. Visual Geometry Group (VGG) 是一種經典的卷積神經網路 (CNN) 架構，主要用於圖像分類等鑑別式任務，不屬於生成式 AI 的核心技術。"
    },
    {
      "id": "IPAS_01_L12_11409_14",
      "content": "使用生成式 AI技術或工具生成內容時,應採取下列哪一項措施以確保內容品質?",
      "A": "使用內容直接進行學術報告",
      "B": "適當標注引用來源",
      "C": "減少人工參與的審查過程",
      "D": "排除所有生成的資料",
      "Ans": "B",
      "exp": "* A. 生成式 AI 內容可能包含幻覺或不準確資訊，不應直接用於學術報告或決策。* B. 負責任地使用生成式 AI 要求使用者對輸出的內容進行事實查核，並在合適時機適當標注引用來源**，以確保透明度和內容品質。* C. 應增加**人工審查，尤其是在高風險或高準確性要求的場景。* D. 排除所有生成的資料則無法發揮 AI 的價值。"
    },
    {
      "id": "IPAS_01_L12_11409_15",
      "content": "小莉老師準備使用生成式AI 製作個人化學習系統,以下為她設計系統時可能採取的邏輯順序排列: a.根據學生學習歷程與成績,輸入學生特徵; b.根據教材主題,指示AI生成適合的練習題與即時回饋; c.生成適應性學習計畫,讓每位學生依進度與弱點調整練習方式; d.匯入課綱與教學單元內容,建立知識結構圖",
      "A": "d→a→c→b",
      "B": "a→d→b→c",
      "C": "d→a→b→c",
      "D": "a→b→c→d",
      "Ans": "C",
      "exp": "* 建立個人化學習系統的合理邏輯順序為：* d. 建立基礎知識庫 (匯入課綱)：先定義 AI 教學的範圍和結構。* a. 輸入學生數據 (輸入學生特徵)：接著讓 AI 了解每個學生的背景和弱點。* b. 生成內容 (生成練習題與回饋)：利用知識結構和學生特徵，生成所需的教學內容。* c. 形成計畫與調整 (生成適應性學習計畫)：根據已有的知識、學生特徵和生成內容，輸出最終的個人化調整計畫。* 因此，最合理的順序為 d → a → b → c。"
    },
    {
      "id": "IPAS_01_L12_11409_16",
      "content": "在提示工程(Prompt Engineering)中,「零次學習 (Zero-shot Learning)」提示的主要優勢是什麼?",
      "A": "需要大量標註範例",
      "B": "不需要額外的範例或微調即可執行任務",
      "C": "專注於生成高度複雜的圖像",
      "D": "只能處理分類問題",
      "Ans": "B",
      "exp": "* A. 零次學習的定義就是不需要提供任何範例 (Example)。* B. 零次學習 (Zero-shot Learning) 提示依賴模型本身的預訓練知識，透過清晰的指令，在不需要任何範例或微調的情況下直接執行任務，這是其主要優勢。* C. 零次學習是一種提示技術，不限於圖像生成。* D. 零次學習可處理多種任務，不限於分類。"
    },
    {
      "id": "IPAS_01_L12_11409_17",
      "content": "某企業希望透過生成式AI模型，根據最新的內部文件即時回答員工查詢。下列哪一種方法最適合在不重新訓練模型的情況下，將外部知識融入模型回應中？",
      "A": "模型蒸餾 (Model Distillation)",
      "B": "參數效率微調 (PEFT)",
      "C": "檢索增強生成 (RAG, Retrieval-Augmented Generation)",
      "D": "量化 (Quantization)",
      "Ans": "C",
      "exp": "* A. 模型蒸餾是將大型模型知識轉移到小型模型。* B. PEFT 是微調模型的技術，仍屬於模型訓練，而非即時知識整合。* C. 檢索增強生成 (RAG) 是將外部、最新的文檔或數據庫檢索到的相關資訊，作為上下文提供給大型語言模型 (LLM) 進行生成回答。這是在不重新訓練模型的前提下，融入最新/內部知識的最佳方案。* D. 量化是優化模型推理速度的技術。"
    },
    {
      "id": "IPAS_01_L12_11409_18",
      "content": "在評估大型語言模型 (LLM) 時，下列哪一項指標主要關注模型的連貫性與流暢性？",
      "A": "準確度 (Accuracy)",
      "B": "困惑度 (Perplexity)",
      "C": "F1 分數 (F1 Score)",
      "D": "BLEU 分數 (BLEU Score)",
      "Ans": "B",
      "exp": "* A, C. 準確度和 F1 分數是分類或事實型任務的評估指標。* B. 困惑度 (Perplexity) 是一種衡量語言模型預測下一個詞彙能力的指標，數值越低代表模型對文本的預測越有信心，通常與模型生成文本的流暢性和自然度呈負相關（困惑度越低，文本越流暢自然）。* D. BLEU 分數主要用於評估機器翻譯或文本摘要的精準度。"
    },
    {
      "id": "IPAS_01_L12_11409_19",
      "content": "關於 LoRA (Low-Rank Adaptation) 這類參數效率微調 (PEFT) 技術，其主要優勢為何？",
      "A": "需要大量的計算資源進行全模型微調",
      "B": "訓練時只需調整少量參數，大幅減少計算成本",
      "C": "專門用於處理圖像識別任務",
      "D": "適用於從零開始 (from scratch) 訓練模型",
      "Ans": "B",
      "exp": "* A. LoRA 的目的就是避免全模型微調所需的大量計算資源。* B. LoRA (PEFT 技術) 通過引入和訓練少量低秩矩陣來適配模型，從而大幅減少了需要訓練的參數數量，顯著節省了計算資源和存儲空間。* C, D. PEFT 技術主要用於對預訓練好的大型語言模型進行微調。"
    },
    {
      "id": "IPAS_01_L12_11409_20",
      "content": "企業在規劃生成式AI應用時，選擇 SaaS (Software as a Service) 部署模式而非地端部署的主要考量點為何？",
      "A": "確保對模型基礎設施的完全控制",
      "B": "降低初始投入成本和維護複雜度",
      "C": "必須處理高度敏感的內部資料",
      "D": "模型的客製化需求極高",
      "Ans": "B",
      "exp": "* A, C, D. 地端部署 (On-Premise) 更適合需要完全控制、處理高度敏感資料和進行深度客製化的場景。* B. SaaS 模式是通過雲服務商提供 AI 服務，企業不需要投入大量的硬體、人力進行部署和維護，因此能降低初始投入成本和維護複雜度。"
    },
    {
      "id": "IPAS_01_L12_11409_21",
      "content": "下列哪一項不是大型語言模型 (LLM) 產生的內容可能帶來的商業風險？",
      "A": "資訊錯誤或「幻覺」導致的商業決策失誤",
      "B": "模型訓練數據洩露個人敏感資訊的隱私風險",
      "C": "提升業務效率和自動化程度",
      "D": "生成內容的版權或智慧財產權爭議",
      "Ans": "C",
      "exp": "* A, B, D. 資訊幻覺、隱私洩露和版權爭議都是 LLM 應用中常見的風險。* C. 提升業務效率和自動化程度是 LLM 帶來的商業價值和優勢，而非風險。"
    },
    {
      "id": "IPAS_01_L12_11409_22",
      "content": "在生成式 AI 的應用中，當要求模型根據既有文件生成摘要時，最關鍵的評估標準是？",
      "A": "模型生成速度",
      "B": "摘要的長度",
      "C": "忠實性 (Factuality) 和涵蓋原文件重點",
      "D": "使用多少專有名詞",
      "Ans": "C",
      "exp": "* C. 摘要的目的是準確地反映原始文件內容。因此，忠實性（摘要內容是否真實、沒有幻覺）和是否涵蓋原文件重點是衡量摘要品質的兩個最關鍵標準。* A, B, D. 速度、長度和詞彙使用是次要考量。"
    },
    {
      "id": "IPAS_01_L12_11409_23",
      "content": "在微調 (Fine-Tuning) 大型語言模型時，標註數據的主要目的是什麼？",
      "A": "減少模型的記憶體消耗",
      "B": "教導模型特定領域的知識和行為模式",
      "C": "加速模型的推理速度",
      "D": "將模型從分類任務轉換為迴歸任務",
      "Ans": "B",
      "exp": "* B. 微調的本質是使用特定領域的標註數據對已預訓練的通用模型進行訓練，目的是讓模型學習和適應特定領域的詞彙、風格、事實或任務（如專業客服問答），以展現特定的知識和行為模式。"
    },
    {
      "id": "IPAS_01_L12_11409_24",
      "content": "關於生成式 AI 在軟體開發中的應用，下列哪一項是最常見的場景？",
      "A": "進行系統壓力測試",
      "B": "自動生成單元測試代碼和解釋現有代碼",
      "C": "擔任專案經理，進行需求分析",
      "D": "自動化部署整個軟體環境",
      "Ans": "B",
      "exp": "* B. 自動生成單元測試代碼、代碼片段、文檔，以及解釋現有代碼是目前生成式 AI（如 GitHub Copilot）在軟體開發中最成熟和常見的輔助編程應用。* A, C, D. 壓力測試、專案管理和環境部署多依賴於傳統自動化工具。"
    },
    {
      "id": "IPAS_01_L12_11409_25",
      "content": "企業在導入生成式 AI 應用時，進行 PoC (Proof of Concept) 的主要目的是？",
      "A": "確保模型的最終擴展性",
      "B": "驗證 AI 解決方案在特定業務場景下的技術可行性與預期價值",
      "C": "確定模型的長期維護成本",
      "D": "制定詳細的員工培訓計畫",
      "Ans": "B",
      "exp": "* PoC (Proof of Concept) 的核心目的在於驗證一個概念或技術是否可行。對於 AI 專案，即驗證該 AI 解決方案在特定業務場景中能否實際工作並帶來預期價值。* A, C, D. 擴展性、維護成本和培訓計畫是 PoC 後續階段的考量。"
    },
    {
      "id": "IPAS_01_L12_11409_26",
      "content": "為了避免模型生成內容中出現訓練數據中的個人身份資訊 (PII)，下列哪一種數據預處理技術是最直接有效的方法？",
      "A": "特徵縮放 (Feature Scaling)",
      "B": "資料去識別化 (Data Anonymization)",
      "C": "數據增強 (Data Augmentation)",
      "D": "類別編碼 (Categorical Encoding)",
      "Ans": "B",
      "exp": "* A, C, D 都是數據預處理技術，但與個人身份資訊洩露的關係不直接。* B. 資料去識別化 (Data Anonymization) 是指在訓練前對數據中的個人身份資訊 (PII) 進行遮蔽、加密或移除，以避免模型記憶並在生成內容中洩露這些敏感資訊。"
    },
    {
      "id": "IPAS_01_L12_11409_27",
      "content": "在提示工程中，提供多個高品質的輸入-輸出範例給模型，以引導其學習任務模式的技術稱為？",
      "A": "零次學習 (Zero-shot Learning)",
      "B": "少次學習 (Few-shot Learning)",
      "C": "監督式學習 (Supervised Learning)",
      "D": "無監督式學習 (Unsupervised Learning)",
      "Ans": "B",
      "exp": "* A. 零次學習：不提供任何範例。* B. 少次學習 (Few-shot Learning)：通過在提示詞中提供少量的範例 (Examples)，讓模型在不更新權重的情況下，快速適應並完成任務，這是提示工程中的關鍵技術。* C, D. 監督式/無監督式學習是模型訓練的方法。"
    },
    {
      "id": "IPAS_01_L12_11409_28",
      "content": "在生成式 AI 的風險管理中，下列哪一項屬於倫理風險？",
      "A": "AI 生成的內容可能帶有偏見或歧視",
      "B": "系統運行中斷可能導致企業業務受到影響",
      "C": "因資料需求增加而引起的存儲成本上升",
      "D": "員工培訓成本增加",
      "Ans": "A",
      "exp": "* A. 倫理風險主要涉及社會公平、偏見、歧視等對個人和群體的道德和社會影響。AI 模型的訓練數據若帶有偏見，生成內容就會產生歧視。* B. 屬於營運風險。* C, D. 屬於財務或資源成本風險。"
    },
    {
      "id": "IPAS_01_L12_11409_29",
      "content": "在企業導入 AI 的實施/營運階段，為持續發揮導入 AI 的價值，下列步驟的正確排序應為何？ A. AI 價值擴散 B.上線部署 C.模型監控與優化",
      "A": "ACB (擴散->監控->部署)",
      "B": "ABC (擴散->部署->監控)",
      "C": "BAC (部署->擴散->監控)",
      "D": "BCA (部署->監控->擴散)",
      "Ans": "D",
      "exp": "* 實施/營運階段的正確順序是：* B. 上線部署 (Deployment)：將模型投入實際使用。* C. 模型監控與優化 (Monitoring & Optimization)：持續觀察模型性能和穩定性，進行迭代優化。* A. AI 價值擴散 (Value Scaling)：在確認模型穩定有效後，將成功的應用推廣到更多業務場景。* 正確排序為 B → C → A (D 選項)。"
    },
    {
      "id": "IPAS_01_L12_11409_30",
      "content": "使用生成式 AI 協助撰寫一份有關產業碳排政策的分析報告，AI 提供的內容看起來語句通順且用詞專業，但經查證發現其中提到的法規條文與企業名稱並不存在。請問造成此現象最可能的原因為下列何者？",
      "A": "模型語料涵蓋不足，導致資料無法完整反映現實",
      "B": "提示語過度簡略，導致生成內容缺乏真實依據",
      "C": "模型缺乏檢索能力，無法即時查詢正確資訊",
      "D": "模型產生幻覺內容，虛構與真實資訊混雜出現",
      "Ans": "D",
      "exp": "* D. 模型產生幻覺內容：大型語言模型 (LLM) 在生成流暢的文本時，可能會虛構事實、法規或引用來源，這種現象稱為「幻覺 (Hallucination)」，是當前生成式 AI 應用中最關鍵的風險之一。"
    },
    {
      "id": "IPAS_01_L12_11409_31",
      "content": "在管理生成式 AI 系統的隱私風險時，下列哪一種技術最能有效避免模型在訓練過程中洩漏個人敏感資訊？",
      "A": "特徵工程 (Feature Engineering)",
      "B": "模型蒸餾 (Model Distillation)",
      "C": "聯邦式學習 (Federated Learning)",
      "D": "數據增強 (Data Augmentation)",
      "Ans": "C",
      "exp": "* A, B, D. 這些技術與直接避免訓練數據洩露的關係較小。* C. 聯邦式學習 (Federated Learning) 允許模型在分散式的本地數據上進行訓練，而不需要將原始的敏感數據集中傳輸到中央伺服器，從而有效降低了模型在訓練過程中洩露個人敏感資訊的風險。"
    },
    {
      "id": "IPAS_01_L12_11409_32",
      "content": "在生成式 AI 應用中，評估模型生成文本的事實準確性 (Factuality) 時，下列哪一種方法最為重要？",
      "A": "檢查文本的風格和語氣",
      "B": "透過人工審核或RAG檢索到的外部知識源進行比對",
      "C": "計算文本的詞彙多樣性",
      "D": "檢查文本是否使用了過多專有名詞",
      "Ans": "B",
      "exp": "* B. 透過外部知識源比對：鑑於生成式 AI 存在幻覺問題，評估其事實準確性 (Factuality) 必須依賴外部可信賴的知識源（如企業知識庫或檢索到的文件），透過人工審核或 RAG 機制進行比對驗證。"
    },
    {
      "id": "IPAS_01_L12_11409_33",
      "content": "關於 LangChain 或 Semantic Kernel 這類 AI 應用框架，它們的主要用途是？",
      "A": "專門用於加速模型的硬體訓練",
      "B": "提供模組化工具，幫助開發者串聯 LLM、數據源和代理 (Agents)",
      "C": "只能用於部署 No Code 應用",
      "D": "僅用於模型的量化和優化",
      "Ans": "B",
      "exp": "* B. 這些框架（如 LangChain）被設計為協調層，幫助開發者將大型語言模型 (LLM) 的核心能力與外部數據、外部工具或邏輯串聯起來，以便構建複雜、多步驟的 AI 應用（即 AI 代理）。* A, C, D. 這些不是其主要或唯一用途。"
    },
    {
      "id": "IPAS_01_L12_11409_34",
      "content": "企業在實施 AI 應用專案的規劃階段，下列哪一項任務應優先完成？",
      "A": "進行大規模模型微調",
      "B": "收集並標註大量訓練數據",
      "C": "明確定義業務問題、目標和評估指標",
      "D": "部署模型到生產環境",
      "Ans": "C",
      "exp": "* C. 明確定義業務問題、目標和評估指標是任何 AI 專案在規劃階段最關鍵的第一步，它決定了專案的方向、範圍和成功與否的衡量標準（KPIs）。* A, B, D. 模型微調、數據標註和部署都是在規劃階段完成之後的執行階段任務。"
    },
    {
      "id": "IPAS_01_L12_11409_35",
      "content": "為了提高生成式 AI 模型在特定領域的專業性與正確性，且無需進行昂貴的全模型微調，下列哪一種方法是最具成本效益的？",
      "A": "增加模型的深度與複雜度",
      "B": "使用檢索增強生成 (RAG) 結合領域知識庫",
      "C": "將模型轉移到另一種程式語言",
      "D": "僅依賴零次學習 (Zero-shot Learning) 提示",
      "Ans": "B",
      "exp": "* A. 增加模型複雜度會增加訓練成本。* B. 檢索增強生成 (RAG) 透過結合外部、最新的專業知識庫，能有效地將特定領域的知識引入模型的回應中，從而提高其專業性和事實正確性，且成本遠低於全模型微調。* C, D. 零次學習提示通常效果不如 RAG 穩定，轉換程式語言與提升專業性無關。"
    }
  ]
}