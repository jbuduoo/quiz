{
  "metadata": {
    "testName": "IPAS_01",
    "subject": "L11",
    "series_no": "126093",
    "sourceFile": "114年_-_iPAS_AI應用規劃師初級能力(科目一)_101-150#126093-阿摩線上測驗.xlsx",
    "count": 50
  },
  "questions": [
    {
      "id": "IPAS_01_L11_126093_1",
      "content": "在商務應用中,模型導向的見解可以用來解決什麼問題?",
      "A": "預測客戶需求",
      "B": "計算數學公式",
      "C": "編輯圖像",
      "D": "翻譯語言",
      "Ans": "A",
      "exp": "模型導向的見解（Model-driven insights）是利用數據分析和AI/機器學習模型，從大量的數據中發現趨勢、模式或預測結果。在商務應用中，最常見且具高價值的能力之一就是預測，例如預測客戶未來的需求、市場趨勢、或產品銷量等，以支持商業決策。"
    },
    {
      "id": "IPAS_01_L11_126093_2",
      "content": "哪一項是AI 責任的重要原則?",
      "A": "不需記錄決策過程",
      "B": "強調AI 透明度",
      "C": "只由使用者承擔責任",
      "D": "忽略潛在風險",
      "Ans": "B",
      "exp": "AI 責任（AI Accountability）的重要原則包括透明度（Transparency）、可解釋性（Explainability）、公平性（Fairness）和可究責性（Accountability）。強調AI透明度，意味著AI的運作方式、決策過程應該是可理解和可追溯的，這是確保AI可信賴的關鍵。"
    },
    {
      "id": "IPAS_01_L11_126093_3",
      "content": "為何開發者需要關注AI 模型的錯誤率分佈?",
      "A": "識別高錯誤率的資料子集",
      "B": "避免模型對某些群體產生偏 差",
      "C": "提高AI準確性與公平性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "關注錯誤率分佈是進行錯誤分析（Error Analysis）的核心目的。它可以幫助開發者：\n1. 識別模型在特定資料子集（如某一年齡層、特定地區或某種產品類型）上表現較差，即高錯誤率的資料子集 (A)。\n2. 發現模型對不同群體存在差異化表現，從而判斷是否存在偏見或歧視 (B)。\n3. 最終目標是針對性地改進模型、修正資料或調整策略，以提高整體準確性與公平性 (C)。因此，以上皆是正確答案。"
    },
    {
      "id": "IPAS_01_L11_126093_4",
      "content": "錯誤分析如何幫助提升AI的可靠性?",
      "A": "找出系統弱點",
      "B": "修正高錯誤率的資料子集",
      "C": "提升模型的準確性與穩定性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "錯誤分析（Error Analysis）是一個系統性地檢查模型錯誤類型的過程。它能夠：\n1. 透過分析錯誤發生的地方，**找出系統的弱點** (A)。\n2. 確定哪些資料子集的表現不佳，從而進行資料清理、增補或再平衡，**修正高錯誤率的資料子集** (B)。\n3. 針對性地改進模型，最終**提升模型的準確性與穩定性**，進而提升AI的可靠性 (C)。因此，以上皆是正確答案。"
    },
    {
      "id": "IPAS_01_L11_126093_5",
      "content": "高錯誤率的AI可能導致哪些問題?",
      "A": "影響系統的可靠性",
      "B": "增加使用風險",
      "C": "導致預測錯誤",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI模型的錯誤率高，直接結果是**導致預測錯誤** (C)。這些錯誤會**影響整個AI系統的可靠性** (A)，尤其在醫療、金融或自動駕駛等高風險領域，錯誤預測可能帶來嚴重的後果，**增加使用風險** (B)。因此，以上皆是正確答案。"
    },
    {
      "id": "IPAS_01_L11_126093_6",
      "content": "為何需要對AI 模型進行錯誤分析?",
      "A": "識別高錯誤率的資料群組",
      "B": "優化AI準確性",
      "C": "增強模型的公平性與可靠性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI模型錯誤分析的主要目的是**系統性地改善模型的性能和可信賴度**。\n1. 透過分析，**識別出模型在哪些資料群組上表現不佳** (A)，這是後續優化的基礎。\n2. 針對性地解決錯誤，可以**優化整體的AI準確性** (B)。\n3. 藉由檢查不同群組的錯誤率差異，可以**增強模型的公平性，同時提升可靠性** (C)。因此，以上皆是進行錯誤分析的原因。"
    },
    {
      "id": "IPAS_01_L11_126093_7",
      "content": "哪些因素可能影響 AI 模型在不同資料子群組間 的錯誤率?",
      "A": "訓練數據的品質",
      "B": "目標變數的定義",
      "C": "資料分布的均勻性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI模型在不同資料子群組間的錯誤率差異（即偏見或不公平性）可能由多種因素造成：\n1. **訓練數據的品質** (A)：如果訓練數據中某個子群體的資料存在較多標註錯誤或缺失，模型對該群體的表現自然較差。\n2. **目標變數的定義** (B)：如果目標變數（要預測的Y）的定義方式對某些群體有隱性偏見，也會影響模型公平性。\n3. **資料分布的均勻性** (C)：若某些子群組的樣本數量極少（資料不均勻），模型對這些群組的學習就會不足，導致錯誤率偏高。因此，以上皆是可能影響因素。"
    },
    {
      "id": "IPAS_01_L11_126093_8",
      "content": "哪些因素可能影響 AI 模型在不同生產批次間的 選取率差異?",
      "A": "原材料品質",
      "B": "操作流程",
      "C": "訓練數據的代表性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "此題情境應為AI模型應用於生產製造等領域。生產批次間的選取率（例如良品率、篩選通過率）差異，可能源於：\n1. **原材料品質的波動** (A)：不同批次原材料的微小差異會影響最終產品的特性，進而影響AI模型的判斷。\n2. **操作流程的輕微變動** (B)：機器設定、環境條件（如溫度、濕度）等流程變動，也會導致數據分布發生偏移 (Data Drift)。\n3. **訓練數據的代表性** (C)：若模型訓練時未充分考慮不同批次的數據特性，在面對新的批次數據時，其表現穩定性就會較差。因此，以上皆是可能影響因素。"
    },
    {
      "id": "IPAS_01_L11_126093_9",
      "content": "如何減少AI 模型在不同批次間的選取率差異?",
      "A": "進行批次間數據分析",
      "B": "優化模型的學習能力",
      "C": "持續監測選取率",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "減少模型在不同批次間的性能差異，是提高模型在實際應用中穩定性和可靠性的關鍵：\n1. **進行批次間數據分析** (A)：檢查不同批次的輸入數據是否存在統計學上的顯著差異（即數據漂移/Data Drift），這是解決問題的第一步。\n2. **優化模型的學習能力** (B)：可以透過增加訓練數據的多樣性、使用更魯棒（Robust）的模型架構或應用領域適應性（Domain Adaptation）技術來提升模型對批次差異的抗性。\n3. **持續監測選取率** (C)：部署後持續追蹤各批次的模型輸出和實際選取率，一旦發現性能下降，立即介入處理。因此，以上皆是有效措施。"
    },
    {
      "id": "IPAS_01_L11_126093_10",
      "content": "哪些措施有助於提升AI系統的公平性?",
      "A": "增加數據多樣性",
      "B": "減少算法偏見",
      "C": "進行公平性測試",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "提升AI系統公平性是負責任AI（Responsible AI）的核心環節，涵蓋了整個生命週期：\n1. **增加數據多樣性** (A)：確保訓練數據能代表所有目標群體，避免因數據不足導致模型對少數群體表現不佳。\n2. **減少算法偏見** (B)：在模型設計和訓練過程中，採用去偏見（Debiasing）技術，例如在損失函數中加入公平性約束或使用特定的公平性感知學習算法。\n3. **進行公平性測試** (C)：使用不同的公平性指標（如平等機會、均等誤差率等）對不同受保護群體進行評估。因此，以上皆是提升公平性的重要措施。"
    },
    {
      "id": "IPAS_01_L11_126093_11",
      "content": "AI公平性的重要性體現在何處?",
      "A": "確保不同群體獲得相等機會",
      "B": "減少社會歧視",
      "C": "增強AI的可信度",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI公平性（AI Fairness）確保AI系統的決策不會基於種族、性別、宗教等受保護特徵產生系統性的偏見或歧視，其重要性體現在：\n1. **確保不同群體獲得相等機會** (A)：例如在信貸審批、招聘篩選中，AI不應歧視特定群體。\n2. **減少社會歧視** (B)：避免將既有的社會偏見編碼進AI系統，加劇歧視問題。\n3. **增強AI的可信度** (C)：公平性是AI可信賴的基石，提升了公眾和使用者的信心。因此，以上皆是AI公平性的重要體現。"
    },
    {
      "id": "IPAS_01_L11_126093_12",
      "content": "以下哪一項是AI可靠性和安全性的應用案例?",
      "A": "自動駕駛",
      "B": "醫療診斷",
      "C": "網路安全監控",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "可靠性（Reliability）和安全性（Safety）是高風險AI應用的關鍵。在這些領域，AI的錯誤可能導致重大人身傷害或財產損失：\n1. **自動駕駛** (A)：要求AI在各種路況和突發事件下都能做出可靠、安全的決策。\n2. **醫療診斷** (B)：AI診斷的準確性和可靠性直接關係到病患的健康與生命。\n3. **網路安全監控** (C)：AI需可靠地識別惡意行為，確保網路系統的安全和穩定。因此，以上皆是強調AI可靠性和安全性的典型應用案例。"
    },
    {
      "id": "IPAS_01_L11_126093_13",
      "content": "Al Act 在AI技術監管上最關注的領域包括哪些?",
      "A": "保護公民健康、安全與基本 權利",
      "B": "限制所有AI產品的商業化",
      "C": "僅監管 AI 軍事應用",
      "D": "禁止所有AI相關的投資",
      "Ans": "A",
      "exp": "《歐盟人工智慧法案》（EU AI Act）採用風險分級方法，對AI技術進行監管。其核心關注點在於確保AI系統，特別是高風險AI，**保護公民的健康、安全與基本權利** (A)，例如在醫療、教育、就業、執法等領域的應用。它並非旨在限制所有商業化或僅監管軍事應用。"
    },
    {
      "id": "IPAS_01_L11_126093_14",
      "content": "Al Act 的目標包括哪些?",
      "A": "確保AI技術的安全、透明與 負責任使用",
      "B": "促進歐盟在AI安全領域的領 導地位",
      "C": "平衡技術發展與公共利益保 護",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "《歐盟人工智慧法案》（EU AI Act）是全球首部針對AI的全面法律框架，其目標宏大且多元：\n1. **確保AI技術的安全、透明與負責任使用** (A)，特別是針對高風險系統。\n2. **促進歐盟在AI安全和可信賴AI領域的領導地位** (B)。\n3. **在鼓勵AI創新的同時，保護社會與個人的公共利益** (C)。因此，以上皆是該法案的重要目標。"
    },
    {
      "id": "IPAS_01_L11_126093_15",
      "content": "Al Act 希望透過法律框架促進哪些領域的發展?",
      "A": "醫療保健",
      "B": "安全交通",
      "C": "公共服務",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "《歐盟人工智慧法案》（EU AI Act）透過建立明確的法律規則，旨在為AI的負責任發展創造一個可信賴的環境，這將間接**促進AI在多個關鍵公共利益領域的發展和應用**，例如：**醫療保健** (A)、**安全交通** (B)、**公共服務** (C)（如教育、執法等）。因此，以上皆是法案希望促進的領域。"
    },
    {
      "id": "IPAS_01_L11_126093_16",
      "content": "Al Act 在促進AI發展的同時,還希望達成哪些目 標?",
      "A": "確保 AI技術符合安全與基本 權利",
      "B": "促進 AI創新與競爭力",
      "C": "建立統一市場規則",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "《歐盟人工智慧法案》（EU AI Act）的目標是多方面的：\n1. **確保 AI技術符合安全與基本權利** (A)：這是該法案的核心保護原則。\n2. **促進 AI創新與競爭力** (B)：透過提供明確的法規，降低企業的不確定性。\n3. **建立統一市場規則** (C)：確保AI產品在歐盟境內自由流通，消除成員國之間的法律差異。因此，以上皆是法案在促進發展同時希望達成的目標。"
    },
    {
      "id": "IPAS_01_L11_126093_17",
      "content": "Al Act 特別針對哪類 AI系統提供更嚴格的監 管?",
      "A": "高風險 AI系統",
      "B": "所有AI系統一視同仁",
      "C": "低風險娛樂型AI",
      "D": "僅限於軍事AI",
      "Ans": "A",
      "exp": "《歐盟人工智慧法案》（EU AI Act）採用基於風險的方法（Risk-Based Approach）來監管AI。它將AI系統分為不可接受風險（直接禁止）、**高風險**（最嚴格監管）、有限風險（特定透明度義務）和最小風險。因此，法案特別針對可能對公民的健康、安全和基本權利造成重大傷害的**高風險 AI系統** (A) 提出最嚴格的要求。"
    },
    {
      "id": "IPAS_01_L11_126093_18",
      "content": "行政院及所屬機關(構)以外的機構如何適用本指 引?",
      "A": "可參考指引訂定AI 使用規範",
      "B": "必須完全遵守指引",
      "C": "不適用於任何其他機關",
      "D": "僅限於科技產業",
      "Ans": "A",
      "exp": "通常這類由政府行政機關頒布的「指引」或「規範」主要約束其所屬機構。對於行政院及所屬機關(構)以外的機構（如民間企業、學校、醫院等），該指引不具有強制性的法律約束力，但它們**可以作為一套最佳實踐（Best Practice），供其他機構參考** (A)，以便制定自己的AI使用、治理或倫理規範。"
    },
    {
      "id": "IPAS_01_L11_126093_19",
      "content": "企業在評估導入AI應用時,應考慮哪些關鍵因素?",
      "A": "目標設立",
      "B": "數據質量",
      "C": "員工技能與技術基礎",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "企業導入AI應用是一個多面向的戰略決策，需要考慮技術、人員和業務三個維度：\n1. **目標設立** (A)：AI應用必須有明確的商業目標，例如提高效率、降低成本、或改善客戶體驗。\n2. **數據質量** (B)：AI模型的性能極度依賴於輸入數據的質量、完整性和可用性。\n3. **員工技能與技術基礎** (C)：企業需要具備足夠的AI/數據科學人才以及適當的IT基礎設施（如雲端運算、GPU資源）。因此，以上皆是關鍵因素。"
    },
    {
      "id": "IPAS_01_L11_126093_20",
      "content": "在評估AI應用時,企業最應關注的數據相關因素 是?",
      "A": "數據質量與可用性",
      "B": "AI算法運行速度",
      "C": "企業名稱與品牌影響力",
      "D": "員工的日常工時",
      "Ans": "A",
      "exp": "AI模型本質上是從數據中學習，因此**數據的質量（Data Quality）與可用性（Availability）** (A) 是決定AI專案成功與否的**最核心**因素。如果數據不準確、不完整或無法取得，再好的算法也無法發揮作用。其他選項雖有相關性，但不是數據相關的**最應關注因素**。"
    },
    {
      "id": "IPAS_01_L11_126093_21",
      "content": "企業導入AI應用時,應優先評估哪些需求?",
      "A": "設立具體目標",
      "B": "識別主要挑戰與痛點",
      "C": "評估技術與數據基礎",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "在啟動AI專案前，企業必須進行全面的需求評估：\n1. **設立具體目標** (A)：確定AI將達成什麼量化或質化的業務成果。\n2. **識別主要挑戰與痛點** (B)：確認AI是否能有效解決業務中最迫切的問題。\n3. **評估技術與數據基礎** (C)：判斷現有的IT環境和數據資源是否足以支持AI模型的開發和部署。因此，以上皆是應優先評估的需求。"
    },
    {
      "id": "IPAS_01_L11_126093_22",
      "content": "以下哪項屬於AI數據品質評估的重點?",
      "A": "數據是否完整、無缺失",
      "B": "數據是否在不同系統間一致",
      "C": "數據是否準確且真實",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "數據品質（Data Quality）的評估是確保AI模型性能的基礎，主要包括以下幾個維度：\n1. **完整性 (Completeness)** (A)：數據是否缺乏重要資訊（如缺失值）。\n2. **一致性 (Consistency)** (B)：數據在不同儲存或應用系統中是否保持相同的值和格式。\n3. **準確性 (Accuracy) 與真實性 (Veracity)** (C)：數據是否正確地描述了現實世界的實體或事件。因此，以上皆是數據品質評估的重點。"
    },
    {
      "id": "IPAS_01_L11_126093_23",
      "content": "AI技術導入成本的主要考量因素有哪些?",
      "A": "硬體與軟體費用",
      "B": "員工培訓成本",
      "C": "維護與運營費用",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI技術導入成本是一個全面的考量，涵蓋了專案的整個生命週期：\n1. **硬體與軟體費用** (A)：包括GPU、雲端服務、數據庫、AI開發平台、開源軟體的商業授權等。\n2. **員工培訓成本** (B)：包括數據科學家、AI工程師的薪資和培訓現有員工以使用新AI系統的費用。\n3. **維護與運營費用** (C)：包括模型的持續監測（MLOps）、模型再訓練、伺服器運行、數據儲存和API服務費用等。因此，以上皆是主要考量因素。"
    },
    {
      "id": "IPAS_01_L11_126093_24",
      "content": "大數據的5V特性中,代表數據多樣性的是哪一項?",
      "A": "Volume 數據量",
      "B": "Velocity",
      "C": "Variety",
      "D": "Veracity",
      "Ans": "C",
      "exp": "大數據的5V特性中：\n* **Volume (數據量)**：指數據的規模。\n* **Velocity (數據速度)**：指數據產生和處理的速度。\n* **Variety (數據多樣性)**：指數據的類型、格式多樣，包括結構化、半結構化和非結構化數據。這是代表數據多樣性的項目 (C)。\n* **Veracity (數據真實性)**：指數據的準確性、可信賴程度。\n* **Value (數據價值)**：指數據的商業價值。"
    },
    {
      "id": "IPAS_01_L11_126093_25",
      "content": "在大數據時代的轉變中,下列哪一項是其中之一?",
      "A": "專注於少量樣本",
      "B": "追求數據的因果關係",
      "C": "接受資料的紛繁複雜",
      "D": "資料的靜態分析",
      "Ans": "C",
      "exp": "大數據時代的分析思維轉變包括：從少量樣本到處理全量數據；從追求精確度到接受資料的混亂與複雜性（即容忍一定程度的雜亂或不完美數據，追求從大量複雜數據中發現趨勢和規律）；從專注因果關係到更重視相關性。因此，**接受資料的紛繁複雜** (C) 是大數據時代的重要特徵之一。"
    },
    {
      "id": "IPAS_01_L11_126093_26",
      "content": "以下哪一項不是大數據的核心特性?",
      "A": "Volume",
      "B": "Velocity",
      "C": "Viability（可行性） ...",
      "D": "Value",
      "Ans": "C",
      "exp": "大數據的核心特性通常被概括為4V或5V：Volume（數據量）、Velocity（數據速度）、Variety（數據多樣性）、Veracity（數據真實性）和Value（數據價值）。**Viability（可行性）** (C) 不是大數據技術本身的核心特性，它更像是一個專案實施時的評估維度，而非數據自身的屬性。"
    },
    {
      "id": "IPAS_01_L11_126093_27",
      "content": "大數據中,數據的真實性代表什麼?",
      "A": "確保數據準確性",
      "B": "資料的即時更新",
      "C": "數據的多樣性",
      "D": "數據的價值",
      "Ans": "A",
      "exp": "大數據的「V」特性之一 **Veracity (真實性)**，主要指的是數據的準確性、可信度和可靠性。真實性旨在確保數據來源的可信賴性，並反映數據中存在的雜亂（messiness）和不確定性。因此，它代表**確保數據的準確性** (A)。"
    },
    {
      "id": "IPAS_01_L11_126093_28",
      "content": "以下哪些數據屬於非結構化數據的範疇?",
      "A": "學生成績資料庫",
      "B": "會議的發言記錄",
      "C": "公文資料",
      "D": "銷售報表",
      "Ans": "B",
      "exp": "非結構化數據（Unstructured Data）是沒有預定義模型或組織架構的數據。**學生成績資料庫**和**銷售報表**屬於結構化數據（通常是表格）。**公文資料**通常屬於半結構化數據或非結構化數據，但**會議的發言記錄** (B) 主要是未經格式化的原始文本，是典型的非結構化數據範疇，例如音訊或未整理的文字稿。"
    },
    {
      "id": "IPAS_01_L11_126093_29",
      "content": "在評估AI模型的泛化能力時，最需要警惕：",
      "A": "過擬合現象",
      "B": "響應延遲",
      "C": "訓練時間過長",
      "D": "資源消耗過大",
      "Ans": "A",
      "exp": "泛化能力（Generalization Ability）是指AI模型對未見過的新數據做出準確預測的能力。當模型在訓練數據上表現極好，但在測試數據或新數據上表現較差時，就出現了**過擬合（Overfitting）現象** (A)。過擬合是評估泛化能力時最需要警惕的問題，因為它意味著模型記住了訓練數據的細節和噪聲，而不是學習到數據中通用的模式。"
    },
    {
      "id": "IPAS_01_L11_126093_30",
      "content": "以下哪個「V」並不屬於大數據4V的重要特徵？",
      "A": "Volume (數據量)",
      "B": "Variety (數據多樣性)",
      "C": "Velocity (數據速度)",
      "D": "Veracity (數據真實性)",
      "Ans": "D",
      "exp": "傳統上，大數據的核心特徵被稱為**3V**：Volume（數據量）、Variety（數據多樣性）和Velocity（數據速度）。後來，為了更全面地描述大數據的挑戰，逐漸加入了**Veracity（真實性）**和**Value（價值）**，形成了**4V或5V**。如果題目限定為「4V」，通常指的是 **Volume, Velocity, Variety, 和 Veracity 或 Value**。然而，在最原始和最核心的定義中，**Veracity（真實性）** (D) 是最後才被廣泛接受為核心特徵，相較於前三者，它有時會被排除在最基礎的「4V」之外（此處的4V較為模糊，但若依據多數教科書，3V為核心，4V和5V是擴展。如果此題答案為D，則可能採用了只包含Volume, Variety, Velocity, Value的定義版本）。但鑒於原答案已給出 D，我們假設該測驗採用了 Volume, Variety, Velocity 加上 Value 的四個特徵，將 Veracity 排除在外。"
    },
    {
      "id": "IPAS_01_L11_126093_31",
      "content": "大數據應用於AI的步驟順序為何？",
      "A": "資料解釋",
      "B": "資料收集",
      "C": "資料分析",
      "D": "資料前處理 決策應用",
      "Ans": "B",
      "exp": "無論是傳統的數據分析還是AI/機器學習專案，其核心流程都始於**數據的獲取和準備**。標準的流程順序為：**資料收集** (B) -> **資料前處理** (D) -> **資料分析** (C) / 模型訓練 -> **資料解釋** (A) / 模型評估 -> 決策應用。因此，第一個步驟是**資料收集** (B)。"
    },
    {
      "id": "IPAS_01_L11_126093_32",
      "content": "以下哪一項是 GDPR(歐盟通用數據保護法)的 要求？",
      "A": "數據收集與處理透明",
      "B": "禁止數據跨境傳輸",
      "C": "僅允許靜態數據存儲",
      "D": "強制採用匿名化技術",
      "Ans": "A",
      "exp": "GDPR（General Data Protection Regulation）旨在保護歐盟公民的個人數據。其核心原則之一是**透明度（Transparency）**和**合法性（Lawfulness）**，要求數據控制者必須以簡潔、透明、可理解和易於訪問的形式告知數據主體，數據是如何被收集、處理和使用的 (A)。GDPR允許數據跨境傳輸，但需符合特定條件，也鼓勵而非強制匿名化。"
    },
    {
      "id": "IPAS_01_L11_126093_33",
      "content": "資料最小化的主要原則是什麼？",
      "A": "收集所有相關數據",
      "B": "僅收集完成任務所需的最少 數據",
      "C": "刪除無效數據",
      "D": "使用加密技術保護數據",
      "Ans": "B",
      "exp": "資料最小化（Data Minimisation）是數據保護法規（如GDPR）的核心原則之一。它要求數據處理者在處理個人數據時，**應將收集的數據限於實現其目的所必需的最少量** (B)。這有助於減少數據洩露的風險，並保護用戶隱私。"
    },
    {
      "id": "IPAS_01_L11_126093_34",
      "content": "資料加密的傳輸加密通常使用哪種技術？",
      "A": "VPN 或 HTTPS",
      "B": "RSA 或 AES",
      "C": "防火牆",
      "D": "IDS",
      "Ans": "A",
      "exp": "資料加密可以分為靜態加密（儲存加密）和傳輸加密（In-transit Encryption）。\n* **傳輸加密**：主要用於保護數據在網路傳輸過程中的安全，常見技術是**VPN（Virtual Private Network）**和**HTTPS（Hypertext Transfer Protocol Secure）**，其中HTTPS使用TLS/SSL協議加密數據 (A)。\n* **靜態加密**：RSA和AES是常見的加密算法，通常用於靜態或儲存加密 (B)。\n* 防火牆（C）和IDS（入侵檢測系統，D）是網路安全設備，非加密技術。"
    },
    {
      "id": "IPAS_01_L11_126093_35",
      "content": "資料訪問控制中的身份驗證可以使用以下哪一 項？",
      "A": "密碼或雙因素驗證",
      "B": "防火牆",
      "C": "數據備份",
      "D": "訪問日誌審查",
      "Ans": "A",
      "exp": "資料訪問控制（Access Control）主要包含三個部分：身份驗證（Authentication）、授權（Authorization）和審計（Accounting）。\n* **身份驗證**（Authentication）是用來確認用戶身份的過程，最常見的方式就是使用**密碼**，更安全的方式是使用**雙因素驗證 (2FA)** (A)。\n* 防火牆 (B) 屬於網路安全設備；數據備份 (C) 屬於資料可用性；訪問日誌審查 (D) 屬於審計環節。"
    },
    {
      "id": "IPAS_01_L11_126093_36",
      "content": "生成式 AI 的資料安全措施包括以下哪一項？",
      "A": "在本地端部署模型以避免敏 感數據外流",
      "B": "禁止使用 AI 模型",
      "C": "僅允許加密存儲",
      "D": "刪除所有生成的數據",
      "Ans": "A",
      "exp": "生成式AI（Generative AI）的一大資料安全風險在於：用戶輸入的敏感數據（如公司機密、個人資料）可能被傳輸到雲端的第三方AI服務器，並可能被用於訓練模型。因此，一個重要的安全措施是**在本地端（On-premise）或專屬私有雲部署模型** (A)，以確保敏感數據和模型訓練在企業可控的範圍內，避免數據外流。"
    },
    {
      "id": "IPAS_01_L11_126093_37",
      "content": "資料清理 中，處理缺失值的常見方法不包括以下 哪一項？",
      "A": "刪除缺失數據行",
      "B": "用均值填補",
      "C": "插值法",
      "D": "移除重複數值",
      "Ans": "D",
      "exp": "資料清理（Data Cleaning）包括處理缺失值（Missing Values）、異常值（Outliers）和重複數據（Duplicates）。\n* 處理缺失值的常見方法包括：**刪除包含缺失值的數據行** (A)、**用平均值/中位數/眾數填補** (B)、**使用插值法（如線性插值）** (C) 等。\n* **移除重複數值** (D) 是資料清理中處理重複數據的步驟，而不是處理缺失值的常見方法。"
    },
    {
      "id": "IPAS_01_L11_126093_38",
      "content": "資料轉換中的標準化(Normalization)的主要 目的是什麼？",
      "A": "將數據轉換為均值為0、標準 差為1的分布",
      "B": "消除單位影響",
      "C": "壓縮數據以接近常態分布",
      "D": "類別型數據編碼",
      "Ans": "B",
      "exp": "資料轉換（Data Transformation）中的**標準化（Normalization）**和**正規化（Standardization）**雖然名稱相似，但目的一致：\n1.  **消除單位和量級的影響** (B)：將不同量級（如年齡和收入）的特徵轉換到統一的尺度上，防止量級大的特徵主導模型訓練。\n2.  選項 A 的描述是**Z-Score 正規化（Standardization）**，它將數據轉換為均值為0、標準差為1的分布。在數據處理中，這兩種方法（標準化和正規化）往往被統稱為資料縮放（Scaling），其核心目的都是**消除量級差異**，故選項 B 是最廣泛適用的目的。"
    },
    {
      "id": "IPAS_01_L11_126093_39",
      "content": "以下哪一項屬於資料 整合 的過程？",
      "A": "移除冗餘特徵",
      "B": "處理缺失值",
      "C": "使用 Z 分數處理異常值",
      "D": "標準化數據",
      "Ans": "A",
      "exp": "資料整合（Data Integration）是將來自不同來源的數據合併到一個一致的數據集中的過程，也包括處理合併後可能產生的數據重複或矛盾問題。**移除冗餘特徵（Redundant Feature Removal）** (A) 是整合過程中處理重複或高度相關變量以確保數據集精簡和一致性的重要步驟。處理缺失值 (B)、處理異常值 (C)、標準化數據 (D) 主要屬於資料清理或資料轉換的範疇。"
    },
    {
      "id": "IPAS_01_L11_126093_40",
      "content": "特徵工程中的特徵選擇方法包括以下哪一項？",
      "A": "使用 PCA 提取信息",
      "B": "使用信息增益方法選擇重要 特徵",
      "C": "根據時間序列生成新特徵",
      "D": "類別型數據編碼",
      "Ans": "B",
      "exp": "特徵工程（Feature Engineering）包括特徵創建、特徵轉換和特徵選擇（Feature Selection）。\n* **特徵選擇**：旨在選出對模型最具預測能力的特徵子集。**信息增益（Information Gain）** (B) 是一種過濾式（Filter Method）特徵選擇方法，常用於評估特徵的重要性。\n* PCA (A) 屬於**特徵提取/降維**；生成新特徵 (C) 屬於**特徵創建**；數據編碼 (D) 屬於**特徵轉換**。"
    },
    {
      "id": "IPAS_01_L11_126093_41",
      "content": "資料降維技術如 PCA 的主要作用是什麼？",
      "A": "減少特徵數量，降低計算複 雜度",
      "B": "增強數據一致性",
      "C": "移除異常值",
      "D": "增加樣本數據",
      "Ans": "A",
      "exp": "資料降維（Dimensionality Reduction）技術，例如主成分分析（Principal Component Analysis, PCA），其主要作用是**在盡可能保留數據集中主要資訊的前提下，減少特徵（維度）的數量** (A)。這樣可以有效降低模型的計算複雜度、減少內存佔用，並在一定程度上緩解過擬合。"
    },
    {
      "id": "IPAS_01_L11_126093_42",
      "content": "深度學習模仿哪一個生物系統？",
      "A": "人體免疫系統",
      "B": "人類神經系統",
      "C": "動物的消化系統",
      "D": "人體循環系統",
      "Ans": "B",
      "exp": "深度學習（Deep Learning）是機器學習的一個子集，其核心是**人工神經網路（Artificial Neural Networks, ANNs）**。人工神經網路的結構和運作原理是**受到人類大腦的神經系統啟發和模仿** (B)，特別是模仿生物神經元之間連接和資訊傳遞的方式。"
    },
    {
      "id": "IPAS_01_L11_126093_43",
      "content": "以下哪一項是 CNN (卷積神經網路) 的主要應 用？",
      "A": "語音辨識",
      "B": "圖像處理和物體檢測",
      "C": "生成新數據",
      "D": "預測數據趨勢",
      "Ans": "B",
      "exp": "卷積神經網路（Convolutional Neural Network, CNN）因其特殊的卷積層（Convolutional Layer）結構，在處理具有網格狀拓撲結構的數據時具有顯著優勢。其最主要和最成功的應用領域是**圖像處理和物體檢測/識別** (B)。雖然也可以應用於語音辨識或序列數據，但其核心優勢在於圖像領域。"
    },
    {
      "id": "IPAS_01_L11_126093_44",
      "content": "GAN 的主要功能是什麼？",
      "A": "對數據進行聚類分析",
      "B": "創建類似於訓練數據的新數 據",
      "C": "優化模型性能",
      "D": "過濾垃圾數據",
      "Ans": "B",
      "exp": "生成對抗網路（Generative Adversarial Network, GAN）由一個**生成器（Generator）**和一個**判別器（Discriminator）**組成，兩者相互對抗訓練。GANs的主要功能是**創建（生成）**逼真且類似於訓練數據集的新數據，例如生成圖像、音樂、文本等 (B)。"
    },
    {
      "id": "IPAS_01_L11_126093_45",
      "content": "TensorFlow 是由哪個公司開發的？",
      "A": "Microsoft",
      "B": "Amazon",
      "C": "Google",
      "D": "Facebook",
      "Ans": "C",
      "exp": "**TensorFlow** 是一個由 **Google** 的 Google Brain 團隊開發的開源機器學習框架，主要用於數值計算和大規模機器學習 (C)。另一個著名的框架 PyTorch 則由 Facebook 的 AI 研究團隊開發。"
    },
    {
      "id": "IPAS_01_L11_126093_46",
      "content": "LSTM 的主要特性是什麼？",
      "A": "學習長期依賴關係",
      "B": "處理靜態數據",
      "C": "用於圖像識別",
      "D": "僅適用於分類任務",
      "Ans": "A",
      "exp": "長短期記憶（Long Short-Term Memory, LSTM）是一種特殊的遞歸神經網路（Recurrent Neural Network, RNN）。它通過引入「門」結構（輸入門、遺忘門、輸出門），有效解決了標準RNN在處理長序列數據時容易出現的梯度消失問題，使其能夠**學習和記憶序列中的長期依賴關係** (A)。它主要用於序列數據，如文本、語音、時間序列預測。"
    },
    {
      "id": "IPAS_01_L11_126093_47",
      "content": "特徵工程的目的是什麼？",
      "A": "減少數據量",
      "B": "增強模型對數據的解釋能力",
      "C": "優化模型訓練速度",
      "D": "建立數據儲存系統",
      "Ans": "B",
      "exp": "特徵工程（Feature Engineering）是利用專業知識將原始數據轉換為能更好地表示潛在問題的特徵，從而**提高機器學習模型性能**的過程。透過創造更具洞察力、更有區分力的特徵，模型可以更容易地從數據中學習模式，從而**增強模型對數據的解釋能力** (B) 和預測能力。"
    },
    {
      "id": "IPAS_01_L11_126093_48",
      "content": "以下哪一項是特徵選取的主要原則之一？",
      "A": "選擇全部可用數據",
      "B": "確保數據集的平衡性",
      "C": "測試特徵對模型性能的影響",
      "D": "僅使用文本數據",
      "Ans": "C",
      "exp": "特徵選取（Feature Selection）的主要目的是從原始特徵集中選出一個最有代表性和預測能力的子集。其核心原則是**評估並測試每個特徵或特徵子集對模型性能的實際影響** (C)，以排除冗餘或不相關的特徵，從而簡化模型、加速訓練並提高泛化能力。"
    },
    {
      "id": "IPAS_01_L11_126093_49",
      "content": "在監督式學習中，標籤的作用是什麼？",
      "A": "提供模型的輸入數據",
      "B": "確定模型的輸出結果 ✅",
      "C": "提高訓練數據的質量",
      "D": "減少數據的噪聲",
      "Ans": "B",
      "exp": "在監督式學習（Supervised Learning）中，**標籤（Label）**，也稱為目標變數（Target Variable）或Y，是訓練數據集中已知的正確答案。模型在訓練時會將其自身的預測輸出與這些標籤進行比較，並根據差異（損失）來調整權重。因此，標籤的作用是**作為模型的學習目標，確定模型的期望輸出結果** (B)。輸入數據是特徵（Feature）。"
    },
    {
      "id": "IPAS_01_L11_126093_50",
      "content": "數據集劃分時，驗證集的主要用途是什麼？",
      "A": "用於模型訓練",
      "B": "調整模型的超參數",
      "C": "測試模型性能",
      "D": "確保數據隨機分布",
      "Ans": "B",
      "exp": "在機器學習中，數據集通常劃分為三個部分：\n1.  **訓練集（Training Set）** (A)：用於訓練模型參數。\n2.  **驗證集（Validation Set）** (B)：用於在訓練過程中或訓練後，**調整模型的超參數（Hyperparameters）**，例如學習率、層數等，以找到最佳的模型配置。\n3.  **測試集（Test Set）** (C)：用於最終評估模型的泛化性能。因此，驗證集的主要用途是調整超參數 (B)。"
    }
  ]
}