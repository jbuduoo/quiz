{
  "importDate": "2025-12-16",
  "source": "114年_-_iPAS_經濟部產業人才能力初級鑑定_AI應用規劃師科目一：人工智慧基礎概論(模擬考題1-3)#126875-阿摩線上測驗.xlsx",
  "questions": [
    {
      "Id": "1",
      "Q": "機器學習的三個核心要素是什麼？",
      "A": "數據、模型、損失函數 解釋：機...",
      "B": "訓練集、測試集、驗證集",
      "C": "特徵工程、優化演算法、正則化",
      "D": "超參數調整、模型選擇、數據處理",
      "Ans": "A",
      "Exp": "機器學習的過程是利用數據 (Data) 通過一個模型 (Model) 進行學習，並透過最小化損失函數 (Loss Function) 來評估和優化模型的表現，因此這三者為核心要素。"
    },
    {
      "Id": "2",
      "Q": "下列哪一項屬於監督式學習的特點？",
      "A": "數據集中包含標記訊息 解釋：監...",
      "B": "僅需探索數據內部的結構",
      "C": "使用代理與環境互動進行學習",
      "D": "不需要驗證集來調整參數",
      "Ans": "A",
      "Exp": "監督式學習（Supervised Learning）的特點是訓練數據中包含了輸入特徵與對應的正確輸出標籤（Label），模型透過學習這些已標記的數據來進行預測或分類。"
    },
    {
      "Id": "3",
      "Q": "機器學習模型過擬合的主要原因是什麼？",
      "A": "模型的複雜度不足",
      "B": "訓練數據樣本過多",
      "C": "模型過度學習數據中的雜訊 解釋...",
      "D": "使用過於簡單的損失函數",
      "Ans": "C",
      "Exp": "過擬合（Overfitting）發生在模型過於複雜或訓練數據不足時。這會導致模型不僅學習了數據中的潛在規律，還將數據中的隨機雜訊（Noise）或異常值也當作規律學習，使得模型在訓練集上表現極佳，但在新的測試數據上表現很差。"
    },
    {
      "Id": "4",
      "Q": "交叉驗證的主要目的是什麼？",
      "A": "提高模型的訓練速度",
      "B": "驗證數據是否線性可分",
      "C": "減少模型的過擬合風險 解釋：交...",
      "D": "測試模型的容錯能力",
      "Ans": "C",
      "Exp": "交叉驗證（Cross-Validation）是一種統計學方法，它將數據集分割成多份，輪流將其中一份作為測試集，其餘作為訓練集。這樣做可以更全面地評估模型在不同數據子集上的泛化能力，從而發現和減少模型過擬合的風險。"
    },
    {
      "Id": "5",
      "Q": "機器學習的梯度下降演算法主要用於什麼？",
      "A": "減少模型的計算複雜度",
      "B": "優化模型參數以最小化損失函數 ...",
      "C": "減少數據中的雜訊干擾",
      "D": "增強數據特徵的表示能力",
      "Ans": "B",
      "Exp": "梯度下降（Gradient Descent）是一種優化演算法，用於迭代地調整模型的參數（權重和偏差）。它沿著損失函數（Loss Function）梯度下降最快的方向移動，目標是找到使損失函數達到最小值的參數組合，從而優化模型的性能。"
    },
    {
      "Id": "6",
      "Q": "線性迴歸模型最適合解決哪種類型的問題？",
      "A": "圖像分類",
      "B": "銷售額預測 解釋：線性迴歸模型...",
      "C": "聚類分析",
      "D": "遊戲策略學習",
      "Ans": "B",
      "Exp": "線性迴歸（Linear Regression）屬於監督式學習中的迴歸問題。它的目標是建立一個線性關係來預測一個連續的輸出值（如銷售額、房價、溫度等），而不是分類（如圖像分類）或聚類（如聚類分析）。"
    },
    {
      "Id": "7",
      "Q": "決策樹的最大優勢是什麼？",
      "A": "適合大規模數據的訓練",
      "B": "具有良好的可解釋性 解釋：決策...",
      "C": "不需要進行數據標準化",
      "D": "適用於圖像生成任務",
      "Ans": "B",
      "Exp": "決策樹（Decision Tree）通過一系列簡單的、基於特徵值的判斷規則來做出決策，其整個決策過程可以清晰地以樹狀結構展現出來，使其具有非常良好的可解釋性（Interpretability），容易被人類理解和解釋。"
    },
    {
      "Id": "8",
      "Q": "神經網路與傳統機器學習模型的主要區別是什麼？",
      "A": "神經網路無法處理非線性數據",
      "B": "神經網路透過多層結構學習複雜特...",
      "C": "神經網路只適用於迴歸問題",
      "D": "神經網路不需要大量數據支持",
      "Ans": "B",
      "Exp": "神經網路（Neural Network）的核心優勢在於其多層（或深度）結構，能夠自動從原始數據中學習和提取複雜、抽象的特徵表示（Feature Representation），尤其適用於處理高度非線性關係的複雜數據，這是許多傳統機器學習模型難以企及的。"
    },
    {
      "Id": "9",
      "Q": "下列關於生成對抗網路(GAN)的描述正確的是哪一項？",
      "A": "GAN 僅用於分類問題",
      "B": "GAN 由生成器和鑑別器組成 ...",
      "C": "GAN 的結果始終高度可解釋",
      "D": "GAN 不能生成高品質的數據",
      "Ans": "B",
      "Exp": "生成對抗網路（GAN）由兩部分組成：**生成器**（Generator）負責創建假數據，以及**鑑別器**（Discriminator）負責判斷輸入的數據是真實數據還是生成器創建的假數據。兩者在對抗中不斷提升彼此的性能，最終生成器能產生高度逼真的數據。"
    },
    {
      "Id": "10",
      "Q": "隨機森林(Random Forest)改進了單一決策樹的缺陷，主要透過什麼方法實現？",
      "A": "使用核函數映射高維空間",
      "B": "集成多棵隨機生成的決策樹並投票...",
      "C": "增加模型參數以減少偏差",
      "D": "採用生成模型替代分類器",
      "Ans": "B",
      "Exp": "隨機森林（Random Forest）是一種集成學習（Ensemble Learning）方法。它通過構建多棵（隨機採樣數據和特徵）決策樹，並將每棵樹的輸出進行匯總（如分類問題中的投票或迴歸問題中的平均），從而顯著降低單一決策樹容易出現的過擬合和高變異性（Variance）問題。"
    }
  ]
}