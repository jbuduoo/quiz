{
  "importDate": "2025-12-16",
  "source": "114年_-_iPAS_AI應用規劃師初級能力(科目一)_51-100#126092-阿摩線上測驗.xlsx",
  "questions": [
    {
      "id": "1",
      "content": "為何負責任 AI 需要法律與政策支持?",
      "A": "確保技術應用符合道德標準",
      "B": "降低AI 透明度",
      "C": "促進市場壟斷",
      "D": "限制 AI 技術發展",
      "Ans": "A",
      "exp": "負責任 AI 的核心目標之一是確保 AI 系統的開發和部署符合社會道德、法律規範和倫理標準。法律與政策的支持是為了提供一個框架，以保障 AI 技術被安全、公平和可問責地應用，避免對社會造成負面影響，例如歧視、隱私侵犯或不透明決策。選項 B、C、D 均與負責任 AI 的宗旨相悖。"
    },
    {
      "id": "2",
      "content": "負責任 AI的最終目標是?",
      "A": "促進人類進步",
      "B": "排除人類干預",
      "C": "讓AI自動決策",
      "D": "確保 AI 市場壟斷",
      "Ans": "A",
      "exp": "負責任 AI (Responsible AI) 的最終目標是確保 AI 技術的發展和應用能夠對社會產生積極影響，並促進人類的福祉與進步。這包括在追求效率的同時，也重視公平性、透明度、可問責性、安全性和隱私保護。排除人類干預或讓 AI 完全自動決策可能會帶來道德和社會風險，而市場壟斷不是負責任 AI 的目標。"
    },
    {
      "id": "3",
      "content": "下列哪個選項不是AI 模型可解釋性的功能?",
      "A": "提供決策過程的透明度：讓使用者了解模型如何得出結論。",
      "B": "增強模型的可理解性：使非技術人員能夠理解模型的行為。",
      "C": "完全消除, AI偏差",
      "D": "幫助監管機構審查 AI 模型：支持合規性和道德審查。",
      "Ans": "C",
      "exp": "AI 模型可解釋性（Explainable AI, XAI）的主要功能包括提高透明度（A）、增強可理解性（B）以及協助監管審查（D）。然而，可解釋性雖然有助於**發現和減輕** AI 偏差，但它本身無法**完全消除**所有 AI 偏差。消除偏差需要更全面的數據治理、模型設計和公平性測試。"
    },
    {
      "id": "4",
      "content": "在AI 模型解釋中,「局部說明」的作用是什麼?",
      "A": "提供單一預測的解釋",
      "B": "分析AI整體運作方式",
      "C": "研究數據分佈",
      "D": "決定AI訓練數據集",
      "Ans": "A",
      "exp": "在 AI 模型解釋性（XAI）中，「局部說明」（Local Explanation）專注於解釋模型**針對某個特定輸入或單次預測**是如何做出決策的，例如解釋為什麼一個客戶被拒絕貸款。選項 B 則是「全域說明」（Global Explanation）的作用。"
    },
    {
      "id": "5",
      "content": "全域說明 主要適用於什麼情境?",
      "A": "分析 AI 訓練數據集",
      "B": "了解AI 模型的整體決策方式",
      "C": "找出某次預測的影響因子",
      "D": "確保 AI免於偏見",
      "Ans": "B",
      "exp": "「全域說明」（Global Explanation）旨在提供對整個 AI 模型**整體行為和決策邏輯**的理解，例如了解模型最看重哪些特徵。選項 C 是「局部說明」（Local Explanation）的作用。全域說明有助於理解模型，進而協助確保模型免於偏見，但其最主要功能是了解**整體決策方式**。"
    },
    {
      "id": "6",
      "content": "局部說明 主要用於什麼?",
      "A": "研究 AI訓練數據",
      "B": "提供單次預測的影響分析",
      "C": "了解AI 模型的整體表現",
      "D": "調整AI 訓練參數",
      "Ans": "B",
      "exp": "局部說明（Local Explanation）的核心目的是針對**單一或特定的輸入資料**，提供 AI 模型做出該次預測時，哪些特徵或因素起到了關鍵作用。這對於建立用戶信任和診斷個案錯誤至關重要。選項 C 屬於全域說明的功能。"
    },
    {
      "id": "7",
      "content": "哪一個方法可以用來測試AI是否在不同群體中公 平運作?",
      "A": "反事實假設狀況（Counterfactual scenarios）",
      "B": "訓練數據擴充",
      "C": "增加計算資源",
      "D": "限制 AI學習範圍",
      "Ans": "A",
      "exp": "反事實假設狀況（Counterfactual scenarios）是一種評估 AI 公平性的重要方法。它透過微調輸入數據中的單一特徵（例如，將輸入中的性別從 '女性' 改為 '男性'，其他條件不變），然後觀察 AI 模型的預測結果是否發生不合理的變化。這種方法可以有效檢測模型是否對不同群體存在潛在的偏見，從而測試其公平運作性。"
    },
    {
      "id": "8",
      "content": "企業如何透過AI促進可持續發展?",
      "A": "優化物流路線",
      "B": "減少碳排放",
      "C": "降低資源浪費",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 在促進可持續發展（Sustainable Development）方面有多種應用，包括：透過優化物流和供應鏈（A）來提高效率；透過智能電網管理或預測性維護來減少能源消耗和碳排放（B）；以及透過生產預測和需求匹配來降低資源浪費（C）。因此，以上選項都是企業透過 AI 促進可持續發展的方式。"
    },
    {
      "id": "9",
      "content": "AI在經濟領域應如何運作以符合負責任 AI概念?",
      "A": "確保公平競爭",
      "B": "市場壟斷、(C) 降低監管、(D) 過度隱私限制皆不屬於負責任 AI 目標。",
      "C": "降低監管要求",
      "D": "增強隱私限制",
      "Ans": "A",
      "exp": "負責任 AI 在經濟領域的應用，強調的原則是促進經濟活動的公平、透明和可持續性。確保公平競爭（A）是負責任 AI 的核心目標之一，它避免 AI 系統的設計或部署造成特定市場或企業的壟斷。市場壟斷、降低監管和過度或不當的隱私限制均不符合負責任 AI 的宗旨。"
    },
    {
      "id": "10",
      "content": "負責任 AI的關鍵原則之一是?",
      "A": "透明性",
      "B": "壟斷市場",
      "C": "只供企業內部使用",
      "D": "無須考慮公平性",
      "Ans": "A",
      "exp": "負責任 AI 的核心關鍵原則通常包括：公平性（Fairness）、透明性（Transparency）、可解釋性（Explainability）、可靠性與安全性（Reliability and Safety）、以及問責性（Accountability）。透明性是讓使用者或監管機構能夠了解 AI 系統如何運作和做出決策的重要前提。壟斷市場和不考慮公平性均與負責任 AI 的目標相悖。"
    },
    {
      "id": "11",
      "content": "以下哪項不是數據分佈和特徵分析的主要目標?",
      "A": "確保數據品質",
      "B": "測試AI硬體性能",
      "C": "提高模型準確性",
      "D": "優化數據處理方式",
      "Ans": "B",
      "exp": "數據分佈和特徵分析（Exploratory Data Analysis, EDA）的主要目的是了解數據的結構、模式、異常值和潛在偏見，從而：確保數據品質（A）、為建立更準確的模型（C）選擇合適的特徵和算法、以及優化數據預處理和處理方式（D）。測試 AI 硬體性能屬於工程或 IT 基礎設施管理範疇，與數據本身的內容和分佈分析無直接關係。"
    },
    {
      "id": "12",
      "content": "以下哪種視覺化方法最適合顯示數據的集中趨 勢?",
      "A": "直方圖 (Histogram) ✅",
      "B": "散點圖",
      "C": "盒鬚圖",
      "D": "熱圖",
      "Ans": "C",
      "exp": "盒鬚圖（Box Plot）專門用於視覺化數據的分佈、集中趨勢（中位數）和變異性。它清晰地顯示了中位數（集中趨勢）、四分位數（分佈範圍）和異常值。直方圖（Histogram）也顯示集中趨勢，但盒鬚圖更簡潔且易於比較多組數據的集中趨勢。散點圖（Scatter Plot）主要顯示兩個變數之間的關係；熱圖（Heatmap）主要用於顯示矩陣或雙變數之間的密度或強度。"
    },
    {
      "id": "13",
      "content": "以下哪一項不是數據特徵?",
      "A": "產品價格",
      "B": "顧客年齡",
      "C": "數據索引",
      "D": "購買頻率",
      "Ans": "C",
      "exp": "數據特徵（Features）是資料集中用於訓練 AI 模型的、描述觀測實體屬性的變數。產品價格（A）、顧客年齡（B）和購買頻率（D）都是可以用來預測或分析的實際屬性。數據索引（C）通常是一個唯一的識別符號（如 ID 號碼或行號），用於資料庫管理或數據訪問，它本身不具備描述實體屬性或影響預測結果的實質意義，因此不是建模中常用的數據特徵。"
    },
    {
      "id": "14",
      "content": "哪一項不是數據分佈和特徵對開發的影響?",
      "A": "數據預處理",
      "B": "模型選擇",
      "C": "硬體維護",
      "D": "調參優化",
      "Ans": "C",
      "exp": "了解數據的分佈和特徵是 AI 開發過程中幾個關鍵步驟的基礎：它指導如何進行數據預處理（A，如缺失值處理、數據標準化）；影響應選擇哪種類型的模型（B，如數據是線性還是非線性）；以及如何進行模型的調參優化（D）。硬體維護屬於 IT 基礎設施或運營管理範疇，與數據本身的統計特性和 AI 模型設計無直接關係。"
    },
    {
      "id": "15",
      "content": "了解數據的分佈和特徵可以幫助開發者進行哪項 優化?",
      "A": "選擇合適的特徵",
      "B": "盲目增加數據量",
      "C": "忽略數據異常",
      "D": "固定使用同一種模型",
      "Ans": "A",
      "exp": "通過數據分佈和特徵分析（EDA），開發者可以識別哪些特徵與目標變數相關性強、哪些特徵存在偏見或多重共線性，從而進行特徵工程，**選擇或構建合適的特徵**（A）來提高模型性能。盲目增加數據量（B）、忽略異常（C）或固定使用單一模型（D）都是不科學的開發方法。"
    },
    {
      "id": "16",
      "content": "AI 錯誤分析結果可能影響哪些應用場景?",
      "A": "自動駕駛",
      "B": "醫療診斷",
      "C": "生產瑕疵檢測",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 錯誤分析（Error Analysis）對於所有高風險或高精度要求的應用場景都至關重要。無論是自動駕駛（A）中的錯誤識別障礙物、醫療診斷（B）中的錯誤判讀影像、或生產瑕疵檢測（C）中的錯誤分類產品，對這些錯誤的深入分析都是系統改進、提高可靠性和確保安全性的關鍵步驟。因此，以上皆是錯誤分析需要關注的應用場景。"
    },
    {
      "id": "17",
      "content": "錯誤分析如何幫助AI系統改進?",
      "A": "增強錯誤識別能力",
      "B": "提升AI的透明度",
      "C": "幫助開發人員診斷錯誤",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 錯誤分析的價值是多方面的：它可以幫助開發人員診斷錯誤的根本原因（C），例如模型在特定數據子集上的表現不佳。透過了解錯誤的類型和分佈，可以指導改進數據集、調整模型架構或訓練參數，從而間接增強錯誤識別能力（A）。此外，對錯誤的理解和分類也是提高系統透明度（B）的一部分，因為它展示了模型失效的邊界。因此，以上皆是。"
    },
    {
      "id": "18",
      "content": "為何AI錯誤分析應該與彙總精確度計量分開?",
      "A": "更精確地識別問題區域",
      "B": "提高模型的公平性",
      "C": "讓開發者能更有效改進 AI",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "彙總精確度（如整體準確率）只提供了一個高層次的性能數字，但無法說明錯誤發生在哪些數據子集或情境。將錯誤分析與彙總精確度分開：可以更精確地識別問題區域（A），例如發現 AI 在某個特定群體或罕見情況下的性能不佳；這對於發現和改進公平性問題（B）至關重要；最終目的是讓開發者能夠針對性地改進 AI 系統（C）。因此，以上皆是。"
    },
    {
      "id": "19",
      "content": "可靠性與安全性為何對AI重要?",
      "A": "確保AI系統穩定運行",
      "B": "降低AI系統風險",
      "C": "增強AI的可信度",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "可靠性（Reliability）確保 AI 系統在不同條件下都能持續、穩定地提供一致的性能（A）。安全性（Safety）則關乎 AI 系統不會對人類或環境造成傷害或意外的負面後果（B）。這兩者是負責任 AI 的核心要素，對於提高用戶、監管機構和社會對 AI 系統的信任度（C）至關重要。因此，以上皆是。"
    },
    {
      "id": "20",
      "content": "哪些方法可提升 AI的可靠性與安全性?",
      "A": "嚴格測試",
      "B": "監控AI運行",
      "C": "針對異常情況設計應對機制",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "提升 AI 可靠性與安全性的方法包括：進行嚴格的單元測試、整合測試和壓力測試（A），確保模型在各種條件下都能穩定運行；持續監控 AI 在實際環境中的運行表現（B），以便及時發現性能漂移或異常行為；以及設計應對機制（C，如故障轉移、人類介入或安全防護牆），以在系統遭遇異常或安全威脅時能夠控制風險。因此，以上皆是。"
    },
    {
      "id": "21",
      "content": "哪些措施可以提高AI的透明度?",
      "A": "提供決策過程說明",
      "B": "允許用戶查詢AI 推薦依據",
      "C": "確保 AI訓練數據公開透明",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 透明度（Transparency）是指讓 AI 的運作方式盡可能地開放和易於理解。這可以透過多種方式實現，包括向使用者解釋 AI 如何做出特定決策或建議（A, B），這也是可解釋性（XAI）的一部分；以及盡可能公開或詳細說明 AI 所使用的訓練數據集和數據來源（C，在不侵犯隱私的前提下）。因此，以上皆是提高透明度的措施。"
    },
    {
      "id": "22",
      "content": "如何提高AI的可解釋性?",
      "A": "提供決策依據",
      "B": "記錄AI行為",
      "C": "讓使用者獲取模型運作資訊",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 可解釋性（Explainability）是指能夠向人類說明 AI 系統決策過程的能力。提高可解釋性的方法包括：向使用者說明模型得出結論的具體依據和因素（A）；記錄模型在訓練和推理過程中的重要行為和權重變化（B）；以及提供使用者介面或工具，讓他們能夠查詢和理解模型的運作資訊（C）。這些措施都有助於揭開 AI 的黑箱，增強信任。因此，以上皆是。"
    },
    {
      "id": "23",
      "content": "透明度與可解釋性對AI的重要性包括?",
      "A": "增強信任",
      "B": "發現潛在風險",
      "C": "促進公平決策",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "透明度與可解釋性是負責任 AI 的核心支柱：它們能讓使用者和利害關係人理解 AI 決策的邏輯，從而增強對系統的信任（A）。通過審查模型的運作，可以幫助開發者或監管者發現數據中的偏見或潛在的系統性風險（B）。同時，理解決策依據也是確保 AI 做出公平決策（C）的關鍵步驟。因此，以上皆是。"
    },
    {
      "id": "24",
      "content": "AI 利害關係人包括哪些群體?",
      "A": "開發人員",
      "B": "使用者",
      "C": "政府機構",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 利害關係人（Stakeholders）是指任何受到 AI 系統開發、部署或使用影響的個人或群體。這包括直接參與系統設計和構建的開發人員和研究人員（A）、直接使用或受到 AI 系統決策影響的使用者或公民（B）、以及負責制定政策和監管框架的政府機構和立法者（C）。事實上，受到 AI 影響的社會群體都屬於利害關係人。因此，以上皆是。"
    },
    {
      "id": "25",
      "content": "利害關係人為何需要參與AI開發與監管?",
      "A": "確保透明度",
      "B": "減少風險",
      "C": "促進公平使用",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "利害關係人的參與對於負責任 AI 至關重要。他們可以提供多樣化的視角，幫助：確保 AI 系統的決策過程對所有受影響群體保持透明（A）；識別和減輕潛在的偏見、安全或隱私風險（B）；以及確保 AI 的設計和應用能夠促進社會公平，避免對特定群體造成歧視或不利影響（C）。因此，以上皆是。"
    },
    {
      "id": "26",
      "content": "在AI招聘過程中,如何減少配置損害?",
      "A": "使用多樣性數據訓練AI",
      "B": "讓AI自動決定錄取名單",
      "C": "移除公平性審查",
      "D": "忽略數據偏見",
      "Ans": "A",
      "exp": "配置損害（Allocational Harm）是指 AI 系統將資源或機會（如工作機會、貸款、教育名額）不公平地分配給不同群體。在 AI 招聘中，減少這種損害的關鍵是使用多樣性數據訓練 AI（A），確保訓練數據能夠代表所有潛在的申請者群體，以防止模型學習到歷史數據中的偏見，從而避免對特定族群或性別的歧視。選項 B、C、D 都會加劇而不是減少配置損害。"
    },
    {
      "id": "27",
      "content": "配置損害可能在哪些AI應用場景中發生?",
      "A": "職位招聘",
      "B": "信貸評分",
      "C": "教育錄取",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "配置損害發生在 AI 系統負責資源或機會分配的場景。職位招聘（A）、信貸評分（B，決定是否給予貸款或利率）、以及教育錄取（C）都是 AI 決策結果直接影響個人獲得重要資源或機會的典型場景。如果 AI 存在偏見，可能導致資源分配不公，造成配置損害。因此，以上皆是。"
    },
    {
      "id": "28",
      "content": "哪種情況可能屬於AI服務品質的損害?",
      "A": "AI 語音識別對某些口音準確度較低",
      "B": "AI在所有語言中識別率一致",
      "C": "AI 服務能公平對待所有使用 者",
      "D": "AI不考慮族群特性",
      "Ans": "A",
      "exp": "服務品質損害（Quality of Service Harm）是指 AI 系統在不同使用者群體之間提供不一致或品質較低的服務。選項 A 中，AI 對某些口音的識別準確度較低，意味著這些群體獲得的語音識別服務品質較差，屬於服務品質損害。選項 B 和 C 是理想的公平狀況，D 則是一個中性的描述，不直接構成損害。"
    },
    {
      "id": "29",
      "content": "如何減少AI服務品質的損害?",
      "A": "提高AI的數據多樣性",
      "B": "讓AI忽略使用者特徵",
      "C": "減少對公平性的關注",
      "D": "只專注於技術優化",
      "Ans": "A",
      "exp": "減少 AI 服務品質損害的關鍵在於確保 AI 模型在所有使用者群體中都能保持一致的高性能。這需要透過**提高 AI 訓練數據的多樣性**（A），使其涵蓋不同群體的特徵（如各種口音、膚色、背景等），從而避免模型只在特定主流群體上表現良好，而在其他群體上性能下降。忽略使用者特徵或減少對公平性的關注會導致服務品質損害加劇。"
    },
    {
      "id": "30",
      "content": "如何評估AI的公平性?",
      "A": "透過群組公平方法",
      "B": "只觀察 AI 模型結果",
      "C": "忽略公平性評估",
      "D": "完全依賴使用者回饋",
      "Ans": "A",
      "exp": "評估 AI 公平性（Fairness）最常用的方法是**群組公平方法**（Group Fairness），它涉及將受保護的群體（如性別、種族、年齡等）分組，並比較 AI 系統在這些群組間的表現指標，例如錯誤率、機會均等（Equal Opportunity）或預測結果的陽性預測值率（Positive Predictive Value）。只觀察整體結果或完全依賴回饋無法系統性地發現潛在的群體偏見。"
    },
    {
      "id": "31",
      "content": "負責任AI的決策原則強調哪些關鍵點?",
      "A": "用戶需求",
      "B": "公平性",
      "C": "隱私保護",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "負責任 AI 的決策原則（Decision Principles）旨在確保 AI 系統在技術部署和日常運營中能體現道德價值。這些關鍵點包括：滿足用戶需求（A），同時確保 AI 的決策不帶有歧視（公平性, B），並嚴格保護用戶的個人數據和隱私（C）。綜合來說，負責任 AI 決策需平衡技術、倫理、社會和用戶等各方面因素。因此，以上皆是。"
    },
    {
      "id": "32",
      "content": "如何增強用戶對AI技術的信任?",
      "A": "提高AI 透明度",
      "B": "確保AI可解釋性",
      "C": "注重數據隱私與公平性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "用戶對 AI 的信任（Trust）建立在多個維度：**透明度**（A）讓用戶了解系統的限制與潛在影響；**可解釋性**（B）讓用戶明白特定決策背後的原因；而**數據隱私與公平性**（C）則保障用戶的權益不受侵害。只有當這些要素都得到充分滿足時，用戶才會更願意接受並依賴 AI 技術。因此，以上皆是。"
    },
    {
      "id": "33",
      "content": "什麼是負責任 AI的核心原則?",
      "A": "確保安全可靠和公平性",
      "B": "只關注技術效率",
      "C": "避免所有監管",
      "D": "促進市場壟斷",
      "Ans": "A",
      "exp": "負責任 AI（Responsible AI）的核心原則是確保 AI 系統的發展不僅追求技術效率，更要以人為本，促進社會福祉。這主要體現在確保 AI 系統**安全可靠**（避免風險與故障）和**公平性**（避免歧視與偏見）上。選項 B、C、D 均與負責任 AI 的倫理和社會目標相悖。"
    },
    {
      "id": "34",
      "content": "為何負責任AI需要防止社會不公與隱私侵害?",
      "A": "確保AI造福社會",
      "B": "促進技術壟斷",
      "C": "降低AI 透明度",
      "D": "讓AI免受法律監管",
      "Ans": "A",
      "exp": "負責任 AI 的宗旨是最大限度地發揮 AI 對社會的積極潛力，同時將其負面影響降至最低。防止社會不公（如歧視）和隱私侵害是實現**確保 AI 造福社會**（A）這一目標的必要條件。如果 AI 造成不公或洩露隱私，將會損害社會信任，並可能導致社會動盪或法律問題。"
    },
    {
      "id": "35",
      "content": "負責任AI的核心價值觀不包括以下哪一項?",
      "A": "公平性",
      "B": "可靠性與安全性",
      "C": "問責性",
      "D": "獨占市場",
      "Ans": "D",
      "exp": "負責任 AI 的核心價值觀包括：公平性（A）、可靠性與安全性（B）、問責性（C）、透明度和可解釋性。這些都旨在確保 AI 的倫理應用和社會福祉。**獨占市場**（D）是一種商業競爭行為，與 AI 的倫理和社會責任價值觀無關，且通常是負責任 AI 應避免的行為。"
    },
    {
      "id": "36",
      "content": "企業在開發AI 時,如何確保AI具備問責性1",
      "A": "建立AI監管機制",
      "B": "讓AI自主運作無需監管",
      "C": "避免任何審查",
      "D": "降低AI 透明度",
      "Ans": "A",
      "exp": "問責性（Accountability）是指能夠確定誰應對 AI 系統的行為和決策負責，特別是在發生錯誤或損害時。確保問責性的關鍵措施是**建立 AI 監管機制**（A），包括記錄決策過程、設立審查委員會、定義人類介入點和故障回溯程序。讓 AI 自主運作或避免審查都會導致問責性缺失；降低透明度則會使問責性難以實現。"
    },
    {
      "id": "37",
      "content": "性能優化的主要目標是什麼?",
      "A": "減少數據存儲",
      "B": "提高數據處理效率",
      "C": "降低數據複雜度",
      "D": "增強數據隱私",
      "Ans": "B",
      "exp": "在 AI 和數據工程領域，性能優化（Performance Optimization）通常是指提高系統或模型的運行效率，例如更快的推理速度、更低的延遲或更高的吞吐量。核心目標是**提高數據處理效率**（B），使其能夠更快地完成訓練、預處理或實時預測。其他選項是次要或屬於不同範疇的目標。"
    },
    {
      "id": "38",
      "content": "以下哪一項不屬於數據結構的基本組成部分?",
      "A": "索引（Index）：→ 在資...",
      "B": "記錄",
      "C": "變數",
      "D": "欄位",
      "Ans": "C",
      "exp": "數據結構（Data Structure）在資料庫或數據表中，通常由**記錄**（B，Record，即一行數據，包含一個實體的完整資訊）、**欄位**（D，Field，即一列數據，代表記錄的某個屬性）和**索引**（A，Index，用於快速檢索數據的機制）組成。**變數**（C，Variable）是一個程式設計或數學概念，用於儲存數據值，雖然在程式碼中會使用變數來操作數據結構，但它本身不是數據結構的組成部分。"
    },
    {
      "id": "39",
      "content": "數據表之間的關聯性不包括以下哪一種?",
      "A": "一對一",
      "B": "一對多",
      "C": "多對多",
      "D": "多對單",
      "Ans": "D",
      "exp": "在關聯式資料庫中，數據表之間的關聯性（Relationships）主要有三種：**一對一**（One-to-One）、**一對多**（One-to-Many）和**多對多**（Many-to-Many）。這些關聯性定義了不同實體之間的邏輯關係。**多對單**（D）本質上就是一對多關係的反向描述，但它不是數據模型標準定義的三種基本關聯類型之一。"
    },
    {
      "id": "40",
      "content": "數據結構影響開發者的哪個方面?",
      "A": "數據管理",
      "B": "數據訪問效率",
      "C": "可擴展性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "數據結構（Data Structure）的設計對 AI 系統開發的影響是全方位的：它決定了數據的組織方式，從而影響**數據管理**（A）的容易程度；高效的數據結構設計（例如使用索引）能極大地提高**數據訪問效率**（B），進而影響模型訓練和實時推理的速度；良好的結構設計也決定了系統在數據量增長時的**可擴展性**（C）。因此，以上皆是。"
    },
    {
      "id": "41",
      "content": "以下哪項不是數據結構影響開發者的主要因素?",
      "A": "系統穩定性",
      "B": "數據訪問效率",
      "C": "模型性能",
      "D": "可擴展性",
      "Ans": "C",
      "exp": "數據結構主要影響數據的組織、儲存和檢索效率。它直接影響**數據訪問效率**（B）、系統在處理大量數據時的**可擴展性**（D）和數據庫本身的**系統穩定性**（A）。雖然數據訪問效率間接影響模型訓練和推理的速度，但**模型性能**（C，如準確率、召回率）主要取決於模型算法、特徵工程和數據品質，而不是數據結構本身。"
    },
    {
      "id": "42",
      "content": "在電商數據管理中,為何需要索引?",
      "A": "儲存數據",
      "B": "快速檢索數據",
      "C": "改變數據格式",
      "D": "增加數據體積",
      "Ans": "B",
      "exp": "索引（Index）在資料庫中的作用類似於書本的目錄。它是一種特殊數據結構，用於幫助系統以極快的速度定位和**快速檢索數據**（B），而不是逐行掃描整個數據表。這對於電商網站中經常發生的商品搜索、訂單查詢等操作至關重要。儲存數據是數據表的職責；索引通常會略微增加數據體積，但這不是其目的；改變數據格式是數據轉換的工作。"
    },
    {
      "id": "43",
      "content": "為何在AI 開發過程中應進行安全性與隱私保護 措施?",
      "A": "防止資料洩漏",
      "B": "保護用戶隱私",
      "C": "提升系統信任度",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "安全性（Security）與隱私保護（Privacy Protection）是負責任 AI 的基石。進行這些措施是為了：防止因惡意攻擊或操作失誤導致的資料洩漏（A）；嚴格遵守法規並保護用戶個人身份資訊（B）；以及向用戶和社會證明系統是可靠和值得信賴的，從而提升系統信任度（C）。因此，以上皆是。"
    },
    {
      "id": "44",
      "content": "保障 AI隱私與保密性的主要方法包括?",
      "A": "設定存取權限",
      "B": "資料加密",
      "C": "限制網絡通訊",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "保障 AI 隱私和保密性的措施是多層次的：**設定存取權限**（A）確保只有經過授權的人才能接觸敏感數據或模型；**資料加密**（B）使數據在儲存和傳輸過程中即使被截獲也無法被讀取；**限制網絡通訊**（C）可以減少數據傳輸路徑上的風險，避免數據被未授權的實體訪問。此外，數據去識別化也是常用手段。因此，以上皆是。"
    },
    {
      "id": "45",
      "content": "AI需要考慮隱私權的主要原因是?",
      "A": "保護個人數據",
      "B": "防止數據濫用",
      "C": "確保合規性",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 系統在訓練和運行時經常涉及大量個人或敏感數據。考慮隱私權是必要的，因為這有助於：**保護個人數據**（A）不被未經授權的訪問或使用；**防止數據濫用**（B），例如利用數據進行歧視性分析或不當營銷；以及滿足如 GDPR、CCPA 等法律法規的**合規性**要求（C）。因此，以上皆是。"
    },
    {
      "id": "46",
      "content": "AI在設計與部署時,應該考慮哪些因素來確保包 容性?",
      "A": "多樣性與公平性",
      "B": "消除系統偏見",
      "C": "促進機會均等",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "包容性（Inclusivity）是負責任 AI 的重要方面，旨在確保 AI 系統能為所有人服務，不遺漏或歧視任何群體。這要求系統：考慮**多樣性與公平性**（A）的需求；努力**消除系統偏見**（B），避免對特定群體產生不利影響；並透過提供公平的資源或決策，**促進機會均等**（C）。因此，以上皆是。"
    },
    {
      "id": "47",
      "content": "哪些做法可以幫助AI系統減少對特定群體的歧 視?",
      "A": "多樣化數據訓練",
      "B": "偏見檢測與修正",
      "C": "透明度與問責機制",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "減少 AI 歧視需要多方面的努力：**多樣化數據訓練**（A）是基礎，能減少數據中的代表性偏見；**偏見檢測與修正**（B）是利用專業工具和算法來識別並減輕模型在不同群體上的差異；**透明度與問責機制**（C）則提供外部審查和糾正歧視的途徑。這些措施共同構成了減少 AI 歧視的全面策略。因此，以上皆是。"
    },
    {
      "id": "48",
      "content": "哪種方式可以幫助決策者利用機器學習提升決策 準確度?",
      "A": "依賴直覺決策",
      "B": "使用資料導向分析",
      "C": "忽略歷史數據",
      "D": "只依靠個人經驗",
      "Ans": "B",
      "exp": "機器學習（Machine Learning, ML）平台的核心價值在於其能夠從大量數據中學習規律、趨勢和複雜關係。因此，決策者應當**使用資料導向分析**（B），即基於 ML 模型提供的預測和洞察來指導決策。直覺、個人經驗和忽略歷史數據都是可能導致決策準確度降低或帶有偏見的非科學方法。"
    },
    {
      "id": "49",
      "content": "以下哪種應用場景最適合使用機器學習平台的商 務決策分析?",
      "A": "預測市場趨勢。",
      "B": "、(C)、(D) 並不是以商務決策分析為核心，因此不合適。",
      "C": "記錄手寫筆跡",
      "D": "自動生成藝術作品",
      "Ans": "A",
      "exp": "商務決策分析（Business Decision Analysis）旨在利用數據科學和機器學習來優化企業的商業策略和運營。**預測市場趨勢**（A，如顧客需求、銷售量、股票價格）是典型的商業預測和決策應用，能直接指導生產、庫存和投資決策。選項 B、C、D 雖然是 AI 的應用，但它們主要屬於電腦視覺、自然語言處理或創意生成領域，並非以商務決策分析為核心目的。"
    },
    {
      "id": "50",
      "content": "哪種方式能幫助企業更好地利用AI進行決策?",
      "A": "採用模型導向的深入解析",
      "B": "依賴個人經驗",
      "C": "忽略數據趨勢",
      "D": "避免使用AI",
      "Ans": "A",
      "exp": "要充分利用 AI 進行決策，企業必須從僅依賴個人經驗轉向**採用模型導向的深入解析**（A）。這意味著使用 AI 模型對數據進行分析、預測和模擬，從而獲得比人類直覺更精準、更客觀的洞察。依賴個人經驗、忽略數據趨勢或避免使用 AI 都會導致決策效率和準確度落後於競爭對手。"
    }
  ]
}