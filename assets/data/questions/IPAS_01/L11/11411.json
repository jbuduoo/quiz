{
  "importDate": "2025-12-16",
  "source": "IPAS_01初級_L11人 工智慧基礎概論_11411.xlsx",
  "questions": [
    {
      "id": "1",
      "content": "在人工智慧系統的決策流程中，下列哪一種情境最符合「人在迴圈上 (Human-over-the-loop)」所強調的監督機制？",
      "A": "AI系統只能提供建議，人類需主動下達命令才能進行決策",
      "B": "人類對AI的運行進行日常監督，必要時可立即介入修正或干預",
      "C": "人類平時不參與AI的運作，僅在發生異常或重大錯誤時才接手控制",
      "D": "AI的所有判斷與行動在執行前，皆須經過人類逐一審核與批准",
      "Ans": "B",
      "exp": "詳細說明：* 人在迴圈上 (Human-over-the-loop) 強調 AI 系統可以獨立運作，但人類作為監督者進行日常監控，並保留最高干預權，可以在發現問題或需要時隨時介入修正或停止系統。"
    },
    {
      "id": "2",
      "content": "哪一種特徵工程技巧，最適合將「星期幾」和「24小時制時間」兩個欄位結合，以預測通勤時間？",
      "A": "One-hot 編碼 (One-hot encoding)",
      "B": "正規化 (Normalization)",
      "C": "特徵交叉 (Feature Cross)",
      "D": "寬深模型 (Wide and Deep)",
      "Ans": "C",
      "exp": "詳細說明：* 特徵交叉 (Feature Cross) 是將兩個或多個特徵組合，以捕捉它們之間的非線性交互作用。通勤時間取決於「星期幾」與「時間」的組合，特徵交叉最適合捕捉這種關聯性。"
    },
    {
      "id": "3",
      "content": "關於 ETL (Extract-Transform-Load)，下列敘述何者為正確？",
      "A": "E 表示將資料直接儲存至目標儲存庫",
      "B": "ETL 的處理順序是 Extract -> Transform -> Load",
      "C": "T 表示將資料從原始系統取出",
      "D": "L 表示在原始系統中對資料進行轉換",
      "Ans": "B",
      "exp": "詳細說明：* ETL 的順序為：E (取出) -> T (轉換) -> L (載入)。"
    },
    {
      "id": "4",
      "content": "下列何者不屬於機器學習中的監督式學習 (Supervised Learning) 任務？",
      "A": "圖像識別 (Image Classification)",
      "B": "垃圾郵件分類 (Spam Classification)",
      "C": "房價預測 (Price Prediction)",
      "D": "降維 (Dimensionality Reduction)",
      "Ans": "D",
      "exp": "詳細說明：* 監督式學習需要標籤 (A, B, C)。降維屬於非監督式學習任務，不需要目標變數 (標籤)。"
    },
    {
      "id": "5",
      "content": "在電腦視覺 (CV) 領域中，下列哪一項任務不僅標註出圖像中物件的位置，還能精確區分屬於同一類別的每一個獨立個體？",
      "A": "語義分割 (Semantic Segmentation)",
      "B": "圖像分類 (Image Classification)",
      "C": "物件偵測 (Object Detection)",
      "D": "實例分割 (Instance Segmentation)",
      "Ans": "D",
      "exp": "詳細說明：* 實例分割 (Instance Segmentation) 是對物件進行像素級的精確分割，並能區分同一類別中的不同實例，是電腦視覺中最精細的任務。"
    },
    {
      "id": "6",
      "content": "關於強化學習 (Reinforcement Learning, RL) 的敘述，下列何者正確？",
      "A": "側重於利用標記數據來訓練模型",
      "B": "代理人 (Agent) 透過最大化累積獎勵 (Reward) 來學習最佳決策序列",
      "C": "主要用於將數據集中的資料點劃分為不同的群集",
      "D": "僅適用於靜態、單一決策的場景",
      "Ans": "B",
      "exp": "詳細說明：* 強化學習的核心是：代理人在環境中行動，接收獎勵，目標是學習一個策略，以最大化長期累積獎勵。"
    },
    {
      "id": "7",
      "content": "在自然語言處理 (NLP) 中，下列何者不屬於文字的預處理步驟？",
      "A": "斷詞 (Tokenization)",
      "B": "詞形還原 (Lemmatization)",
      "C": "停用詞移除 (Stopword Removal)",
      "D": "特徵交叉 (Feature Cross)",
      "Ans": "D",
      "exp": "詳細說明：* 特徵交叉是一種特徵工程技巧，不屬於 NLP 中的基礎文字預處理步驟。"
    },
    {
      "id": "8",
      "content": "企業在 AI 系統部署後，應持續監控模型性能。當模型對實際營運數據的預測準確度顯著下降時，最可能出現下列哪一種情況？",
      "A": "模型出現過度擬合 (Overfitting)",
      "B": "訓練數據與實際營運數據的分佈發生漂移 (Data Drift)",
      "C": "模型的訓練時間不足",
      "D": "模型使用了過少的特徵",
      "Ans": "B",
      "exp": "詳細說明：* 數據漂移 (Data Drift) 是指模型訓練時所用的數據分佈與模型部署後在真實世界遇到的數據分佈不再一致，這是導致模型性能在實際營運中下降的最常見原因。"
    },
    {
      "id": "9",
      "content": "在神經網路訓練中，下列何者用於計算模型預測值與真實值之間的差異程度？",
      "A": "激活函數 (Activation Function)",
      "B": "損失函數 (Loss Function)",
      "C": "優化器 (Optimizer)",
      "D": "正則化項 (Regularization Term)",
      "Ans": "B",
      "exp": "詳細說明：* 損失函數 (Loss Function) 的核心功能是量化模型預測值與真實值之間的誤差，這個誤差值會被用於指導模型更新權重。"
    },
    {
      "id": "10",
      "content": "某公司想利用客戶資料預測他們的未來消費金額。下列哪一種模型最適合用於此預測任務？",
      "A": "K-Means 聚類",
      "B": "邏輯迴歸 (Logistic Regression)",
      "C": "決策樹迴歸 (Decision Tree Regression)",
      "D": "支持向量機 (Support Vector Machine, SVM)",
      "Ans": "C",
      "exp": "詳細說明：* 未來消費金額是連續數值，屬於迴歸 (Regression) 任務。決策樹迴歸適合用於此類任務。"
    },
    {
      "id": "11",
      "content": "在人工智慧倫理治理的考量中，下列哪一項屬於公平性 (Fairness) 的範疇？",
      "A": "確保 AI 模型具有高透明度與可解釋性",
      "B": "確保 AI 決策結果不會因受保護的特徵（如性別、種族）而產生不當的偏見或歧視",
      "C": "確保系統在遭受網路攻擊時仍能維持運作",
      "D": "確保使用者有權利知道他們的資料是如何被使用的",
      "Ans": "B",
      "exp": "詳細說明：* 公平性的核心在於消除或緩解 AI 系統因訓練數據中固有的偏見，導致對特定群體產生不平等或歧視性的對待。"
    },
    {
      "id": "12",
      "content": "某醫學中心希望透過 AI 識別 X 光片上的病灶。下列哪一種深度學習模型最適合處理此類圖像識別任務？",
      "A": "遞迴神經網路 (RNN)",
      "B": "卷積神經網路 (CNN)",
      "C": "生成對抗網路 (GAN)",
      "D": "強化學習 (RL)",
      "Ans": "B",
      "exp": "詳細說明：* 卷積神經網路 (CNN) 透過卷積層，能有效地捕捉圖像的空間結構特徵，是圖像識別、分類等電腦視覺任務的標準架構。"
    },
    {
      "id": "13",
      "content": "下列何者不屬於機器學習模型的評估指標？",
      "A": "F1-Score",
      "B": "Recall",
      "C": "Precision",
      "D": "特徵工程 (Feature Engineering)",
      "Ans": "D",
      "exp": "詳細說明：* 特徵工程是數據預處理和轉換的過程，不是模型訓練完成後的評估指標。"
    },
    {
      "id": "14",
      "content": "在數據預處理中，對數轉換 (Log Transformation) 的主要目的是什麼？",
      "A": "提高模型的解釋性",
      "B": "增加資料的維度",
      "C": "降低資料分佈的偏態 (Skewness) 並減輕極端值的影響",
      "D": "將類別資料轉換為數值格式",
      "Ans": "C",
      "exp": "詳細說明：* 對數轉換能有效地壓縮數值範圍，使數據分佈更接近常態分佈，從而降低偏態並減輕極端值對模型的影響。"
    },
    {
      "id": "15",
      "content": "當模型無法捕捉數據中的基本模式，導致訓練誤差和測試誤差都很高時，這通常是發生了下列哪一種情況？",
      "A": "模型出現過度擬合 (Overfitting)",
      "B": "模型出現欠擬合 (Underfitting)",
      "C": "訓練數據與測試數據分佈不一致",
      "D": "模型的學習率設置過高",
      "Ans": "B",
      "exp": "詳細說明：* 訓練誤差高且測試誤差高，表明模型太過簡單或訓練不足，無法捕捉規律，即欠擬合 (Underfitting)。"
    },
    {
      "id": "16",
      "content": "某團隊想採用循環神經網路（Recurrent Neural Network, RNN）建構長期氣候數據的預測模型，以下哪一項敘述最符合使用 RNN 可能會遇到的挑戰？",
      "A": "RNN 無法處理可變長度的序列輸入，因此在實務上限制極大",
      "B": "RNN 在長序列訓練中可能出現梯度消失，影響模型效果",
      "C": "RNN 無法捕捉時間上的依賴關係，因此預測準確度低",
      "D": "RNN 只能用於分類任務，不能應用於時間序列預測",
      "Ans": "B",
      "exp": "詳細說明：* 梯度消失 (Vanishing Gradient) 是 RNN 在處理長序列時最著名的缺陷，這使得模型難以學習長期的依賴關係（如長期氣候數據）。"
    },
    {
      "id": "17",
      "content": "一間金融科技公司設計一款智慧投資系統，該系統會根據市場變化自動決定「買進」、「持有」或「賣出」的行動，並根據每次交易後的盈虧結果，逐步優化下一次的投資策略。整個過程中，系統不依賴事先標記的資料，而是根據歷次行動獲得的獎勵進行調整。請問此系統最可能採用哪一種學習方法？",
      "A": "強化式學習（Reinforcement Learning）",
      "B": "監督式學習（Supervised Learning）",
      "C": "非監督式學習（Unsupervised Learning）",
      "D": "遷移學習（Transfer Learning）",
      "Ans": "A",
      "exp": "詳細說明：* 關鍵字：「行動」、「獎勵」、「逐步優化策略」、「不依賴事先標記的資料」皆指向強化式學習。"
    },
    {
      "id": "18",
      "content": "關於 Q-Learning 與 Deep Q-Learning，下列敘述何者最正確？",
      "A": "Q-Learning 與 Deep Q-Learning 的差異在於是否使用標記資料作為學習基礎",
      "B": "Q-Learning 可處理任意維度的狀態空間，因此比 Deep Q-Learning 更靈活",
      "C": "Deep Q-Learning 透過深度神經網路近似 Q 值，避免了 Q 表在高維空間中難以擴展的問題",
      "D": "Deep Q-Learning 無法搭配經驗回放（Experience Replay），因為會導致樣本順序被打亂",
      "Ans": "C",
      "exp": "詳細說明：* Deep Q-Learning (DQN) 的核心優勢就是使用深度神經網路解決 Q-Learning 在處理高維狀態空間（如圖像、複雜環境）時的維度災難。"
    },
    {
      "id": "19",
      "content": "在訓練機器學習模型時，若任務為預測房價，應選用下列哪一種損失函數（Loss Function）來衡量預測誤差？",
      "A": "均方誤差（MSE）",
      "B": "交叉熵損失（Cross-Entropy Loss）",
      "C": "Hinge 損失（Hinge Loss）",
      "D": "KL 散度（Kullback-Leibler Divergence）",
      "Ans": "A",
      "exp": "詳細說明：* 房價預測屬於迴歸任務，均方誤差 (MSE) 是迴歸任務中最常見的損失函數。"
    },
    {
      "id": "20",
      "content": "某醫院希望開發一個系統，根據患者的年齡、血壓與 BMI 等資訊，預測其罹患糖尿病的機率（0~1），並依據預測值是否超過 0.5 做出風險警示。下列哪一種模型最適合用於此分類任務？",
      "A": "邏輯迴歸（Logistic Regression）",
      "B": "支援向量機（Support Vector Machine）",
      "C": "決策樹（Decision Tree）",
      "D": "K 平均演算法（K-means）",
      "Ans": "A",
      "exp": "詳細說明：* 邏輯迴歸模型的輸出本身就是介於 0 到 1 之間的機率值，因此最直接、最適合用於這種機率預測的分類任務。"
    },
    {
      "id": "21",
      "content": "某金融科技公司正開發一套違約風險預測系統，需大量處理不同客戶的財務特徵資料。考量到資料特徵數量眾多，且希望提升預測的穩定性與泛化能力，下列哪一種鑑別式 AI 模型最適合？",
      "A": "邏輯迴歸（Logistic Regression）",
      "B": "支援向量機（Support Vector Machine）",
      "C": "決策樹（Decision Tree）",
      "D": "隨機森林（Random Forest）",
      "Ans": "D",
      "exp": "詳細說明：* 隨機森林是一種集成學習方法，透過結合多個決策樹的結果，能顯著降低過度擬合的風險，提升模型在複雜數據上的穩定性與泛化能力。"
    },
    {
      "id": "22",
      "content": "關於變分自編碼器（Variational Autoencoder, VAE）的運作流程，下列何者敘述最為正確？",
      "A": "解碼器的任務是將低維壓縮向量分類為不同類別",
      "B": "編碼器將輸入資料轉換為可視化圖像以利模型學習",
      "C": "編碼器將資料轉換為潛在空間表示，解碼器再重建資料",
      "D": "編碼器利用最大邊際機率對資料進行異常點偵測",
      "Ans": "C",
      "exp": "詳細說明：* 自編碼器的核心功能是：編碼器將輸入壓縮成潛在向量（潛在空間表示），解碼器則負責從該向量重建原始輸入。"
    },
    {
      "id": "23",
      "content": "下列何者不是我國數位發展部 AI 產品與系統評測中心對生成式 AI 的評測項目?",
      "A": "當責性",
      "B": "可靠性",
      "C": "隱私及資安",
      "D": "互動性",
      "Ans": "D",
      "exp": "詳細說明：* AI 評測主要關注倫理、安全與法規等核心面向（當責性、可靠性、隱私及資安）。互動性屬於產品設計範疇，不是核心的 AI 倫理與安全評測項目。"
    },
    {
      "id": "24",
      "content": "在保持 GPT-OSS 模型架構不變的前提下，如果將模型參數量從 20 億提升至 120 億，並假設有足夠的訓練資料支撐，下列敘述何者最正確？",
      "A": "模型參數增加會線性提升效能，且即使訓練資料不變也不會遇到瓶頸",
      "B": "參數越多模型推理越快，因為每層可以並行計算更多參數",
      "C": "較大的參數量能提升模型的表達能力與預測效能，但需足夠訓練資料支持",
      "D": "增加參數量不影響記憶體使用，只會影響計算速度",
      "Ans": "C",
      "exp": "詳細說明：* 增加模型參數能提升模型的容量和潛力，進而提升效能，但這需要足夠的數據來充分訓練這些參數。"
    },
    {
      "id": "25",
      "content": "在自然語言處理任務中，為了減少訓練語料中偏見對模型的影響，下列哪種資料處理策略屬於常見的「資料去偏（Data Debiasing）」做法？",
      "A": "讓模型在訓練時隨機替換輸出，以抵消資料中存在的系統性偏差",
      "B": "增加模型的參數量，依賴更大的模型自動消除原始資料中的偏見",
      "C": "調整或擴充訓練語料，使不同群體或類型資料的比例更加平衡，避免模型過度偏向出現頻率高的類別",
      "D": "對訓練資料施加額外正則化或噪音，使模型在學習過程中對偏見敏感度降低",
      "Ans": "C",
      "exp": "詳細說明：* 資料去偏最直接有效的方法是從數據源頭著手，透過調整訓練語料的平衡性，以防止模型從帶有偏見的數據分佈中學習到不公平的模式。"
    },
    {
      "id": "26",
      "content": "在深度學習模型的微調（Fine-tuning）過程中，可能出現所謂的「災難性遺忘（Catastrophic Forgetting）」。此現象最可能造成哪種情況？",
      "A": "由於計算資源或訓練步驟不足，模型在微調過程中無法完整收斂，導致學習效果受限",
      "B": "微調後模型的表現變得隨機，無法有效記憶新學到的模式與知識",
      "C": "微調後模型的部分權重產生偏移，導致模型無法針對較長的文字進行回應",
      "D": "模型過度適應微調的資料分佈，逐漸遺忘先前預訓練所獲得的廣泛知識，在原有任務或廣泛領域上表現變差",
      "Ans": "D",
      "exp": "詳細說明：* 災難性遺忘是指模型在學習新任務時，會破壞或忘記在舊任務（即原始預訓練）中學到的知識，導致通用能力下降。"
    },
    {
      "id": "27",
      "content": "在大型 Transformer 模型的效能優化過程中，常見的方法之一是「剪枝（Pruning）」。下列哪一項最符合該方法的核心概念？",
      "A": "將模型中所有權重按比例縮小，使其值更接近零，以降低計算量",
      "B": "移除模型中影響較小或冗餘的部分權重參數，以減少模型大小並提升推理效率",
      "C": "在訓練時僅更新部分權重而將其他權重凍結，從而減少需要調整的參數數量",
      "D": "根據注意力分數動態跳過處理部分輸入 Token，以減少每次前向傳播的計算",
      "Ans": "B",
      "exp": "詳細說明：* 剪枝的核心是識別並移除對模型輸出貢獻度低的冗餘權重，從而降低模型的複雜度和大小。"
    },
    {
      "id": "28",
      "content": "對非常長的輸入序列進行推理（Inference），Transformer 模型推理的主要計算瓶頸通常是什麼？",
      "A": "模型輸出層產生文本的過程，因為每生成一個詞都必須重新訓練整個模型一次",
      "B": "詞嵌入 (Embedding) 查找操作，因為其時間複雜度隨詞彙表大小指數級增長",
      "C": "Softmax 函數的計算，因為對每個 Token 都需要執行繁重的運算",
      "D": "自注意力層的計算和其記憶體使用，因為注意力矩陣的大小隨序列長度呈平方級增長",
      "Ans": "D",
      "exp": "詳細說明：* 自注意力層的計算複雜度是 O(L2)（L 為序列長度），在長序列輸入時，這種平方級的增長會成為最主要的計算瓶頸。"
    },
    {
      "id": "29",
      "content": "在「可解釋人工智慧（Explainable AI, XAI）」領域中，LIME（Local Interpretable Model-agnostic Explanations）方法最核心的應用目的是什麼？",
      "A": "解釋單一樣本（局部預測） 的黑箱模型決策過程",
      "B": "全面提升黑箱模型整體的預測準確度",
      "C": "將黑箱模型轉換成完全可解釋的模型作為替代",
      "D": "用於生成大量擬真數據來替代訓練集",
      "Ans": "A",
      "exp": "詳細說明：* LIME (Local Interpretable Model-agnostic Explanations) 專門用於解釋單一預測的依據，是局部且模型無關的解釋方法。"
    },
    {
      "id": "30",
      "content": "在醫療診斷決策支援系統等高風險領域中，「可解釋人工智慧（Explainable AI, XAI）」的核心價值最主要呈現在哪個面向？",
      "A": "透過提供可理解的決策依據，促進患者與醫療專業人員對系統診斷結果的信任與接受度",
      "B": "以可解釋性方法優化臨床資料蒐集與管理流程，從而降低整體醫療作業成本",
      "C": "利用解釋機制增強模型預測的統計顯著性與準確度，使其在研究及實務應用中更具科學性",
      "D": "透過提供透明化的運作過程，進而減輕臨床人員負擔，並提升醫療服務的整體效率",
      "Ans": "A",
      "exp": "詳細說明：* 在高風險領域，信任是 AI 導入的基石。XAI 提供決策依據，有助於專業人員驗證結果並建立對系統的信任。"
    },
    {
      "id": "31",
      "content": "在金融科技公司的信貸決策系統中，導入反事實解釋（Counterfactual Explanation）時，實際部署往往伴隨技術與監管挑戰。下列哪一項最符合該情境下的核心挑戰？",
      "A": "需要建立完整的客戶行為預測模型來估算建議改變的實施成本，並整合到現有的風險管理系統架構中",
      "B": "必須使用聯邦學習技術保護客戶隱私，同時在分散式環境中計算跨機構的反事實解釋結果",
      "C": "需要建構時間序列因果圖來處理客戶信用狀況的動態變化，並預測未來可能的信用評分軌跡",
      "D": "生成的反事實樣本必須滿足特徵間的因果約束和業務邏輯約束，同時確保建議的改變在現實中具有可操作性且符合公平放貸法規",
      "Ans": "D",
      "exp": "詳細說明：* 反事實解釋的挑戰在於，生成的改變建議必須是可行且符合現實約束和法規要求，才能真正幫助使用者並滿足監管要求。"
    },
    {
      "id": "32",
      "content": "在統計推論中，若樣本來自母體但呈現明顯偏態分布，且樣本數有限，下列哪一項策略最能減少推估母體參數的偏誤？",
      "A": "直接使用樣本平均數與變異數估計母體參數，不做任何調整",
      "B": "增加樣本數並考慮使用分位數或中位數作為中心趨勢估計",
      "C": "將樣本隨機重新排列後，多次計算平均值以消除偏態影響",
      "D": "完全依賴樣本標準差來估計母體參數，忽略分布形態",
      "Ans": "B",
      "exp": "詳細說明：* 偏態分佈下，中位數對極端值較穩健，是更可靠的中心趨勢估計。同時，增加樣本數能提高估計穩定性。"
    },
    {
      "id": "33",
      "content": "在工業物聯網架構中，進行設備預測性維護（Predictive Maintenance）時，若面對異常事件發生頻率極低、樣本高度不平衡的時間序列資料，下列哪一種方法最能兼顧模型穩定性與異常偵測效能？",
      "A": "將每筆異常事件資料複製多次以提升模型對異常的辨識敏感度，搭配全序列訓練模型（如 LSTM）",
      "B": "對時間序列進行差分與標準化後，使用傳統監督式學習模型（如 SVM）進行分類訓練",
      "C": "使用經過時間序列特化的 SMOTE 技術生成異常樣本，以平衡異常與正常資料比例",
      "D": "採用基於重建誤差的自編碼器模型（Sequence-to-Sequence Autoencoder）進行異常偵測，並僅使用正常資料進行訓練",
      "Ans": "D",
      "exp": "詳細說明：* 自編碼器只用正常資料訓練，遇到異常時會產生高重建誤差，這是處理高度不平衡異常偵測問題的標準且有效方法。"
    },
    {
      "id": "34",
      "content": "在零售業進行客戶行為分析時，資料倉儲中發現多個欄位儲存相同的購買金額資訊（例如：amount_usd、total_price、transaction_value），但其單位、命名慣例及格式不一致，進而導致特徵工程階段混淆模型輸入。針對此種跨欄位語義重疊與結構冗餘問題，下列哪一種資料處理策略最合適且具實務可行性？",
      "A": "利用資料探勘技術自動選擇資料集中對目標變數最敏感的欄位，其他欄位捨棄即可，避免過度清理干擾原始結構",
      "B": "保留所有相似欄位，交由高階模型（如 Gradient Boosting 或 Deep Learning）自動學習特徵關聯，無需手動處理",
      "C": "建立欄位命名標準，統一金額單位與格式，進行欄位正規化與語義合併，減少重複資訊影響特徵重要性估計",
      "D": "將重複欄位視為類別欄位，進行 One-hot 編碼（One-hot encoding）後輸入模型，以避免數值誤導模型學習過程",
      "Ans": "C",
      "exp": "詳細說明：* 解決「語義重疊與結構冗餘」最直接的方法是透過正規化和合併，確保相同意義的特徵只有單一、乾淨的表示。"
    },
    {
      "id": "35",
      "content": "某大型零售企業準備將商品推薦模型上線，專案團隊在檢視訓練資料時，發現部分商品類別（例如高價商品）樣本數量極少，而多數樣本集中於低價商品。若此不平衡問題未妥善處理，下列何種狀況最可能在實際推薦結果中發生？",
      "A": "模型在預測時傾向輸出稀有類別，導致雖能捕捉到少數樣本，但精確率（Precision）顯著下降",
      "B": "模型由於類別分布不均，難以建立有效的線性分離邊界，進而無法收斂",
      "C": "模型過度聚焦於稀有類別樣本，導致對多數類別的預測能力下降，整體效能受損",
      "D": "模型學到的決策邊界主要由多數類別主導，忽視了稀有類別，造成該類別的召回率（Recall）大幅降低",
      "Ans": "D",
      "exp": "詳細說明：* 在類別不平衡中，模型為最大化整體準確度會傾向於預測多數類，導致對少數類的召回率 (Recall) 大幅降低。"
    },
    {
      "id": "36",
      "content": "某電商資料團隊要協助行銷部門規劃再行銷策略。目前取得資料包含使用者點擊、購買紀錄、流量來源與轉換率。若資料團隊希望先進行探索性資料分析（EDA），下列哪一項最符合 EDA 的做法？",
      "A": "建立隨機森林模型，預測使用者是否會完成購買",
      "B": "使用 K-means 對使用者群進行分群並立即制定對應促銷策略",
      "C": "繪製各類流量來源對轉換率的關聯圖，尋找潛在關係",
      "D": "對不同購物路徑設定統計假設並進行雙樣本 t 檢定",
      "Ans": "C",
      "exp": "詳細說明：* 探索性資料分析 (EDA) 核心目標是理解數據的特性、分佈、找出潛在的模式和關係，通常透過視覺化來實現。"
    },
    {
      "id": "37",
      "content": "某金融科技公司在利用歷史交易資料建立風險控管模型時，嘗試推估整體詐騙交易比例。近期發現，樣本間存在明顯的時間序列相關性，導致模型在實際偵測新交易時誤判率升高。若希望同時改善詐騙比例推估的準確性並提升模型的穩健性，下列哪一種做法最為合適？",
      "A": "擴充樣本數量，以涵蓋更多潛在的詐騙型態，但維持既有的隨機抽樣方式不變",
      "B": "採取時間序列敏感的抽樣策略，例如依據交易時間區間進行分層，以保存原始的時間結構特性",
      "C": "將資料完全隨機打散，以降低序列相關性對模型訓練造成的影響",
      "D": "在模型評估時，針對相鄰時間區段進行誤差合併，以便用整體估計方式修正詐騙比例",
      "Ans": "B",
      "exp": "詳細說明：* 針對時間序列數據，應採取時間敏感的抽樣策略，以保留數據的時序結構特性，從而提升模型在未來數據上的預測穩健性。"
    },
    {
      "id": "38",
      "content": "某公司建置基於檢索增強生成（RAG） 的知識查詢系統，需同時兼顧查詢效能與資料的即時更新。近期發現回應內容偶爾過時，且每次更新文件都需完整重建索引，導致系統在更新期間無法服務。若要解決此問題並提升整體穩健性，下列哪項做法最適合？",
      "A": "調整生成模型的回應隨機性參數，以降低答案偏差並提升一致性",
      "B": "提升檢索與索引的運算效能，以縮短查詢與更新所需時間",
      "C": "採用索引的增量或分段更新方式，使新資料能即時納入而不需全部重建",
      "D": "建立常見問題的標準答案集，透過快速檢索回應以降低模型負擔",
      "Ans": "C",
      "exp": "詳細說明：* 解決 RAG 系統中即時性和高可用性問題的標準工程實踐是採用增量或分段更新，避免完整重建索引導致服務中斷。"
    },
    {
      "id": "39",
      "content": "某醫院計畫開發住院日數預測模型，以協助病房調度。多數病人的住院日數集中在 3–7 天，但仍有少數重症患者因治療需求而住院日數明顯偏長。醫院希望採用一種合適的評估方式，既能兼顧大部分病人的預測準確度，也能確保對重症個案的預測維持穩健。下列哪一種方法最符合此需求？",
      "A": "在模型檢核時，同時呈現平均絕對誤差（MAE） 與重症子群的誤差指標",
      "B": "僅針對一般病人樣本進行交叉驗證，以避免重症個案拉高誤差",
      "C": "將所有病人的住院日數進行標準化處理，以減少數值範圍差異的影響",
      "D": "只採用單一的整體決定係數 (R2) 作為模型優劣的判斷依據",
      "Ans": "A",
      "exp": "詳細說明：* MAE 對極端值不敏感，能客觀反映一般病人誤差；單獨檢視重症子群誤差則確保了對關鍵少數樣本的關注。"
    },
    {
      "id": "40",
      "content": "關於監督式學習（Supervised Learning）與非監督式學習（Unsupervised Learning）的目標，下列敘述何者錯誤？1. 非監督式學習的核心在於發掘資料內在結構，例如分群、關聯規則與降維，而不依賴外部標籤。2. 監督式學習的典型應用為分類與迴歸，通常不適合應用於異常偵測任務。3. 非監督式學習若搭配少量標註資料，即會完全轉化為監督式學習。4. 監督式學習仰賴已標註的資料集，透過最小化輸出與真實標籤之間的差距，學習輸入與目標之間的對應函數。5. 所有監督式學習任務都必須要有大量完整標註資料，否則無法進行任何有效的模型訓練。6. 非監督式學習不需要目標變數，僅透過輸入資料本身的特徵分布進行模式學習。",
      "A": "3、5、6",
      "B": "1、4、6",
      "C": "2、4、6",
      "D": "2、3、5",
      "Ans": "D",
      "exp": "詳細說明：* 錯誤敘述： 2 (監督式學習可應用於異常偵測)、3 (搭配少量標註是半監督式學習)、5 (存在少次學習等方法，不一定需要大量標註)。"
    },
    {
      "id": "41",
      "content": "一家旅遊平台希望建立模型，預測顧客下次是否會再次透過該平台訂房。資料包含：顧客 ID、年齡、旅遊次數、平均花費金額、主要交通方式（火車/飛機/自駕/公車）、會員等級（普通/進階/白金）、是否為海外旅遊等。下列哪一種特徵工程方法最適合處理「主要交通方式」欄位？",
      "A": "布林轉換（Boolean Conversion）",
      "B": "序數編碼（Ordinal Encoding）",
      "C": "數值標準化（Numerical Standardization）",
      "D": "One-hot 編碼（One-hot Encoding）",
      "Ans": "D",
      "exp": "詳細說明：* 「主要交通方式」是無序類別變數（名目類別），應使用 One-hot 編碼將其轉換為模型可處理的二元特徵，以避免引入錯誤的順序關係。"
    },
    {
      "id": "42",
      "content": "一家跨國醫療研究機構希望利用各地醫院的病患資料，建立一個能夠預測疾病早期風險的機器學習模型。由於各國法規限制，病患的原始資料無法集中到單一伺服器。在此情境下，下列哪一種方法最能同時滿足「各醫院保留資料不外流」與「模型仍能跨院學習」的需求？",
      "A": "資料匿名化（Data Anonymization）",
      "B": "差分隱私（Differential Privacy）",
      "C": "聯邦學習（Federated Learning）",
      "D": "交叉驗證（Cross-validation）",
      "Ans": "C",
      "exp": "詳細說明：* 聯邦學習 (Federated Learning) 允許模型在本地數據上訓練，僅交換模型參數，從而滿足資料隱私與跨機構協作的需求。"
    },
    {
      "id": "43",
      "content": "某公司欲建立員工離職風險預測模型，資料集中包含「年度績效分數」、「平均每月加班時數」、「年齡」等數值型特徵。由於各特徵的數值範圍差異極大（例如績效分數 1–5、加班時數 0–80、年齡 20–65），若直接輸入至使用梯度下降的邏輯迴歸(Logistic Regression)模型，可能導致模型收斂緩慢或權重偏斜。為提升模型訓練效率與準確度，下列哪一種特徵工程方法最適合應用於這些數值特徵？",
      "A": "布林轉換（Boolean Conversion）",
      "B": "時間序列分解（Time Series Decomposition）",
      "C": "One-hot 編碼（One-hot Encoding）",
      "D": "數值標準化（Numerical Standardization）",
      "Ans": "D",
      "exp": "詳細說明：* 數值標準化（特徵縮放）是解決使用梯度下降的模型因特徵尺度差異大而導致收斂緩慢或不穩定的標準方法。"
    },
    {
      "id": "44",
      "content": "在機器學習中，「叢集（Clustering）」方法最典型的應用情境是下列何者？",
      "A": "根據歷史交易紀錄與已標註的詐欺案例，訓練模型來偵測未來的詐欺交易",
      "B": "使用醫療數據與病患的診斷標籤，建立模型以預測病人是否罹患特定疾病",
      "C": "根據顧客的消費行為與特徵，將顧客自動劃分為數個群組，以便進行差異化行銷",
      "D": "透過大量已標註影像，訓練深度學習模型來辨識照片中的物件種類",
      "Ans": "C",
      "exp": "詳細說明：* 叢集屬於非監督式學習，目的是在沒有標籤的情況下，根據數據本身的相似性將數據點劃分為不同的群組。"
    },
    {
      "id": "45",
      "content": "某醫院研究團隊蒐集了大量病患的「收縮壓」數據，經檢驗後顯示此數值大致呈現常態分布。在進行後續模型分析前，研究人員希望妥善處理可能存在的極端血壓數值。下列哪一種做法最為合適？",
      "A": "將所有極端偏高或偏低的血壓數據直接刪除，以保留最具代表性的病患樣本",
      "B": "使用對數轉換（Log Transformation），將數據壓縮至更接近常態，以降低極端值的影響",
      "C": "透過 Z 分數（Z-score） 或標準差範圍檢測異常值，並依研究需求決定是否調整或移除",
      "D": "將檢測到的離群值以 Label Encoding 編碼，轉換為序號標籤以避免影響原始分布",
      "Ans": "C",
      "exp": "詳細說明：* 在常態分佈數據中，Z 分數是標準的異常值檢測方法，並應依據領域知識謹慎決定後續處理方式。"
    },
    {
      "id": "46",
      "content": "某電商公司想預測用戶是否會購買特定商品，分析師希望選出對購買結果最有預測價值的特徵。下列哪一種描述最符合監督式特徵選擇 (Supervised Feature Selection) 的概念？",
      "A": "根據特徵的整體分布、變異度或資訊量進行篩選，而不直接參考目標變數",
      "B": "評估每個特徵與目標變數之間的相關性，選擇對預測結果貢獻最大的特徵",
      "C": "使用模型評估特徵對預測結果的重要性，並保留對目標變數影響較大的欄位",
      "D": "將特徵透過降維方法（如 PCA...）",
      "Ans": "B",
      "exp": "詳細說明：* 監督式特徵選擇：在選擇特徵時，會參考目標變數（即標籤）進行評估，例如計算相關性。"
    },
    {
      "id": "47",
      "content": "關於處理資料中的異常值 (Outliers)，下列敘述何者是不適當的作法？",
      "A": "隨機抽樣，確保極端值不會過度影響訓練集的代表性的病患樣本",
      "B": "使用對數轉換（Log Transformation），將數據壓縮至更接近常態，以降低極端值的影響",
      "C": "透過 Z 分數（Z-score）或標準差範圍檢測異常值，並依研究需求決定是否調整或移除",
      "D": "將檢測到的離群值以 Label Encoding 編碼，轉換為序號標籤以避免影響原始分布",
      "Ans": "D",
      "exp": "詳細說明：* Label Encoding 用於類別資料，不適用於數值型的離群值處理。"
    },
    {
      "id": "48",
      "content": "若希望檢視某一連續型數據的分布情形（如集中程度、偏態或是否呈現多峰），下列哪一種應用情境最適合使用直方圖（Histogram） 來進行分析？",
      "A": "探討顧客年齡資料的整體分布特徵，並檢視是否存在異常集中或分散現象",
      "B": "比較不同商品在各月份的銷售額變化趨勢，以觀察季節性波動",
      "C": "追蹤公司近一年營收的時間序列變化，以了解整體成長趨勢",
      "D": "檢視產品價格與月銷售量之間的關聯性，以評估是否具線性相關",
      "Ans": "A",
      "exp": "詳細說明：* 直方圖專門用於呈現單一數值變數的分佈頻率和形態。"
    },
    {
      "id": "49",
      "content": "下列何者並非我國數位發展部 AI 產品與評測中心在評估大型語言模型安全性時，所指出的常見使用指標？",
      "A": "資料複雜性",
      "B": "事實正確性",
      "C": "偏見與歧視",
      "D": "惡意與濫用可能性",
      "Ans": "A",
      "exp": "詳細說明：* LLM 安全性評估主要關注輸出內容對社會的潛在負面影響（事實正確性、偏見、惡意），資料複雜性屬於技術或數據品質層面。"
    },
    {
      "id": "50",
      "content": "某雲端服務公司計畫將大型語言模型部署於線上系統，並以批次推論（Batch Inference） 方式處理每日上百萬筆用戶請求。專案團隊在評估可能遇到的挑戰時，下列哪一項通常不會被視為批次推論階段的主要難題？",
      "A": "如何確保訓練語料的涵蓋性與標註品質，以避免模型偏差影響輸出",
      "B": "當批次規模增大時，如何降低推論延遲並保持即時回應能力",
      "C": "在推論過程中，有效管理與分配龐大的輸入資料量以避免資源壅塞",
      "D": "在叢集環境中精確安排推論任務，以提升 GPU/TPU 等硬體資源的利用率",
      "Ans": "A",
      "exp": "詳細說明：* 訓練語料的涵蓋性與標註品質是模型訓練階段的難題，批次推論階段主要關注部署後的效率、資源和延遲問題。"
    }
  ]
}