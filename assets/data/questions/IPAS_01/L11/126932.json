{
  "importDate": "2025-12-16",
  "source": "IPAS_01_AI_126932-阿摩線上測驗.xlsx",
  "questions": [
    {
      "id": "1",
      "content": "1 下列何者最適合訓練電腦下圍棋、自動駕駛等動態重複地互動的問題？",
      "A": "\"監督式學習 (Supervised Learning)\"",
      "B": "\"非監督式學習 (Unsupervised Learning)\"",
      "C": "半監督式學習 (Semi- supervised Learning)",
      "D": "強化學習 (Reinforcement Learning)",
      "Ans": "D",
      "exp": "強化學習（Reinforcement Learning）是透過代理人（Agent）與環境（Environment）持續進行動態、重複地互動，並根據環境給予的獎勵（Reward）或懲罰來學習最佳行動策略，這完全符合下圍棋、自動駕駛這類需要連續決策與環境回饋的問題的特性。 "
    },
    {
      "id": "2",
      "content": "2 關於 AI 的定義，下列敘述何者較為正確？",
      "A": "AI 僅限於深度學習技術",
      "B": "AI 包括各種技術，例如機器學習、專家系統等",
      "C": "AI 系統只能在學術研究中應用",
      "D": "AI 無法應用於金融領域",
      "Ans": "B",
      "exp": "人工智慧（AI）是一個廣泛的領域，涵蓋了模擬人類智慧的各種技術，例如機器學習（Machine Learning）、深度學習（Deep Learning）、專家系統（Expert Systems）、自然語言處理（NLP）等。選項 A 過於狹隘，選項 C 和 D 不符合現實應用。"
    },
    {
      "id": "3",
      "content": "3 為了提升 AI 系統的透明性，下列哪種措施是適當的？",
      "A": "不需對外揭露任何有關 AI系統的資訊",
      "B": "規劃透過發布報告、技術文件或網站揭露 AI 系統的相關資訊",
      "C": "僅對內部員工進行透明性說明",
      "D": "將所有 AI 系統資訊保密",
      "Ans": "B",
      "exp": "AI 系統的透明性（Transparency）要求對外公開（或對相關利益人公開）足夠的資訊，以便理解系統的運作方式、決策依據和潛在限制。發布報告、技術文件或網站是實踐透明性的常見且適當的方式。"
    },
    {
      "id": "4",
      "content": "4 下列何者不適合做為資料分布估計？",
      "A": "直方圖 (圖源：Wikipedia...",
      "B": "散布圖（Scatter plot） ✅適合",
      "C": "\"雷達圖 (Radar chart)\"",
      "D": "\"四分位數 (Quartile)\"",
      "Ans": "C",
      "exp": "資料分布估計（Data Distribution Estimation）主要是為了理解單一變數或多變數之間的數值分佈和集中趨勢：* 直方圖：用於顯示單一連續變數的頻率分佈。* 四分位數：是描述資料分佈和分散程度的統計量。* 散布圖：用於顯示兩個變數之間的關係和聯合分佈。* 雷達圖：主要用於多個類別或項目在多個定量特徵上的表現比較，例如評分或績效，其圓形結構本身不利於準確判斷資料的數值分佈趨勢，因此不適合用於傳統的資料分布估計。"
    },
    {
      "id": "5",
      "content": "5 \"K-Means 聚類算法中，K 代表什麼？\"",
      "A": "數據集中特徵的數量",
      "B": "數據集中樣本的數量",
      "C": "所需劃分的群組數量",
      "D": "迭代次數",
      "Ans": "C",
      "exp": "K-Means 演算法是一種非監督式學習的聚類方法，其中 K 是使用者事先指定的超參數，代表想要將資料集劃分為的群組（Cluster）數量。"
    },
    {
      "id": "6",
      "content": "6 深度學習模型中，下列哪一項通常用來降低過擬合問題？",
      "A": "增加訓練數據量 ✅ 也是可行的方法，但不是「模型內部」降低過擬合的主要機制，",
      "B": "增加模型的複雜度 ❌",
      "C": "增加學習率 ❌",
      "D": "增加正則化項 ✅",
      "Ans": "D",
      "exp": "過擬合（Overfitting）是指模型在訓練數據上表現很好，但在新數據上表現差。正則化項（Regularization Term）是添加到損失函數中的一個懲罰項，用於約束模型權重的大小，從而降低模型的複雜度和對訓練數據中雜訊的依賴，有效減少過擬合。增加模型複雜度（B）會加劇過擬合；增加學習率（C）主要影響訓練收斂速度，與過擬合無直接關聯。"
    },
    {
      "id": "7",
      "content": "7 生成式人工智慧最核心的能力是什麼？",
      "A": "從大量數據中學習",
      "B": "執行複雜的數學計算",
      "C": "生成新的、原創的內容",
      "D": "控制機器人",
      "Ans": "C",
      "exp": "生成式人工智慧（Generative AI）的核心能力在於學習數據的底層分佈，並利用這個分佈生成與訓練數據相似但全新的、原創的內容，例如圖像、文本、音頻等。"
    },
    {
      "id": "8",
      "content": "8 下列哪項技術是生成式 AI 發展的重要基礎？",
      "A": "決策樹",
      "B": "神經網路",
      "C": "線性迴歸",
      "D": "貝氏分類",
      "Ans": "B",
      "exp": "現代生成式 AI（如 GANs、VAEs、Transformers）幾乎都基於深度學習，而神經網路（Neural Networks，特別是深度神經網路）是深度學習的核心架構。選項 A、C、D 雖然是機器學習技術，但不是現代生成式 AI 的基礎。"
    },
    {
      "id": "9",
      "content": "9 關於 AI，下列敘述何者較為正確？",
      "A": "AI 僅限於深度學習技術",
      "B": "AI 包括各種技術，例如機器學習、專家系統等",
      "C": "AI 系統只能在學術研究中應用",
      "D": "AI 無法應用於金融領域",
      "Ans": "B",
      "exp": "人工智慧（AI）是一個廣泛的領域，涵蓋了模擬人類智慧的各種技術，例如機器學習（Machine Learning）、深度學習（Deep Learning）、專家系統（Expert Systems）、自然語言處理（NLP）等。選項 A 過於狹隘，選項 C 和 D 不符合現實應用。"
    },
    {
      "id": "10",
      "content": "10 在 AI 治理中，下列何者是國際合作的重要性？",
      "A": "統一 AI 發展標準",
      "B": "避免 AI 技術的濫用",
      "C": "促進 AI 技術的轉移",
      "D": "以上皆是",
      "Ans": "D",
      "exp": "AI 治理（AI Governance）的國際合作對於應對 AI 帶來的全球性挑戰至關重要。這包括制定共同的倫理和安全標準（A）、防止惡意使用（B）、以及確保技術的普惠共享和轉移（C），因此以上皆是正確選項。"
    },
    {
      "id": "11",
      "content": "11 關於 K 平均法(K- means)，下列敘述何者「不」正確？",
      "A": "希望找出 k 個互不交集的群集...",
      "B": "不同的起始群集中心，可能會造成不同的分群結果",
      "C": "\"容易受雜訊與離群值",
      "D": "可以處理類別型資料",
      "Ans": "D",
      "exp": "K-Means 演算法的基礎是計算資料點之間的歐幾里得距離，這需要數值型資料。它無法直接處理類別型（Categorical）資料，除非先將類別型資料轉換為數值表示（例如 One-Hot Encoding）。因此，敘述 D 是不正確的。"
    },
    {
      "id": "12",
      "content": "12 在品質管理中，若一產品的生產過程中標準差顯著偏大，通常意味著什麼？",
      "A": "資料點高度集中，產品質量穩定",
      "B": "生產過程波動大，產品品質不穩定",
      "C": "資料無法反映產品實際狀況",
      "D": "中位數數值高，品質良率較高",
      "Ans": "B",
      "exp": "標準差（Standard Deviation, sigma）是用來衡量資料點相對於平均數的分散程度。標準差顯著偏大，表示資料點（例如產品的尺寸、重量等品質指標）離平均值的距離較遠，說明生產過程中波動性大，導致產品品質的穩定性差。"
    },
    {
      "id": "13",
      "content": "13 下列何者「並非」K 平均數(k-means)集群法的特點？",
      "A": "原理相對其他集群法較為複雜 ❌（錯誤）",
      "B": "可結合其他方法，使用上較為彈性 ✅",
      "C": "在特定情況下，能將集群的任務處理得足夠好 ✅",
      "D": "不適合非球形、數據密度變化大或有離群數據的集群問題 ✅",
      "Ans": "A",
      "exp": "K 平均數演算法（K-Means）的原理是透過迭代計算群集中心（Centroid）並重新分配資料點到最近的中心，直到收斂。相較於 DBSCAN 或階層式聚類（Hierarchical Clustering）等其他聚類方法，K-Means 的原理相對簡單且容易實現，因此選項 A「原理相對其他集群法較為複雜」是不正確的特點。"
    },
    {
      "id": "14",
      "content": "14 \"驗證性資料分析(Confirmatory Data Analysis, CDA)與探索性資料分析 (Exploratory Data Analysis, EDA)相比，主要著重於下列哪一項？\"",
      "A": "對資料進行初步描述和視覺化",
      "B": "驗證先前生成的假設並進行深入挖掘",
      "C": "排除資料中的極端值以提高準確性",
      "D": "探索數據中潛在的模式和異常",
      "Ans": "B",
      "exp": "探索性資料分析（EDA）主要著重於初步描述、視覺化和發現數據中的潛在模式和異常（選項 A, D）。而驗證性資料分析（CDA）則主要著重於使用統計學方法來檢驗或驗證研究人員根據先前知識或 EDA 結果所建立的特定假設（Hypothesis），進行更深入、有針對性的挖掘和確認。"
    },
    {
      "id": "15",
      "content": "15 以下哪種情況下，使用中位數來描述資料的集中趨勢最為合適？",
      "A": "一組考試成績，大部分學生分數集中在 80 分左右",
      "B": "一組房屋價格數據，其中包含少數豪宅的極端高價",
      "C": "一組產品銷售量數據，每個產品的銷量差異不大",
      "D": "一組學生身高數據，呈現出常態分布",
      "Ans": "B",
      "exp": "中位數（Median）是排序後位於數據中心點的值，它的一個主要優勢是不受極端值（Outliers）的顯著影響。在房屋價格數據中，少數豪宅的極端高價會將平均數（Mean）顯著拉高，使其不能很好地代表典型價格，此時中位數能更穩定、更合適地描述資料的集中趨勢。"
    },
    {
      "id": "16",
      "content": "16 一組數據中，如果平均數小於中位數，那麼這組數據的分布可能是下列哪一種?",
      "A": "對稱分布",
      "B": "正偏態分布",
      "C": "負偏態分布",
      "D": "無法判斷",
      "Ans": "C",
      "exp": "在統計學中，資料分佈與集中趨勢指標的關係如下：\n* 對稱分布（Symmetric）：平均數 約等於 中位數 約等於 眾數\n* 正偏態分布（Right Skewed）：平均數 > 中位數 > 眾數（分佈尾巴在右側，被極高值拉高負偏態分布（Left Skewed）：平均數 < 中位數 < 眾數（分佈尾巴在左側，被極低值拉低 當平均數小於中位數時，表示數據有向左延伸的尾巴，屬於負偏態分布。"
    },
    {
      "id": "17",
      "content": "17 當我們進行一次假設檢定，得到的 p 值為 0.03，顯著性水準設定為 0.05，以下哪一個敘述是正確的？",
      "A": "我們有 97%的信心拒絕虛無假設",
      "B": "我們有 95%的信心水準下拒絕虛無假設",
      "C": "我們無法拒絕虛無假設",
      "D": "我們犯型一錯誤的機率有 5%",
      "Ans": "B",
      "exp": "假設檢定原則：當 p 值 <= 顯著性水準（alpha）時，我們拒絕虛無假設（H0）。在此例中，p 值 = 0.03 且 alpha = 0.05，0.03 <= 0.05，因此我們應拒絕 H0。顯著性水準 alpha = 0.05 意味著信心水準（Confidence Level）為 1 - alpha = 1 - 0.05 = 0.95（95%）。因此，在 95% 的信心水準下，我們有足夠的證據拒絕虛無假設。"
    },
    {
      "id": "18",
      "content": "18 一組資料中，若平均數大於中位數，則這組資料的分布可能是下列哪一種？",
      "A": "對稱分布",
      "B": "負偏態分布",
      "C": "正偏態分布",
      "D": "無法判斷",
      "Ans": "C",
      "exp": "在統計學中，當平均數（Mean）大於中位數（Median）時，表示資料中存在一些極高的值（Outliers）將平均數向右側拉動，使得分佈的尾巴向右延伸，這被稱為正偏態分布（Right Skewed Distribution）。"
    },
    {
      "id": "19",
      "content": "19 下列哪一個敘述關於四分位距(IQR)是正確的？",
      "A": "四分位距會受到極端值的影響",
      "B": "四分位距代表資料中所有數據的分散程度",
      "C": "四分位距是第三四分位數與第一四分位數的差",
      "D": "四分位距與平均數一樣，容易受到極端值影響",
      "Ans": "C",
      "exp": "四分位距（Interquartile Range, IQR）的定義是第三四分位數（Q3）與第一四分位數（Q1）之間的差值，即 IQR = Q3 - Q1。它代表了數據中中間 50% 資料的分散程度。因為它不考慮極端值（Q1 以下和 Q3 以上的數據），所以不易受極端值影響（選項 A 和 D 錯誤）。"
    },
    {
      "id": "20",
      "content": "20 以下哪一種情況最適合用眾數來描述資料的集中趨勢？",
      "A": "一組學生身高資料，呈現出常態分布",
      "B": "一組產品銷售量資料，其中一種產品的銷量遠高於其他產品",
      "C": "\"一組考試成績資料，大部分學生的分數集中在80 分左右\"",
      "D": "一組房屋價格資料，其中包含少數豪宅的極端高價",
      "Ans": "B",
      "exp": "眾數（Mode）是資料集中出現頻率最高的值。當資料是類別型或當某個數值（或數值範圍）明顯地比其他數值更頻繁出現（即有明顯的高峰）時，眾數最適合用來描述集中趨勢。選項 B 中，一種產品的銷量遠高於其他產品，表示這個銷量（或其對應的類別）是出現最頻繁或最具有代表性，因此最適合用眾數來描述。選項 A, C, D 則多以平均數或中位數更合適。"
    },
    {
      "id": "21",
      "content": "21 機器學習的三個核心要素是什麼？",
      "A": "數據、模型、損失函數",
      "B": "訓練集、測試集、驗證集",
      "C": "特徵工程、優化演算法、正則化",
      "D": "超參數調整、模型選擇、數據處理",
      "Ans": "A",
      "exp": "機器學習（Machine Learning）的三個核心要素是：1. 數據（Data）：訓練模型所需的輸入資訊，是學習的基礎。2. 模型（Model）：用於表示和處理數據、從數據中學習規律的演算法架構（如線性迴歸、神經網路）。3. 損失函數（Loss Function）/目標函數（Objective Function）：用於衡量模型預測結果與真實值之間的誤差，是模型優化（最小化誤差）的目標。選項 B、C、D 雖然與機器學習過程相關，但不是構成學習過程本身的核心要素。"
    },
    {
      "id": "22",
      "content": "22 下列哪一項屬於監督式學習的特點？",
      "A": "數據集中包含標記訊息",
      "B": "僅需探索數據內部的結構：這是非監督式學習的特點，該方法不依賴於標記數據。",
      "C": "使用代理與環境互動進行學習：這是強化學習的特點，強調與環境的互動。",
      "D": "不需要驗證集來調整參數：雖然有些模型可以在沒有驗證集的情況下進行訓練，但監督式學習通常會使用驗證集來調整模型參數，以提高模型的性能。",
      "Ans": "A",
      "exp": "監督式學習（Supervised Learning）的定義是從帶有標記（Labelled）的訓練數據中學習一個函數，將輸入映射到輸出。因此，數據集中包含標記訊息（即已知的正確答案）是其最核心的特點。"
    },
    {
      "id": "23",
      "content": "23 機器學習模型過擬合的主要原因是什麼？",
      "A": "模型的複雜度不足",
      "B": "訓練數據樣本過多",
      "C": "模型過度學習數據中的雜訊",
      "D": "使用過於簡單的損失函數",
      "Ans": "C",
      "exp": "過擬合（Overfitting）發生在模型過於複雜（模型複雜度高於數據複雜度）且訓練時間過長時，導致模型不僅學習了數據中的真實規律，還學習了數據中的隨機誤差（雜訊）。結果是模型在訓練集上表現極佳，但在未見過的新數據（測試集）上表現很差。選項 A 是欠擬合（Underfitting）的原因。"
    },
    {
      "id": "24",
      "content": "24 交叉驗證的主要目的是什麼？",
      "A": "提高模型的訓練速度",
      "B": "驗證數據是否線性可分",
      "C": "減少模型的過擬合風險",
      "D": "測試模型的容錯能力",
      "Ans": "C",
      "exp": "交叉驗證（Cross-Validation）是一種統計學技巧，通過將數據集劃分為多個子集（例如 K-Fold），輪流使用不同子集進行訓練和驗證，以評估模型性能。其主要目的是更可靠地評估模型在新數據上的泛化能力，從而減少模型在特定單一訓練集上產生的過擬合風險，使模型更穩定。"
    },
    {
      "id": "25",
      "content": "25 機器學習的梯度下降演算法主要用於什 麼？",
      "A": "減少模型的計算複雜度：這不是梯度下降的主要目的。",
      "B": "優化模型參數以最小化損失函數",
      "C": "減少數據中的雜訊干擾：這通常涉及數據清理和預處理，而非梯度下降。",
      "D": "增強數據特徵的表示能力：這通常是通過特徵工程或使用更複雜的模型來實現的，而不是通過梯度下降。",
      "Ans": "B",
      "exp": "梯度下降（Gradient Descent）是一種優化演算法。它的核心作用是透過計算損失函數對模型參數（權重和偏差）的梯度（即斜率），然後沿著梯度負方向（下降方向）調整參數，以最小化損失函數，直到模型收斂。"
    },
    {
      "id": "26",
      "content": "26 線性迴歸模型最適合解決哪種類型的問 題？",
      "A": "圖像分類",
      "B": "銷售額預測",
      "C": "聚類分析",
      "D": "遊戲策略學習",
      "Ans": "B",
      "exp": "線性迴歸（Linear Regression）是一種監督式學習的迴歸模型，其目標是預測一個連續型的數值輸出（例如房價、溫度、銷售額等），因此最適合解決銷售額預測這類連續數值預測問題。選項 A 是分類問題，選項 C 是非監督式學習，選項 D 是強化學習。"
    },
    {
      "id": "27",
      "content": "27 決策樹的最大優勢是什麼？",
      "A": "適合大規模數據的訓練: 雖然...",
      "B": "具有良好的可解釋性",
      "C": "不需要進行數據標準化",
      "D": "適用於圖像生成任務",
      "Ans": "B",
      "exp": "決策樹（Decision Tree）是一種白箱模型，其決策路徑可以清晰地以樹狀圖呈現和理解（例如：'如果年齡 > 30 且收入 > 5 萬，則分類為高風險'），因此其最大的優勢是具有良好的可解釋性（Interpretability）。"
    },
    {
      "id": "28",
      "content": "28 神經網路與傳統機器學習模型的主要區別是什麼？",
      "A": "神經網路無法處理非線性數據",
      "B": "神經網路透過多層結構學習複雜特徵",
      "C": "神經網路只適用於迴歸問題",
      "D": "神經網路不需要大量數據支持",
      "Ans": "B",
      "exp": "神經網路（Neural Network，特別是深度神經網路）的核心特點是其多層結構（深層結構）。這種結構能夠自動從原始輸入數據中逐層學習和提取複雜、抽象的特徵表示，這使得它能處理更複雜的非線性問題（與選項 A 相反），這是傳統機器學習模型（如線性迴歸、SVM）難以比擬的。"
    },
    {
      "id": "29",
      "content": "29 下列關於生成對抗網路(GAN)的描述正確的是哪一項？",
      "A": "GAN 不僅用於分類，主要用於生成資料（如圖像、音頻、文字等）。",
      "B": "GAN 的核心由生成器（Generator）與鑑別器（Discriminator）組成，透過對抗訓練互相提升能力。",
      "C": "GAN 的結果通常缺乏可解釋性，屬於黑箱模型。",
      "D": "現代的 GAN（如 StyleGAN、BigGAN）能生成非常高品質的資料。",
      "Ans": "B",
      "exp": "生成對抗網路（GAN）由兩個主要的深度神經網路組成：1. 生成器（Generator）：負責生成新的數據樣本。2. 鑑別器（Discriminator）：負責判斷輸入的數據是真實的（Real）還是生成器偽造的（Fake）。兩者透過對抗過程（Adversarial Process）進行訓練，生成器試圖騙過鑑別器，鑑別器則試圖更精準地識別偽造品，從而互相提升。"
    },
    {
      "id": "30",
      "content": "30 隨機森林(Random Forest)改進了單一決策樹的缺陷，主要透過什麼方法實現？",
      "A": "使用核函數映射高維空間",
      "B": "集成多棵隨機生成的決策樹並投票",
      "C": "增加模型參數以減少偏差",
      "D": "採用生成模型替代分類器",
      "Ans": "B",
      "exp": "隨機森林（Random Forest）是一種集成學習（Ensemble Learning）方法。它通過構建多棵（Forest）獨立訓練的決策樹，每棵樹在訓練時引入隨機性（Random），然後將所有樹的預測結果進行集成（例如投票或平均），以獲得最終預測。這能有效地減少單一決策樹容易出現的過擬合問題和高方差（Variance）。"
    },
    {
      "id": "31",
      "content": "31 \"下列何者為鑑別式 AI",
      "A": "學習數據的生成過程",
      "B": "生成類似真實數據的新樣本",
      "C": "分類或迴歸數據",
      "D": "創建多樣化的數據分佈",
      "Ans": "C",
      "exp": "鑑別式 AI（Discriminative AI）專注於學習條件機率 P(y|x)，即給定輸入 x，預測輸出 y 的機率。其主要任務是區分或預測不同類別或數值，因此是用於分類（Classification）或迴歸（Regression）數據。選項 A、B、D 都是生成式 AI（Generative AI）的特點。"
    },
    {
      "id": "32",
      "content": "32 \"下列何者屬於生成式 AI 使用之模型？\"",
      "A": "\"支援向量機 (SVM)\"",
      "B": "\"邏輯迴歸 (Logistic Regression)\"",
      "C": "生成對抗網路(GAN)",
      "D": "\"隨機森林 (Random Forest)\"",
      "Ans": "C",
      "exp": "生成式 AI 模型的主要目的是生成新的數據。生成對抗網路（GAN）就是一種最著名的生成式模型。選項 A、B、D 都是鑑別式模型，主要用於分類或迴歸。"
    },
    {
      "id": "33",
      "content": "33 關於目前生成式 AI 的主要應用，不包括下列哪一項？",
      "A": "創建合成數據樣本",
      "B": "模擬數據分佈",
      "C": "分類醫學影像",
      "D": "生成文本",
      "Ans": "C",
      "exp": "生成式 AI 專注於生成新的內容，例如文本（D）、圖像、音頻，以及學習數據的底層結構來創建合成數據樣本（A）和模擬數據分佈（B）。分類（Classification）醫學影像屬於鑑別式 AI 的任務，目的是區分或識別圖像中的病理特徵，而不是生成新的影像。"
    },
    {
      "id": "34",
      "content": "34 生成對抗網路(GAN)的兩個核心組件是什麼？",
      "A": "編碼器與解碼器：這通常與自編碼器 (Autoencoder) 相關。",
      "B": "分類器與生成器：這不是 GAN 的核心組件。",
      "C": "生成器與鑑別器",
      "D": "訓練器與推斷器：這些術語不特指 GAN 的組件。",
      "Ans": "C",
      "exp": "生成對抗網路（GAN）的核心在於其對抗訓練機制，它由一個生成器（Generator）和一個鑑別器（Discriminator）組成。生成器負責生成數據，鑑別器負責判斷數據真偽。"
    },
    {
      "id": "35",
      "content": "35 關於鑑別式 AI，下列敘述何者較為正確？",
      "A": "\"學習數據的聯合概率 P (x,y)\"",
      "B": "專注於數據的分類或迴歸任務",
      "C": "主要用於生成新數據",
      "D": "適合處理無標記數據",
      "Ans": "B",
      "exp": "鑑別式 AI（Discriminative AI）的核心是學習條件機率 P(y|x)，目的是對給定的輸入 x 進行分類（Classification）或迴歸（Regression），即區分數據之間的差異。選項 A（學習聯合概率 P(x,y)）和 C（生成新數據）是生成式 AI 的特點。選項 D（處理無標記數據）是非監督式學習的特點。"
    },
    {
      "id": "36",
      "content": "36 在醫學影像中，生成式 AI 和鑑別式 AI 的整合應用主要目的是什麼？",
      "A": "減少標記數據需求",
      "B": "自動生成診斷結論",
      "C": "提高診斷準確性和數據多樣性",
      "D": "完全取代醫生的判斷",
      "Ans": "C",
      "exp": "在醫學影像應用中，鑑別式 AI（如 CNN）負責診斷（分類/識別）；而生成式 AI（如 GAN）可以生成逼真的合成影像（數據增強）。兩者整合的目的在於：* 生成式 AI 增加數據多樣性，擴充有限的醫學影像數據集，同時解決資料不平衡問題。* 藉由更多的訓練數據，提升鑑別式模型的魯棒性和診斷準確性，為醫生提供更可靠的輔助診斷。"
    },
    {
      "id": "37",
      "content": "37 下列哪項是生成式 AI 支援鑑別式 AI 的典型案例？",
      "A": "模擬交通場景以訓練自動駕駛模型",
      "B": "使用 CNN 對腫瘤分類",
      "C": "使用 SVM 分析風險",
      "D": "創建更好的分類演算法",
      "Ans": "A",
      "exp": "生成式 AI 支援鑑別式 AI 的典型案例是利用生成模型來生成合成數據（Synthetic Data），以擴充訓練數據集，從而訓練鑑別式模型（如分類器、迴歸模型）。* 生成式 AI (模擬)：如使用 GAN 或模擬器模擬各種極端或稀有的交通場景（例如惡劣天氣、緊急情況）。* 鑑別式 AI (訓練)：將這些模擬數據納入訓練集，用於訓練自動駕駛車輛的決策模型（鑑別式模型），使其在現實中能更準確地識別和決策。選項 B 和 C 是純粹的鑑別式 AI 應用。"
    },
    {
      "id": "38",
      "content": "38 下列哪種方法能解決生成式模型的訓練不穩定性問題？",
      "A": "使用更大的數據集：雖然可以提高模型的表現，但不一定直接解決訓練不穩定性問題。",
      "B": "採用 Waserstein GAN (WGAN)",
      "C": "提高硬體效能：這可能加速訓練，但不會直接影響訓練的穩定性。",
      "D": "增加模型層數：增加模型的複雜度可能會引入更多的不穩定性，而不是解決問題。",
      "Ans": "B",
      "exp": "原始的生成對抗網路（GAN）訓練中存在梯度消失和模式崩潰等導致訓練不穩定的問題。Waserstein GAN（WGAN）是為了解決這些問題而提出的改進模型，它用 Wasserstein 距離（Earth Mover's Distance）取代了原始 GAN 的 JS 散度（Jensen-Shannon divergence）作為損失函數，顯著改善了訓練的穩定性與生成圖像的品質。"
    },
    {
      "id": "39",
      "content": "39 \"在整合應用中，生成式 AI 提供的數據增強主要解決了哪個問題？\"",
      "A": "模型過擬合",
      "B": "數據稀缺或不平衡",
      "C": "訓練過程的時間延遲",
      "D": "數據隱私問題",
      "Ans": "B",
      "exp": "生成式 AI 進行數據增強（Data Augmentation）是通過生成與真實數據相似的合成數據來擴充訓練集。這主要用於解決數據稀缺（Lack of Data）或數據類別不平衡（Data Imbalance）的問題（例如，醫學影像中某種罕見疾病的影像極少），從而改善鑑別式模型的訓練效果。"
    },
    {
      "id": "40",
      "content": "40 未來整合鑑別式 AI 和生成式 AI 的關鍵方向是什麼？",
      "A": "增加生成模型的參數數量",
      "B": "開發更高效的整合框架",
      "C": "減少對標記數據的依賴",
      "D": "將兩者獨立使用",
      "Ans": "B",
      "exp": "生成式 AI（生成數據或特徵）和鑑別式 AI（分類/決策）的整合可以實現許多強大功能，例如半監督學習、數據增強等。未來的關鍵發展方向是開發更高效、更魯棒（Robust）的整合框架，使兩種模型能夠在單一架構中協同工作，例如將生成模型作為輔助特徵提取器，或以統一的模型同時實現生成與判別任務，以達到更高的準確度和效率。"
    }
  ]
}