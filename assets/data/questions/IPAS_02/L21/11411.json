{
  "importDate": "2025-12-16",
  "source": "IPAS_02中級_L21人工智慧技術應用與規劃_11411.xlsx",
  "questions": [
    {
      "id": "1",
      "content": "某電商企業希望利用自然語言處理(NLP)技術,分析顧客在社群平台與商品評論中的文字內容,以即時掌握顧客對產品的滿意度變化。若採用情感分析(Sentiment Analysis)模型,其主要目的為何?",
      "A": "預測顧客使用的語言風格與語氣",
      "B": "判斷文本中所表達的情感傾向",
      "C": "將顧客留言自動翻譯成企業內部指定語言",
      "D": "產生顧客評論的自動化摘要內容",
      "Ans": "B",
      "exp": "情感分析（Sentiment Analysis）的核心目標是識別文本中的主觀信息並判斷其極性（如正面、負面、中性），即判斷文本所表達的情感傾向 。"
    },
    {
      "id": "2",
      "content": "某跨國金融科技公司導入Transformer 架構開發多語客服系統,以提升長篇金融文件的自動翻譯品質。下列何者為該模型能顯著改善翻譯準確度的主要原因?",
      "A": "透過自注意力機制(Self-Attention Mechanism) 捕捉長距離語境依賴關係",
      "B": "透過卷積運算(Convolution Operation)加速訓練過程",
      "C": "透過強化學習(Reinforcement Learning)自動調整語句生成策略",
      "D": "透過資料增強(Data Augmentation)平衡多語語料比例",
      "Ans": "A",
      "exp": "Transformer 架構的關鍵創新是自注意力機制 (Self-Attention Mechanism)，它允許模型在處理序列時，同時考慮序列中所有單詞的關係，有效捕捉長距離語境依賴關係，這是傳統RNN或CNN模型難以比擬的優勢 。"
    },
    {
      "id": "3",
      "content": "某企業計畫應用BERT (Bidirectional Encoder Representations from Transformers)模型分析大量顧客意見,以強化客服自動回覆系統。在BERT的預訓練過程中,「遮罩語言模型(Masked Language Model, MLM)」的主要訓練策略為何?",
      "A": "依序遮罩句尾詞語,讓模型從左到右逐步生成完整句子",
      "B": "隨機遮罩部分詞語,並讓模型根據雙向上下文(Bidirectional Context)預測被遮罩的詞",
      "C": "透過對抗訓練(Adversarial Training)生成語意相似的擾動樣本以提升泛化性",
      "D": "以未遮罩的詞為條件,使用解碼器(Decoder)結構重建整句內容",
      "Ans": "B",
      "exp": "遮罩語言模型 (MLM) 是 BERT 的核心預訓練任務之一。它的策略是隨機遮罩輸入序列中的部分詞語（通常是 15%），然後讓模型根據完整的上下文（雙向）來預測這些被遮罩的詞語，從而實現深層次的雙向語境理解 。"
    },
    {
      "id": "4",
      "content": "在詞向量(Word Embedding)訓練方法中,GloVe (Global Vectors for Word Representation)與Word2Vec的主要差異為何?",
      "A": "Word2Vec 以詞頻權重訓練詞向量,而GloVe以隨機初始化向量進行學習",
      "B": "Word2Vec 以全局統計矩陣為基礎,而GloVe採用神經網路進行上下文預測",
      "C": "Word2Vec 為基於預測的模型,而GloVe為基於共現統計的模型",
      "D": "Word2Vec 僅能用於靜態文本語料,而GloVe可應用於即時語料更新",
      "Ans": "C",
      "exp": "Word2Vec 屬於基於預測 (Prediction-based) 的模型（如 Skip-gram 或 CBOW），它透過預測上下文詞或中心詞來學習詞向量。而 GloVe (Global Vectors) 則是基於全局共現統計 (Count-based) 的模型，它結合了全局詞共現矩陣的資訊進行訓練 。"
    },
    {
      "id": "5",
      "content": "某企業以詞頻-逆文件頻率(Term Frequency Inverse Document Frequency, TF-IDF)方法分析顧客意見內容,但發現模型在處理篇幅較長的回饋文本時,無法準確反映關鍵詞的重要性。下列何者為造成此現象的主要原因?",
      "A": "長文本中的詞頻偏高,導致常見詞權重被過度放大",
      "B": "長文本中缺乏明確句子邊界,造成TF-IDF 無法計算詞頻",
      "C": "TF-IDF 無法同時處理多份文件",
      "D": "長文本會改變IDF(Inverse Document Frequency)的計算,使所有詞權重趨於相近",
      "Ans": "A",
      "exp": "TF-IDF 中的 TF (Term Frequency) 部分是計算詞語在單一文件中的出現次數。在長文本中，即使是非關鍵的常見詞也會因為文本長度而有很高的詞頻，導致其 TF 值偏高，進而使整體 TF−IDF 權重被過度放大，無法有效凸顯真正的關鍵詞 。"
    },
    {
      "id": "6",
      "content": "某企業嘗試以N-gram語言模型(N-gram Language Model)建立客服自動回覆系統,但發現模型生成的句子雖在片段上合理,卻缺乏整體語意連貫性。此問題最可能源自N-gram模型的哪一項限制?",
      "A": "N-gram 模型在訓練過程中需要龐大計算量,導致長句無法收斂",
      "B": "N-gram 模型僅根據固定長度的前序詞建立機率估計,難以捕捉長距離依賴關係(Long-range Dependencies)",
      "C": "N-gram 模型缺乏語意嵌入(Semantic Embedding)層,因此無法表徵詞語間的語意相似度",
      "D": "N-gram 模型假設詞與詞之間相互獨立,導致無法建構上下文語意關聯",
      "Ans": "B",
      "exp": "N-gram 模型基於馬可夫假設，即當前詞的出現只依賴於前 N−1 個詞。這種固定長度的依賴性使其在處理長句子時，難以捕捉句子開頭與結尾之間的長距離語境或語意連貫性 。"
    },
    {
      "id": "7",
      "content": "在企業導入的智慧監控系統中,模型以物件偵測(Object Detection)方式自動辨識影像中的人物與車輛。若評估指標採用平均精確率(Mean Average Precision, mAP),其中 IoU (Intersection over Union) 值設定較高時,代表下列哪一項意義?",
      "A": "預測邊界框與真實邊界框的重疊程度越高,模型偵測結果越精準",
      "B": "預測邊界框與真實邊界框的誤差越大,導致mAP數值上升",
      "C": "模型整體精確率(Precision)降低,但召回率(Recall)上升",
      "D": "預測邊界框的評估結果不受真實框大小影響",
      "Ans": "A",
      "exp": "IoU 是用來衡量預測邊界框 (Predicted Bounding Box) 與真實邊界框 (Ground Truth) 之間重疊程度的指標。在 mAP 評估中，若要求 IoU 值設定較高（例如從 0.5 提高到 0.75），則表示只有那些與真實框重疊程度很高的預測框才算作有效的偵測 (True Positive)，這代表模型對物件的定位越精準 。"
    },
    {
      "id": "8",
      "content": "關於 Softmax 與Max-Pooling,下列敘述何者正確?",
      "A": "Softmax 與Max-Pooling 都會將特徵張量壓縮為單一最大值",
      "B": "Max-Pooling會對輸入進行機率分佈的轉換",
      "C": "Softmax 會保留所有輸入資訊,但以比例表示;Max-Pooling 只保留區域最大值",
      "D": "Softmax 主要用於特徵降維,而Max-Pooling 用於分類輸出",
      "Ans": "C",
      "exp": "Softmax 函式將輸入轉換為一個機率分佈，所有輸出的值介於 0 到 1 之間，且總和為 1，它保留了所有輸入資訊並將其比例化 。Max-Pooling 則是一種降採樣操作，它只從一個區域中選取最大值，因此會捨棄該區域中的其他資訊 。"
    },
    {
      "id": "9",
      "content": "某企業在訓練生成式AI模型時,導入資料增強(Data Augmentation)技術以擴充訓練資料,但觀察到模型效能反而下降。下列哪一項最可能的原因與對應改善策略最為正確?",
      "A": "增強樣本未經隨機初始化,導致模型梯度更新不穩定,應重新設計訓練啟動流程",
      "B": "增強後資料的特徵分佈與原始資料不一致,影響模型的泛化能力,應檢查並調整增強策略以維持語意一致性",
      "C": "增強樣本的比例過高,造成模型對特定資料產生偏好,應適度提高增強比例並調整學習率",
      "D": "增強後資料的標註可信度下降,導致訓練訊號偏差,應以半監督學習方式重新校正資料",
      "Ans": "B",
      "exp": "資料增強的目的是在不改變語意或核心特徵的前提下擴大資料集。如果增強後的資料分佈與原始資料不一致，或是增強方式引入了不真實或有偏差的雜訊（例如影像增強後的圖片失真、文本增強後的語意改變），反而會誤導模型學習到錯誤的特徵，從而降低泛化能力和模型效能 。"
    },
    {
      "id": "10",
      "content": "如果希望同時兼顧「精確率(Precision)」和「召回率(Recall)」,下列哪一個指標可以作為綜合評估的標準?",
      "A": "準確率(Accuracy)",
      "B": "均方根誤差(RMSE)",
      "C": "均方誤差(MSE)",
      "D": "F1分數(F1 Score)",
      "Ans": "D",
      "exp": "F1 分數 (F1 Score) 是精確率 (Precision) 和召回率 (Recall) 的調和平均數 (Harmonic Mean)，它提供了一個單一指標來綜合評估模型性能，特別適用於類別不平衡（Imbalanced Class）或需要同時關注兩個指標的場景 。"
    },
    {
      "id": "11",
      "content": "企業資料分析團隊使用DBSCAN (Density-Based Spatial Clustering of Applications with Noise)演算法進行顧客行為分群,並希望模型能自動區分主要群集與雜訊資料。在此演算法中,決定聚類結果的兩個主要超參數為下列何者?",
      "A": "特徵數與學習率",
      "B": "K值與距離 值",
      "C": "鄰域半徑(Epsilon  ϵ)與最小點數(MinPts)",
      "D": "交叉熵(Cross Entropy)與權重初始化",
      "Ans": "C",
      "exp": "DBSCAN 是一種基於密度的聚類演算法，其核心思想是根據點的鄰域密度來劃分群集。決定其聚類結果的兩個關鍵超參數是：鄰域半徑 (ϵ)，用來定義一個點的鄰域範圍；以及最小點數 (MinPts)，用來定義一個核心點所需的最小鄰域點數 。"
    },
    {
      "id": "12",
      "content": "某金融科技公司建立房價預測模型,使用多項特徵(如建坪、房齡、樓層、總價等)進行線性迴歸分析(Linear Regression Analysis)。資料分析師發現多個特徵之間存在高度相關性,導致模型係數不穩定、預測誤差上升。為解決此問題,下列哪一種方法最適合?",
      "A": "繼續保留所有特徵,不進行任何處理",
      "B": "使用主成分分析(PCA)將相關特徵轉換為彼此獨立的主成分",
      "C": "新增更多原始變數以提升模型表現",
      "D": "改用分類模型進行預測",
      "Ans": "B",
      "exp": "特徵間的高度相關性稱為多重共線性 (Multicollinearity)，會導致線性迴歸模型係數的估計不穩定。主成分分析 (PCA) 是一種常用的降維技術，它可以將原始的高度相關特徵，轉換為一組彼此獨立（正交）的主成分，從而消除多重共線性問題 。"
    },
    {
      "id": "13",
      "content": "下列何者為Kubernetes 在AI 模型部署與運行中的核心功能?",
      "A": "自動化管理模型的訓練流程與參數調校",
      "B": "管理與協調模型服務的部署、擴展與運行環境",
      "C": "提供AI模型的資料儲存與版本控管功能",
      "D": "負責深度學習推論的GPU加速運算",
      "Ans": "B",
      "exp": "Kubernetes (K8s) 是一個容器編排 (Container Orchestration) 系統，其核心功能是自動化部署、擴展和管理容器化應用程式（例如 AI 模型服務）的運行環境，確保服務的高可用性與可擴展性 。"
    },
    {
      "id": "14",
      "content": "在調整模型超參數(Hyperparameters)時,若希望避免因過度調整參數而導致過擬合,下列哪一種做法最有效提升模型的泛化能力?",
      "A": "採用交叉驗證(Cross-Validation)於多組參數組合間反覆評估,選擇在驗證資料上表現最穩定的設定",
      "B": "使用早期停止機制(Early Stopping)監控訓練誤差並在收斂前停止訓練,以防模型學習過度",
      "C": "對輸入特徵進行標準化以減少特徵值差異帶來的過擬合風險",
      "D": "提高模型複雜度並使用更多超參數搜尋範圍,以確保模型能充分學習資料特徵",
      "Ans": "A",
      "exp": "交叉驗證 (Cross-Validation) 是一種評估模型性能和選擇超參數的健壯方法。它將資料集分割成多份，反覆用不同組合進行訓練和驗證，從而更可靠地評估模型在未見資料上的表現，有效避免因單一驗證集上的偶然優秀表現（可能導致過度擬合）而做出錯誤的超參數選擇，從而提升模型的泛化能力 。"
    },
    {
      "id": "15",
      "content": "在企業導入的MLOps (Machine Learning Operations)流程中, Model Registry最常用於哪一個階段?",
      "A": "用於設定運算資源與執行環境以確保訓練穩定",
      "B": "用於建立可重複使用的資料與特徵版本",
      "C": "用於集中管理模型版本、訓練紀錄與部署狀態",
      "D": "用於追蹤模型上線後的表現與漂移情況",
      "Ans": "C",
      "exp": "Model Registry (模型註冊中心) 是 MLOps 流程中至關重要的一環。它提供一個集中式的儲存庫，用於管理和追蹤所有訓練完成的 AI 模型的版本、對應的訓練參數/紀錄、以及當前的部署狀態（如測試中、生產中等），確保模型生命週期的可控與可追溯性 。"
    },
    {
      "id": "16",
      "content": "下列哪一種情境中最適合使用「序列到序列(Seq2Seq)」模型?",
      "A": "預測銷售趨勢曲線,輸出未來數值序列",
      "B": "辨識文本中出現的人名、地名與組織名稱等實體資訊",
      "C": "對輸入文本中的關鍵字進行頻率統計與可視化",
      "D": "將輸入文字轉換成語意等價的另一段文字,如自動翻譯或摘要生成",
      "Ans": "D",
      "exp": "序列到序列 (Seq2Seq) 模型架構（通常包含一個編碼器 Encoder 和一個解碼器 Decoder）專門設計用於處理輸入序列到輸出序列的轉換任務。典型的應用包括機器翻譯（將一種語言序列轉換為另一種語言序列）和文本摘要（將長文本序列轉換為短摘要序列） 。"
    },
    {
      "id": "17",
      "content": "在自然語言處理中,檢索增強生成(Retrieval-Augmented Generation, RAG)是一種結合語言模型與向量搜尋的技術,可有效減少模型知識過時與產生幻覺的問題。若要建立一套高效能的RAG系統,下列何者為在「檢索階段」最關鍵的挑戰?",
      "A": "確保檢索到的文件能被完整納入語言模型的上下文視窗(Context Window)中進行生成",
      "B": "選擇使用Faiss或ScaNN等近似最近鄰搜尋函式庫",
      "C": "降低嵌入模型(Embedding Model)在高維空間中的計算成本與記憶體佔用",
      "D": "避免向量檢索結果僅具語意相似但與查詢意圖無實質關聯的情況",
      "Ans": "D",
      "exp": "在 RAG 系統的檢索階段，最關鍵的挑戰是確保檢索到的文件塊 (Chunks) 對於當前查詢是實質相關且有資訊量的。如果僅是表面上的語意相似（例如，都是關於金融的詞彙）但內容無法回答用戶的具體意圖，則會導致語言模型生成無效或「幻覺」的答案 。"
    },
    {
      "id": "18",
      "content": "當Transformer模型發生「注意力分布過於平均(Attention Collapse)」的情形時,導致模型無法有效聚焦於關鍵資訊,下列哪一項策略可有效改善此問題?",
      "A": "提高 Query-Key 點積(Dot Product)的縮放常數",
      "B": "在Softmax前加入高斯雜訊(Gaussian Noise)",
      "C": "使用 ReLU 函數取代 Softmax",
      "D": "對注意力權重施加稀疏化約束(Sparsity Constraint)",
      "Ans": "D",
      "exp": "注意力分佈過於平均 (Attention Collapse) 指的是注意力權重趨於均勻分佈，使得模型無法有效地區分輸入序列中的重要與非重要部分。施加稀疏化約束 (Sparsity Constraint) 是一種直接的方法，它鼓勵注意力權重只集中在少數幾個關鍵的 token 上，從而迫使模型聚焦於關鍵資訊 。"
    },
    {
      "id": "19",
      "content": "某研究團隊正在訓練一個針對低資源語言(如少數民族語言)的語言模型,但該語言僅有約1萬筆語料可用。在訓練過程中出現明顯的過擬合現象,若希望在不新增真實語料的前提下提升模型的泛化能力,採用下列哪一種方法最為適合?",
      "A": "將 Transformer的隱藏層維度擴增至1024,以提升表徵能力",
      "B": "採用反向翻譯(Back-Translation)技術,以生成額外目標語句的偽平行語料(Pseudo-Parallel Corpus)",
      "C": "對詞嵌入矩陣(Embedding Matrix),施加L1正則化以壓縮模型參數",
      "D": "將多語言BERT (mBERT)中所有 Transformer層全部凍結以保留預訓練知識",
      "Ans": "B",
      "exp": "由於真實語料稀少 (1萬筆) 且出現過擬合，最有效的解決方案是擴充資料集。反向翻譯 (Back-Translation) 是一種常用的資料增強技術，尤其適用於低資源語言，它利用現有的（或高資源語言的）翻譯模型來生成偽平行語料 (Pseudo-Parallel Corpus)，從而增加訓練數據量，提升模型的泛化能力 。"
    },
    {
      "id": "20",
      "content": "在使用生成對抗網路(GAN)進行人臉影像生成時,若出現「模式崩潰」(Mode Collapse)現象,下列哪一種方法最常被用來有效解決此問題?",
      "A": "在鑑別器中加入梯度懲罰(Gradient Penalty)以穩定訓練過程",
      "B": "採用 Wasserstein 距離(WGAN損失)替代原始的GAN 損失函數",
      "C": "對生成器輸入的潛在向量加入隨機擾動",
      "D": "使用多尺度鑑別器架構以提高對多樣性的判別能力",
      "Ans": "B",
      "exp": "模式崩潰 (Mode Collapse) 是指 GAN 生成器只學習到產生少數幾種樣本，無法覆蓋真實資料分佈的多樣性。Wasserstein GAN (WGAN) 使用 Wasserstein 距離（又稱 Earth Mover's Distance）作為損失函數，相比原始 GAN 的 Jensen-Shannon 散度，它能提供更平滑的梯度，有助於穩定訓練過程，並被證明能有效緩解模式崩潰問題，促進生成多樣性 。"
    },
    {
      "id": "21",
      "content": "在多模態 AI 模型訓練或推論過程中,遇到某一模態資料缺失(例如僅有影像資料但缺少文本說明),下列哪一種策略最有效維持模型效能?",
      "A": "以零向量或固定向量填充缺失模態輸入",
      "B": "訓練具備模態缺失感知能力的模型,使其適應缺失狀況",
      "C": "利用生成模型(如GAN或自迴歸模型)預測並補全缺失模態資料",
      "D": "直接捨棄缺少模態的樣本,避免干擾訓練或推論",
      "Ans": "B",
      "exp": "在多模態應用中，如果經常遇到某一模態資料缺失 (Missing Modality)，最健壯的解決方案是設計一個模型架構，使其本身就具有模態缺失感知能力 (Modality Missing Awareness)。這通常涉及特殊的融合或注意力機制，允許模型在缺乏特定輸入時，仍能利用現有的模態信息做出有效的預測或推論 。"
    },
    {
      "id": "22",
      "content": "某電商平台開發的顧客流失預測模型在上線數月後,預測準確率明顯下降。專案團隊懷疑顧客行為模式改變,導致模型輸入特徵的分佈與原始訓練資料不同,出現典型的資料漂移(Data Drift)問題。為了偵測並確認資料分佈是否發生變化,下列哪一種作法最合適?",
      "A": "定期重新訓練模型以應對外部變化",
      "B": "提升模型複雜度以捕捉更多資料變異性",
      "C": "增加測試資料量以提高評估準確度",
      "D": "計算輸入特徵分佈間的KL散度(KL Divergence)",
      "Ans": "D",
      "exp": "資料漂移 (Data Drift) 是指輸入資料的統計屬性（分佈）隨時間發生變化。為了偵測和確認分佈變化，最適合的方法是使用統計指標來量化新舊分佈之間的差異。KL 散度 (Kullback-Leibler Divergence) 或 PSI (Population Stability Index) 等指標都是用於衡量兩個機率分佈之間差異的常用方法，能精確地偵測特徵分佈是否發生了顯著偏移 。"
    },
    {
      "id": "23",
      "content": "某大型醫院即將部署一套輔助診斷的AI系統,為降低對臨床流程的衝擊,同時確保風險可控與回饋可收斂,應採取何種『漸進式部署』(Phased Rollout) 策略最為合適?",
      "A": "從單一專科(如放射科)或特定病房開始啟用,逐步擴展至全院",
      "B": "先部署於病例量較高的急診單位,加速收集高頻使用回饋",
      "C": "僅在夜班或離峰時段啟用,避免影響主要臨床工作負載",
      "D": "在使用者界面啟用提示模式,讓全院同步體驗但不影響診斷流程",
      "Ans": "A",
      "exp": "漸進式部署 (Phased Rollout) 的核心原則是控制範圍和風險。在醫療等高風險環境中，最合適的策略是先在單一、限制性較強的範圍內（如特定專科或病房）進行小規模試點，待驗證穩定且收集到有效回饋後，再逐步擴展至整個系統或全院，以最小化對整體臨床流程的衝擊並確保風險可控 。"
    },
    {
      "id": "24",
      "content": "某金融機構的AI風控系統遭受對抗性攻擊,駭客透過對輸入特徵進行微小但惡意的擾動,成功欺騙了模型。為了從根本上解決模型自身對這類攻擊的脆弱性,下列何者並非針對此種攻擊型態的技術手段?",
      "A": "強化資料前處理,用以過濾掉格式不符或數值極端異常的輸入",
      "B": "在模型訓練階段導入對抗樣本訓練,以提升模型對惡意特徵擾動的辨識與防禦能力",
      "C": "於推論後階段使用規則引擎,以確保模型的預測結果不違反既有的業務硬性規定",
      "D": "在模型部署環境中強化網路防火牆,以阻擋來自未授權來源的網路連線",
      "Ans": "D",
      "exp": "對抗性攻擊 (Adversarial Attack) 是針對模型內部數學特性（例如梯度）進行的攻擊，目的是讓模型做出錯誤的預測。選項 A、B、C 都是在資料、模型訓練或推論邏輯層面進行的防禦技術。而選項 D 強化網路防火牆是針對網路層面的攻擊（如 DDoS 或未授權存取），無法解決模型自身對輸入擾動的脆弱性問題，故不是針對此種攻擊型態的技術手段 。"
    },
    {
      "id": "25",
      "content": "某企業部署生成式AI系統協助行銷與內容產出,但近期遭質疑部分生成內容可能涉及著作權侵權。為降低企業在法律層面的潛在責任與風險,下列哪一項策略最能有效預防侵權問題產生?",
      "A": "對生成內容進行語意相似度比對,自動標註可能涉及既有著作的輸出結果,以降低侵權風險",
      "B": "建立訓練資料篩選與授權驗證機制,排除未授權或高風險資料來源",
      "C": "在訓練與微調過程中採用差分隱私技術,避免模型記憶特定受著作權保護的樣本",
      "D": "在模型輸出端嵌入浮水印(Watermarking)或數位指紋(Digital Fingerprint)技術,以確保生成內容可追溯",
      "Ans": "B",
      "exp": "生成式 AI 內容的侵權風險主要來自於訓練資料的來源。若訓練資料中包含未經授權的受著作權保護材料，模型在生成內容時就有可能「記憶」並「重現」這些受保護的內容。因此，從源頭建立訓練資料的篩選與授權驗證機制，排除高風險資料，是最根本且最有效的預防侵權策略 。"
    },
    {
      "id": "26",
      "content": "在房價預測任務中,若發現特徵如「房間數」與「坪數」存在高度多重共線性(Multicollinearity),為降低共線性對模型參數估計的負面影響,應優先選擇下列哪種模型?",
      "A": "不受多重共線性影響的決策樹模型",
      "B": "傳統線性迴歸模型,不含正則化項",
      "C": "支持向量機搭配線性核函數",
      "D": "含L1正則化的LASSO迴歸模型",
      "Ans": "D",
      "exp": "多重共線性會導致傳統線性迴歸模型 (B) 的係數不穩定。LASSO 迴歸 (Least Absolute Shrinkage and Selection Operator) 引入了 L1 正則化項，其特性是能夠將部分不重要的特徵的係數壓縮至零。對於存在多重共線性的特徵，Lasso 會傾向於選擇其中一個特徵，並將其他共線特徵的係數降為零，從而有效解決共線性問題並進行特徵選擇 。"
    },
    {
      "id": "27",
      "content": "某企業需分析半結構化的系統日誌(JSON格式),以提取關鍵的時序特徵供故障預測模型使用。考量日誌結構複雜且包含巢狀欄位(Nested Fields),下列哪一種策略最有效且實務可行?",
      "A": "先將JSON資料扁平化轉成CSV,再對欄位計算統計量(如均值、次數)作為特徵",
      "B": "使用遞歸神經網路(RNN)直接輸入原始JSON字串進行時序特徵抽取",
      "C": "設計遞迴函式展開巢狀欄位,並基於時間窗口(Time Window)進行聚合與特徵萃取",
      "D": "只保留時間戳記欄位,忽略其他巢狀內容以簡化特徵工程",
      "Ans": "C",
      "exp": "處理包含巢狀欄位 (Nested Fields) 的半結構化資料 (如 JSON) 時，標準的做法是利用遞迴函式或結構化解析工具，將所有巢狀欄位展開 (Flatten) 為可供分析的結構。由於是系統日誌且用於故障預測（時序任務），展開後還需結合時間窗口 (Time Window) 進行聚合，以提取例如「過去一小時內某錯誤代碼出現的次數」等時序特徵，這在實務上是最有效且常見的策略 。"
    },
    {
      "id": "28",
      "content": "在一個同時包含連續型特徵與類別型特徵的資料集中,若希望透過適當的特徵工程流程來提升模型整體表現,下列哪一種作法最為合適?",
      "A": "將類別型特徵使用標籤編碼(Label Encoding)轉換後,與連續特徵直接合併進行模型訓練",
      "B": "將連續特徵進行離散化(Discretization)或分桶(Binning)轉為類別型特徵,統一以類別方式處理",
      "C": "對連續特徵做標準化(Standardization),類別特徵採用目標編碼(Target Encoding),並生成交互特徵提升模型表現",
      "D": "只保留連續特徵,忽略類別型變量以簡化模型",
      "Ans": "C",
      "exp": "處理混合資料類型時，應對兩種類型的特徵進行優化處理：連續特徵通常需要標準化 (Standardization) 或歸一化 (Normalization) 以消除量綱影響 。類別特徵則需要編碼，例如目標編碼 (Target Encoding)（使用目標變量的統計量來編碼）或獨熱編碼 (One-Hot Encoding) 。最後，生成交互特徵（如 連續特徵×類別特徵）可以捕捉特徵間的複雜關係，從而提升模型的整體表現 。"
    },
    {
      "id": "29",
      "content": "某AI 開發團隊為提升模型開發效率及品質控制,計畫實施持續整合(Continuous Integration, CI)流程。下列哪一項做法最符合CI 的核心實踐,且能有效減少整合風險?",
      "A": "在主分支(Main Branch)每日固定時間手動合併並執行完整測試流程",
      "B": "每次程式碼提交(Commit)後自動觸發建置、單元測試及靜態程式碼分析",
      "C": "於模型訓練完成後,定期安排開發團隊回顧並合併程式碼",
      "D": "透過自動化部署腳本,將模型在特定時間點批次釋出到測試環境",
      "Ans": "B",
      "exp": "持續整合 (CI) 的核心實踐是頻繁地整合程式碼變更到共享的主分支，並在每次整合時自動化執行建置和各種測試 (如單元測試、靜態分析)。這可以即時發現整合錯誤和程式碼缺陷，從而將整合風險降到最低 。"
    },
    {
      "id": "30",
      "content": "某銀行計劃將AI詐欺偵測模組整合至核心交易系統,主管機關要求全流程必須符合金融監管對「不可否認性(Non-repudiation)」的資訊安全規範,以確保日後能進行法務追蹤與稽核。下列哪一項措施最能確保此要求的落實?",
      "A": "為每筆AI模型推論記錄其輸入與輸出結果的加密雜湊值(Hash),並簽署數位簽章以確保不可竄改性",
      "B": "優化模型效能以降低平均推論延遲至100ms以下,提升使用者體驗",
      "C": "增加主機備援數量,以確保系統在故障時持續可用",
      "D": "將模型推論請求導入負載平衡器,避免單點壅塞導致服務延遲",
      "Ans": "A",
      "exp": "不可否認性 (Non-repudiation) 在資訊安全中，是指確保一個行為或事件（例如 AI 模型的某次推論結果）的發生者或內容無法否認。最有效的技術手段是使用加密雜湊值 (Hash) 和數位簽章 (Digital Signature)。雜湊值確保數據內容不可竄改，數位簽章則提供了行為人（即系統或模型）的身份認證和行為證明，滿足法務追蹤與稽核的要求 。"
    },
    {
      "id": "31",
      "content": "某AI服務系統每次推論請求需約1秒完成,且必須支撐高達10,000次請求每秒(RPS)的流量。為確保系統具備高可用性且能穩定應付流量峰值,下列哪一種架構方案最為合適?",
      "A": "依賴單台超高效能伺服器進行垂直擴展,提升硬體規格",
      "B": "採用容器化部署並水平擴展服務實例,結合自動彈性伸縮機制(Auto Scaling)",
      "C": "限制最大併發連線數,以避免系統過載",
      "D": "增加批次處理大小,一次同時處理上千筆請求",
      "Ans": "B",
      "exp": "系統要求高達 10,000 RPS (Request Per Second) 的極高吞吐量，且單次推論耗時 1 秒，這幾乎不可能透過單台伺服器（垂直擴展）來達成。唯一可行且最適合高可用性和高流量的方案是水平擴展 (Horizontal Scaling)，即部署多個服務實例。結合容器化部署（如 Docker/Kubernetes）與自動彈性伸縮 (Auto Scaling) 機制，可以根據即時流量需求動態地增減服務實例數量，以穩定應付流量峰值並確保高可用性 。"
    },
    {
      "id": "32",
      "content": "某企業已將AI 模型部署於生產環境,為確保系統持續穩定運作,並能提前偵測模型效能可能衰退,技術團隊希望透過監控指標進行預警。下列哪一項監控指標最具預測效力,能提早發現模型效能下滑風險?",
      "A": "系統CPU與記憶體使用率波動幅度",
      "B": "模型推論結果的置信度(Confidence)分佈變化趨勢",
      "C": "API平均回應時間與延遲百分位數變化",
      "D": "輸入特徵與訓練資料分布差異的PSI(Population Stability Index)指數",
      "Ans": "D",
      "exp": "模型效能衰退的兩大主因是資料漂移 (Data Drift) 和概念漂移 (Concept Drift)。PSI (Population Stability Index) 或 KL 散度等指標，是用來量化輸入特徵分佈與訓練資料分佈之間差異的指標。輸入資料分佈的變化（Data Drift）是導致模型效能下降的先兆。因此，監控 PSI 指數可以提早發現潛在的衰退風險，比監控最終的預測結果或系統資源更有預測效力 。"
    },
    {
      "id": "33",
      "content": "企業團隊在使用Word2Vec模型訓練客服文本語料時,若訓練資料量龐大且希望模型能更有效捕捉罕見詞的語意關聯,下列哪一種訓練策略最為適合?",
      "A": "採用 Skip-gram模型,但以隨機初始化權重加快高頻詞的訓練收斂",
      "B": "採用CBOW模型(Continuous Bag of Words Model)並結合TF-IDF 權重以強化低頻詞表示",
      "C": "採用 Skip-gram模型,利用中心詞預測周圍詞語,能更有效學習低頻詞關係",
      "D": "採用CBOW模型(Continuous Bag of Words Model),利用周圍詞預測中心詞,能提升罕見詞的語意穩定度",
      "Ans": "C",
      "exp": "在 Word2Vec 的兩種主要架構中：CBOW (Continuous Bag of Words) 是用上下文詞預測中心詞，它訓練速度快，且對高頻詞的表示效果較好；而 Skip-gram 則是用中心詞預測上下文詞，它通過在更大的上下文窗口中進行預測，對於低頻詞 (罕見詞) 也能產生更豐富的、更好的語意表示 。"
    },
    {
      "id": "34",
      "content": "在自駕車影像辨識系統中,開發團隊希望模型能同時辨識每個像素所屬的物件類別(例如道路、建築、行人),又能區分出同類物件的不同個體(例如多位行人)。此時最適合採用下列哪一項電腦視覺技術?",
      "A": "語義分割(Semantic Segmentation)",
      "B": "物件偵測(Object Detection)",
      "C": "實例分割(Instance Segmentation)",
      "D": "全景分割(Panoptic Segmentation)",
      "Ans": "D",
      "exp": "全景分割 (Panoptic Segmentation) 是一種結合了語義分割 (Semantic Segmentation) 和實例分割 (Instance Segmentation) 的技術 。它要求模型對圖像中的每個像素都進行預測，同時識別出：1) 像素所屬的類別 (如道路、建築，這是「Things」或「Stuff」的語義分割)；2) 屬於同一類別的不同個體 (如行人 A, 行人 B，這是實例分割) 。這完全符合題幹中「同時辨識每個像素所屬的物件類別，又能區分出同類物件的不同個體」的需求 。"
    },
    {
      "id": "35",
      "content": "某媒體公司計畫導入CLIP(Contrastive Language - Image Pre-training)模型,以協助大量影像自動標註與搜尋,並希望在無需新增標訓資料的情況下,僅透過文字提示(Text Prompt)即可識別影像內容。請問此應用情境中,CLIP能夠達成的關鍵技術特性為何?",
      "A": "透過圖文對比式學習(Contrastive Learning)將影像與文字映射至共同嵌入空間(Shared Embedding Space),可直接以語意相似度進行零樣本分類",
      "B": "透過影像增強與特徵擴散降低標訓資料需求",
      "C": "以監督式學習結合多層感知器(Multilayer Perceptron, MLP)進行影像特徵分類",
      "D": "以自迴歸生成模型(Autoregressive Model)逐步生成文字標籤描述影像內容",
      "Ans": "A",
      "exp": "CLIP (Contrastive Language-Image Pre-training) 的核心是利用對比式學習 (Contrastive Learning)，將影像 (Image) 和其對應的文本描述 (Text) 投影到一個共同的嵌入空間 (Shared Embedding Space) 中 。在這個空間中，相似的圖文對 (正樣本) 距離近，不相似的圖文對 (負樣本) 距離遠 。這使得模型可以直接計算輸入影像嵌入向量與任何文字提示嵌入向量之間的語意相似度，從而實現強大的零樣本分類 (Zero-Shot Classification) 能力 。"
    },
    {
      "id": "36",
      "content": "某資料科學團隊在開發預測模型時,針對多種模型設定(如學習率、樹深度、正則化係數等)進行系統化測試,希望找出在驗證資料上表現最穩定的組合。此過程最可能採用下列哪一種方法?",
      "A": "使用交叉驗證(Cross Validation)反覆評估模型以降低過擬合風險",
      "B": "透過網格搜尋(Grid Search)在多組超參數設定中進行系統化搜尋與評估",
      "C": "以隨機搜尋(Random Search)快速探索部分參數空間以提升搜尋效率",
      "D": "採用貝葉斯優化(Bayesian Optimization)根據歷次結果動態調整搜尋方向",
      "Ans": "B",
      "exp": "網格搜尋 (Grid Search) 是一種最基礎、最直觀的超參數優化方法。它要求使用者定義每個超參數的離散值集合，然後模型會系統化地遍歷所有這些超參數組合的笛卡爾積（即網格點），並評估每一組組合的性能，以找出最佳組合 。題幹中的「針對多種模型設定進行系統化測試」與網格搜尋的定義相符 。"
    },
    {
      "id": "37",
      "content": "某公司正在訓練一個大型語音合成模型,開發團隊使用多台GPU進行訓練,但經常出現 GPU 記憶體不足問題。由於模型架構已固定且無法更換硬體,團隊希望在維持模型效能與收斂品質的前提下,下列哪一種方法最有效降低單張 GPU的記憶體壓力?",
      "A": "減少訓練資料量以降低記憶體使用",
      "B": "採用較小的批次大小(Batch Size)並搭配資料分片(Data Sharding)分散訓練負載",
      "C": "增加學習率(Learning Rate)以加快收斂速度",
      "D": "改用測試資料集(Test Set)進行部分訓練以節省空間",
      "Ans": "B",
      "exp": "批次大小 (Batch Size) 是決定 GPU 記憶體使用量的主要因素。降低批次大小可以立竿見影地減少單張 GPU 的記憶體壓力，因為每次運算所需的資料量變少 。同時，搭配資料分片 (Data Sharding)（將訓練資料切分到不同 GPU 上）和適當的學習率調整，可以分散訓練負載，並在不改變模型架構和不更換硬體的前提下，維持模型的效能和收斂品質 。"
    },
    {
      "id": "38",
      "content": "某影像設計團隊在使用Stable Diffusion 生成4K級產品圖時,發現影像邊緣與細節存在顆粒化與模糊現象。若僅能在生成階段進行調整,希望提升畫面清晰度與紋理層次,同時避免過度平滑,下列哪一項作法最適合?",
      "A": "降低取樣步數,以縮短生成時間",
      "B": "增加取樣步數並選擇高品質取樣器,以強化細節還原度",
      "C": "提高CFG(Classifier-Free Guidance)值,使生成結果更具創意與多樣性",
      "D": "改用低解析度輸入以降低計算成本",
      "Ans": "B",
      "exp": "在擴散模型 (Diffusion Model) 的生成階段，取樣步數 (Sampling Steps) 決定了去噪過程的精細程度 。增加取樣步數 (例如從 20 步增加到 50 步) 可以讓去噪過程更完整，從而顯著提高生成影像的細節清晰度和紋理還原度，減少顆粒化或模糊現象 。此外，選擇如 DPM++ 2M Karras 等高品質取樣器 (Sampler) 也有助於細節優化 。"
    },
    {
      "id": "39",
      "content": "某企業的資料科學團隊利用 ARIMA模型(AutoRegressive Integrated Moving Average Model)預測每週產品銷售量。模型建立完成後,分析人員發現預測誤差隨時間呈現週期性波動,且自相關函數(ACF)顯示殘差在多個時滯(Lag)上仍顯著不為零。根據上述現象,最合理的模型診斷結論為何?",
      "A": "模型殘差符合白噪音(White Noise)假設,預測表現穩定",
      "B": "模型殘差雖有輕微異常，但可視為隨機誤差忽略不計",
      "C": "模型存在配適不足（Underfitting）問題，需重新調整 p 或 q 參數以捕捉時間依賴性",
      "D": "殘差特性不影響預測結果，無須進一步修正",
      "Ans": "C",
      "exp": "ARIMA 模型的假設之一是其殘差 (Residuals) 應為白噪音 (White Noise)，即殘差彼此獨立且無規律可循。如果殘差仍呈現週期性波動或自相關函數 (ACF) 顯著不為零，這表明模型未能充分捕捉時間序列中的所有時間依賴性或結構性資訊（例如殘留的自迴歸 AR 或移動平均 MA 關係） 。這是一種典型的配適不足 (Underfitting) 現象，需要重新調整模型的參數 p (AR 項) 或 q (MA 項) (或考慮加入季節性項 SARIMA) 。"
    },
    {
      "id": "40",
      "content": "下列哪一項最正確地描述了 VAE（Variational Autoencoder）、GAN（Generative Adversarial Network）與擴散模型（Diffusion Model）在多模態潛在空間對齊（Latent Alignment）與生成策略上的根本差異？",
      "A": "VAE 透過顯式潛在變數建模實現跨模態對齊，適合捕捉整體語意結構但生成解析度有限；GAN 透過對抗損失（Adversarial Loss）在不同模態間學習分佈映射，生成品質高但穩定性差；擴散模型則以條件化噪聲反推（Conditional Denoising）方式實現高保真跨模態生成，兼具穩定性與多樣性",
      "B": "VAE 與 Diffusion Ｍodel 均屬隱式生成架構，主要依賴對抗式訓練實現跨模態對齊；GAN 則以顯式後驗估計方式提升樣本一致性",
      "C": "VAE 與 GAN 均使用馬爾可夫鏈（Markov Chain）進行跨模態轉換；Diffusion Model 則透過 KL 散度最小化學習語意對應",
      "D": "三者在多模態應用中皆依賴同一潛在表徵空間（Shared Latent Space），僅在解碼器結構不同而已",
      "Ans": "A",
      "exp": "VAE 透過顯式的機率圖模型來建模潛在空間 z，實現潛在空間對齊 。其優點是穩定且能捕捉整體結構，缺點是生成解析度相對受限 。GAN 透過生成器 G 與鑑別器 D 的對抗損失來學習數據分佈，其優點是能生成高解析度圖像，但缺點是訓練穩定性差 。擴散模型則是以條件化去噪的方式，從純噪聲中逐步反推數據，兼具高保真、穩定性與多樣性，是目前多模態生成的主流 。"
    },
    {
      "id": "41",
      "content": "在進行超參數調校（Hyperparameter Tuning）時，若直接在 K-Fold 交叉驗證（Cross-Validation）的資料上同時調整模型參數並評估效能，最可能導致下列哪一種問題？",
      "A": "模型的交叉驗證結果出現過度樂觀偏差（Over-optimistic Bias），因測試摺資料間接參與參數選擇，造成資料洩漏（Data Leakage）",
      "B": "模型會在每一摺（Fold）內反覆調整參數，導致訓練不穩與過度正則化",
      "C": "因交叉驗證資料被重複使用，造成效能方差增大，無法獲得穩定估計",
      "D": "K-Fold 交叉驗證的假設與超參數搜尋相衝突，導致驗證過程失效",
      "Ans": "A",
      "exp": "在超參數調校時，應該使用一個獨立的驗證集 (Validation Set) 來評估性能。如果直接在 K-Fold 交叉驗證的測試摺 (Test Fold) 資料上進行參數選擇和調校，相當於讓測試數據間接參與了模型的優化過程 。這會導致資料洩漏 (Data Leakage)，使得模型對這個數據集（即交叉驗證的結果）的評估過於樂觀，無法真實反映模型在全新未見資料上的泛化能力 。"
    },
    {
      "id": "42",
      "content": "若部署一個深度學習模型至金融風控系統，該模型採用鑑別式架構（如 Transformer Classifier）。然而上線後，模型對新樣本的分類錯誤率顯著上升，經檢查發現，輸入資料分佈已與原訓練集明顯不同。針對此情形，下列哪一種應對策略最為適合？",
      "A": "改用生成對抗網路（GAN）生成新樣本並混入訓練集",
      "B": "改用邏輯迴歸模型（Logistic Regression）以提升穩定性",
      "C": "增加模型容量（Model Capacity），以學習更多樣本差異",
      "D": "使用變分自編碼器（VAE）監控潛在空間分佈，偵測輸入資料偏移",
      "Ans": "D",
      "exp": "模型分類錯誤率上升且輸入資料分佈明顯不同，這是一個典型的資料漂移 (Data Drift) 問題。VAE (Variational Autoencoder) 或其他自編碼器 (Autoencoder) 可用於潛在空間分佈監控 。透過訓練 VAE 重建訓練資料，並監控新輸入資料在 VAE 潛在空間中的分佈，可以偵測到輸入資料是否發生偏移，因為偏移後的資料在潛在空間中會位於低密度區域或遠離原始訓練數據的聚類，從而提前發現漂移 。"
    },
    {
      "id": "43",
      "content": "某金融科技公司欲導入 AI 模型協助客服郵件自動分類（投訴、詢問、表揚）。團隊同時考慮兩種模型設計：方案 A（生成式路徑）：採用 VAE 建構潛在語意空間，再結合下游分類器進行標籤預測；方案 B（鑑別式路徑）：採用 BERT Classifier 直接根據輸入文本進行監督式分類。現有標註資料約 2,000 筆，資料分佈均勻但擴充成本高。若團隊希望公平比較兩種模型的資料利用效率與泛化能力，下列哪一種實驗設計最能突顯兩者的本質差異？",
      "A": "在完整資料集上分別訓練兩者，並比較其分類準確率（Accuracy）與推論時間",
      "B": "在低資源情境（Low-resource Setting）下，逐步減少標註比例（100%、50%、10%），比較其 F1-score",
      "C": "使用 GAN 自動生成文本樣本補足資料，觀察兩模型在資料增強後的精確率（Precision）差異",
      "D": "在相同訓練資料上固定輸入維度，僅調整模型參數量，比較其對過擬合的敏感度",
      "Ans": "B",
      "exp": "VAE (生成式) 和 BERT Classifier (鑑別式) 的一個重要本質差異在於它們對資料量的依賴程度。BERT 屬於強大的鑑別式模型，通常需要較多標註數據才能發揮全部性能。VAE 作為生成式模型，可以透過自監督預訓練更好地學習數據的固有結構 (潛在空間)，因此在低資源情境 (Low-resource Setting) 下，其資料利用效率和泛化能力可能優於或與 BERT 有不同的表現 。透過逐步減少標註比例來比較性能衰減情況，可以最有效地突顯兩者在資料效率上的差異 。"
    },
    {
      "id": "44",
      "content": "某電信公司希望建立一個模型來預測顧客是否即將流失，並進一步模擬不同促銷或服務策略下顧客的行為變化，以生成多樣化的虛擬樣本資料進行 A/B 測試與行銷策略評估。若要同時兼顧預測與資料生成的需求，最適合採用下列哪一種方法？",
      "A": "使用傳統隨機森林（Random Forest）",
      "B": "使用邏輯迴歸（Logistic Regression）模型",
      "C": "使用變分自編碼器（Variational Autoencoder, VAE）或生成對抗網路（Generative Adversarial Network, GAN）",
      "D": "使用強化學習代理（Reinforcement Learning Agent）",
      "Ans": "C",
      "exp": "題目的需求包含兩個核心功能：1) 預測顧客流失（鑑別任務）；2) 生成多樣化的虛擬樣本數據（生成任務）以進行模擬和 A/B 測試 。VAE 和 GAN 都是主流的生成式模型 。它們不僅能學習數據的分佈（用於生成新樣本），也可以透過其潛在空間或鑑別器結構進行下游的分類或預測任務 (如流失預測)，從而同時滿足預測和資料生成的需求 。"
    },
    {
      "id": "45",
      "content": "進行影像分類任務時，研究團隊嘗試利用主成分分析（Principal Component Analysis, PCA）將輸入特徵從 1024 維降至 100 維，並將降維後的資料輸入支持向量機（Support Vector Machine, SVM）模型進行訓練。關於此作法，下列哪一項描述最為合理？",
      "A": "PCA 保留的主成分必然能提升 SVM 的分類準確率",
      "B": "使用原始高維資料通常更能保留資訊，因此 PCA 沒有實際意義",
      "C": "PCA 可讓 SVM 自動適用於非線性（Nonlinear）資料集",
      "D": "降維後可降低訓練時間並減少過擬合（Overfitting）風險",
      "Ans": "D",
      "exp": "PCA 是一種降維技術，將高維特徵 (1024 維) 降至低維特徵 (100 維) 。降維有兩大主要優勢：1) 加速訓練：特徵維度大幅減少，可以顯著縮短模型（如 SVM）的訓練時間 ；2) 防止過擬合：在高維空間中，模型容易過度學習訓練數據的細節，導致過擬合。降維可以去除一些冗餘或雜訊特徵，從而減少過擬合的風險，提升模型的泛化能力 。"
    },
    {
      "id": "46",
      "content": "某企業的 AI 模型已部署於線上服務環境中，用於即時預測顧客流失機率。近期團隊注意到模型預測準確率逐漸下降，但系統運作正常且未出現錯誤訊息。經分析發現，近期輸入資料的分布與模型訓練資料相比出現顯著偏移。若要在 MLOps 流程中主動偵測並預警此類問題，最應採用下列哪項措施？",
      "A": "建立即時的資料漂移（Data Drift）與概念漂移（Concept Drift）監測機制",
      "B": "將模型轉換為量化版本以降低延遲",
      "C": "增加模型超參數調整次數以強化適應性",
      "D": "使用固定隨機種子（Random Seed）確保訓練穩定",
      "Ans": "A",
      "exp": "模型準確率下降，且輸入資料分佈出現顯著偏移，這明確指向資料漂移 (Data Drift) 或概念漂移 (Concept Drift) 問題。在 MLOps 流程中，為了主動偵測並預警此類問題，必須建立專門的監測機制，以即時比較生產環境的輸入數據分佈與原始訓練數據分佈，並在差異超出閾值時發出警告 。"
    },
    {
      "id": "47",
      "content": "某金融科技公司導入多任務學習架構，讓單一 Transformer 模型同時執行 OCR（Optical Character Recognition）後的文檔分類以及命名實體辨識（Named Entity Recognition, NER）任務，以協助自動歸檔與抽取關鍵金融資訊。在部署初期，團隊發現當模型的 NER 準確率（Accuracy）提升時，文檔分類準確率反而下降。若模型架構正確且資料品質良好，下列哪一項最可能是造成此現象的原因？",
      "A": "模型架構無法同時支援文字分類與序列標註任務（Sequence Labeling）",
      "B": "文檔分類任務不需要語意化表徵（Contextualized Representation）",
      "C": "損失函數（Loss Function）未進行權重平衡，導致任務間競爭",
      "D": "所使用的 BERT 模型無法支援多任務輸出頭（Multi-Head Outputs）",
      "Ans": "C",
      "exp": "在多任務學習 (Multi-Task Learning, MTL) 中，模型會同時優化多個任務的損失函數。如果不同的任務（例如 NER 和文檔分類）的損失函數沒有經過適當的權重平衡 (Loss Weighting)，那麼其中一個任務（例如 NER）的損失可能會佔主導地位，導致模型在優化該任務時，犧牲了其他任務（例如文檔分類）的表現，形成任務間的競爭 。"
    },
    {
      "id": "48",
      "content": "某數據工程師使用 DBSCAN 演算法對一份數百萬筆的高維顧客資料進行聚類分析，但發現程式執行速度極慢，甚至出現記憶體不足的情況。若要在不改變演算法核心邏輯的前提下，最有效提升其運算效率的作法為何？",
      "A": "改用以平均連結（Average Linkage）為基礎的階層式群集法（Hierarchical Clustering）",
      "B": "採用高效率的距離索引結構（Distance Index Structure），例如 KD-Tree 或 Ball Tree",
      "C": "將 ϵ（Epsilon）參數調得極小，以減少鄰近點的數量",
      "D": "在資料前處理時增加標準化後的特徵維度數",
      "Ans": "B",
      "exp": "DBSCAN 的主要計算瓶頸在於需要為每個點查找其 ϵ 鄰域內的所有點，這涉及大量的距離計算 。對於數百萬筆的高維數據，直接進行暴力搜尋的效率極低。採用高效率的距離索引結構，例如 KD-Tree (K-Dimensional Tree) 或 Ball Tree，可以極大地加速鄰近點的搜尋過程，從而在不改變 DBSCAN 核心邏輯的前提下，顯著提升運算效率 。"
    },
    {
      "id": "49",
      "content": "某電商平台導入 AI 情感分析模型，用以自動偵測顧客評論中的負面情緒並觸發客服機制。然而，上線後發現模型在面對不同語言或族群書寫風格的評論時表現不一致，例如部分語氣強烈的正面評論被誤判為負面，而禮貌但含批評意圖的評論卻被判為中性。若從技術與資料治理的角度分析，下列哪一項描述不正確？",
      "A": "模型未啟用詞嵌入正規化（Embedding Normalization）可能造成語意距離不穩定，導致預測誤差",
      "B": "訓練語料若偏向特定文化或語氣特徵，可能使模型產生內隱偏誤（Implicit Bias）",
      "C": "模型若訓練資料來源不平衡，容易導致對不同語言或族群風格的情緒判斷不準確",
      "D": "Transformer 架構能捕捉上下文語意，但若訓練資料偏差仍存在，模型仍可能學習到偏誤判斷",
      "Ans": "A",
      "exp": "模型對不同書寫風格表現不一致，這是一個典型的模型偏誤 (Bias) 問題，主要源於訓練數據的偏差或不平衡 。選項 B, C, D 都是合理的解釋。而詞嵌入正規化 (Embedding Normalization) 的主要目的是優化詞向量空間的幾何特性，不是解決由文化/語氣風格差異引起的模型偏誤的根本技術手段，也不是造成此類預測誤差的最主要原因 。"
    },
    {
      "id": "50",
      "content": "某設計師使用公司內部建置的生成式 AI 工具製作行銷素材，並輸入提示語（Prompt）：「請生成一張模特兒手持品牌飲料、背景為海邊夕陽的照片」。系統能正確生成主要主題與場景，但輸出的圖像中，品牌標誌顏色常有誤差，或人物手部姿勢顯得不自然。若從多模態生成模型的技術機制分析，此現象最可能是下列哪一項原因所造成？",
      "A": "擴散式生成模型的去雜訊過程出現隨機梯度漂移，導致影像像素錯誤",
      "B": "提示語過長造成 Transformer 的位置編碼超出上下文限制，導致生成混亂",
      "C": "CLIP 模型中的文字編碼器與影像編碼器在語意嵌入空間未充分對齊，導致跨模態理解偏差",
      "D": "模型未採用對比學習（Contrastive Learning）損失函數，無法建立多模態語意關聯",
      "Ans": "C",
      "exp": "現代文生圖模型（如 Stable Diffusion）的核心通常依賴 CLIP (Contrastive Language-Image Pre-training) 等模型來理解提示語 (Prompt) 的語意。CLIP 透過將文本和圖像映射到共同嵌入空間來實現跨模態理解 。若文字編碼器和影像編碼器在這個嵌入空間中對齊不足 (C)，模型就無法精確地將文本中的細節（如「品牌標誌顏色」或「手部姿勢」）精準映射到圖像中的對應像素，這就是導致細節出錯和不自然的最常見技術原因 。"
    }
  ]
}