{
  "importDate": "2025-12-16",
  "source": "IPAS_02中級_L23機器學習技術與應用_11409.xlsx",
  "questions": [
    {
      "id": "1",
      "content": "在MapReduce 計算框架中,關於 Map 和 Reduce 所負責處理資料的問題,下列敘述何者正確?",
      "A": "Map:一組資料映射成另一組資料;Reduce:統合與歸納資料",
      "B": "Map:地圖式的搜索資料;Reduce:統合與歸納資料",
      "C": "Map:一組資料映射成另一組資料;Reduce:過濾不符合的資料",
      "D": "Map:一組資料映射成另一組資料;Reduce:生成更多的資料",
      "Ans": "A",
      "exp": "Map 階段 (映射)：負責將輸入的資料集分割，並將每個獨立的數據處理成一組鍵值對 (Key-Value Pair) 形式的中間結果。* Reduce 階段 (歸納)：負責將 Map 階段輸出的相同鍵 (Key) 的資料彙整起來，並對其進行聚合、統計或總結 (統合與歸納)，產生最終結果。"
    },
    {
      "id": "2",
      "content": "下列何種卷積神經網路(CNN)是將卷積層加寬而非加深?",
      "A": "R-CNN",
      "B": "Inception",
      "C": "ResNet",
      "D": "VGG19",
      "Ans": "B",
      "exp": "A, C, D 屬於或依賴於加深 (Deepening) 網路結構（例如 ResNet 使用殘差連接，VGG19 使用大量小卷積核堆疊）的演化方向。* B. Inception 網路（如 GoogLeNet）的核心思想是使用 Inception 模組，在同一層中並行使用多個不同尺寸的卷積核和池化操作，然後將它們的輸出拼接 (Concatenate) 起來，從而實現**「加寬 (Widening)」** 網路結構的效果。"
    },
    {
      "id": "3",
      "content": "當模型的訓練誤差(Training Error)低、但測試誤差(TestError)很大時,這通常是在訓練過程中產生下列哪一種情況?",
      "A": "模型的泛化能力強",
      "B": "模型出現過度擬合(Overfitting)",
      "C": "模型出現欠擬合(Underfitting)",
      "D": "訓練資料和測試資料之間沒有相關性",
      "Ans": "B",
      "exp": "訓練誤差低 (Low Training Error)：模型完美地記住了訓練數據的細節。* 測試誤差大 (High Test Error)：模型在未見過的數據上表現差，無法將學習到的知識應用於新情境（即泛化能力差）。* 這種現象的典型表現就是過度擬合 (Overfitting)。"
    },
    {
      "id": "4",
      "content": "下列哪一種指標通常用於評估迴歸模型的效能?",
      "A": "R2",
      "B": "F1-分數",
      "C": "曲線下面積(AUC)",
      "D": "Precision",
      "Ans": "A",
      "exp": "B, C, D (F1-分數、AUC、Precision) 都是用於評估分類 (Classification) 模型的指標。* A. R2 (R-squared, 決定係數) 是最常用的迴歸模型評估指標之一，它衡量模型能解釋的總變異比例，數值越接近 1，模型擬合效果越好。"
    },
    {
      "id": "5",
      "content": "近年來,深度學習研究與應用蓬勃發展,但數據本身可能存在什麼潛在問題?",
      "A": "數據標註品質鮮少被討論,但它卻直接影響模型性能",
      "B": "數據品質是完美可信賴的",
      "C": "大部分情況下,數據不存在類別不平衡問題",
      "D": "數據不需要領域知識的輔助",
      "Ans": "A",
      "exp": "B, C, D 均為不實或過於樂觀的假設。* A. 數據標註 (Data Labeling) 是深度學習訓練的基石。標註品質低會直接導致模型學習到錯誤的模式，嚴重影響模型性能，但其重要性常被低估。"
    },
    {
      "id": "6",
      "content": "在分類任務中,深度學習模型通常搭配哪一種輸出函數?",
      "A": "Tanh",
      "B": "ReLU",
      "C": "Sigmoid 或 Softmax",
      "D": "Dropout",
      "Ans": "C",
      "exp": "A, B (Tanh, ReLU) 通常作為隱藏層的激活函數 (Activation Function)。* D (Dropout) 是一種正則化 (Regularization) 技術。* C. Sigmoid (用於二元分類，輸出 0 到 1 的概率) 和 Softmax (用於多類分類，輸出各類別概率總和為 1) 是分類任務中輸出層最常用的函數。"
    },
    {
      "id": "7",
      "content": "下列哪一種學習任務不適合使用監督式學習方法處理?",
      "A": "客戶信用風險分類",
      "B": "預測未來銷售額",
      "C": "找出資料中的潛在群集",
      "D": "判斷影像是否為貓或狗",
      "Ans": "C",
      "exp": "監督式學習 (Supervised Learning) 適用於目標 (Label) 已知的情況 (A, B, D)。* C. 找出資料中的潛在群集（即分群/聚類）是一個非監督式學習 (Unsupervised Learning) 任務，其特點是訓練數據沒有預先定義的標籤。"
    },
    {
      "id": "8",
      "content": "在神經網路中,前向傳播(Forward Propagation)主要依賴下列哪一種數學操作?",
      "A": "機率積分",
      "B": "矩陣乘法與向量內積",
      "C": "對數變換",
      "D": "條件機率推論",
      "Ans": "B",
      "exp": "前向傳播是指數據從輸入層依序通過各個隱藏層，最終到達輸出層的過程。* 每個神經元接收輸入時，都是將前一層的輸出（向量）與其自身的權重（矩陣）進行線性運算，即矩陣乘法或向量內積，然後再通過激活函數。"
    },
    {
      "id": "9",
      "content": "特徵縮放(Feature Scaling)中・下列何者為標準化(Standardization)的主要作用?",
      "A": "將數據範圍限制在0到1且標準差-1",
      "B": "使數據平均值為0且標準差為1",
      "C": "移除數據中的異常值",
      "D": "增加特徵間的相關性",
      "Ans": "B",
      "exp": "A. 將數據範圍限制在 0 到 1 是最小-最大正規化 (Min-Max Normalization) 的作用。* B. 標準化 (Standardization)：透過 Z-score 轉換，使數據的平均值 (Mean) 變為 0，標準差 (Standard Deviation) 變為 1。"
    },
    {
      "id": "10",
      "content": "關於準確率(Accuracy)的計算方式,下列何者正確?",
      "A": "TP/(TP+FP)",
      "B": "(TP+TN)/(TP+FP+TN+FN)",
      "C": "TN/(TN+FP)",
      "D": "TP/(TP+FN)",
      "Ans": "B",
      "exp": "準確率 (Accuracy) 衡量模型整體預測正確的比例。* TP (True Positive)：真陽性 (正確預測為正)* TN (True Negative)：真陰性 (正確預測為負)* FP (False Positive)：假陽性 (錯誤預測為正)* FN (False Negative)：假陰性 (錯誤預測為負)* Accuracy = 總數正確預測數​=TP+TN+FP+FNTP+TN​"
    },
    {
      "id": "11",
      "content": "關於損失函數(Loss Function)的主要功能,下列何者正確?",
      "A": "記錄模型預測歷史",
      "B": "計算模型結構複雜度",
      "C": "控制模型的學習率",
      "D": "衡量模型預測與真實值之間的誤差",
      "Ans": "D",
      "exp": "損失函數 (Loss Function) 的核心功能是量化模型預測值與真實值之間的差異程度（即誤差），這個誤差值會被用來指導模型在訓練過程中更新權重。"
    },
    {
      "id": "12",
      "content": "關於歐盟《一般資料保護規則(GDPR)》,所謂的被遺忘權(Right to be Forgotten)主要賦予資料主體哪一項權利?",
      "A": "要求平台永久備份其個資以防遺失",
      "B": "在符合條件下請求刪除其個人資料",
      "C": "將個人資料轉換為匿名格式保存",
      "D": "限制企業將資料輸出至境外伺服器",
      "Ans": "B",
      "exp": "歐盟 GDPR 賦予資料主體多項權利，其中被遺忘權 (Right to be Forgotten)（或稱刪除權）的核心是允許個人在符合特定條件時，有權要求資料控制者刪除其個人資料。"
    },
    {
      "id": "13",
      "content": "在進行模型訓練前,若針對資料中不同群體(例如分類標籤)之間樣本數量不平衡的情況進行比例調整,此方法通常屬於下列哪一種技術?",
      "A": "資料重抽樣",
      "B": "特徵選擇",
      "C": "模型正則化",
      "D": "超參數調整",
      "Ans": "A",
      "exp": "類別不平衡 (Class Imbalance) 問題常透過調整樣本比例來解決。* A. 資料重抽樣 (Data Resampling) 包括過採樣 (Oversampling) 少數類樣本或欠採樣 (Undersampling) 多數類樣本，以平衡不同群體間的樣本數量。"
    },
    {
      "id": "14",
      "content": "在優化器中,哪一個方法會自動調整每個參數的學習率,特別適用於稀疏資料?",
      "A": "Momentum",
      "B": "Adagrad",
      "C": "Adam",
      "D": "SGD",
      "Ans": "B",
      "exp": "A, C, D (Momentum, Adam, SGD) 都是優化器，但 B. Adagrad 是第一個提出自動調整每個參數學習率的優化器。* Adagrad 會根據歷史梯度平方和調整學習率，對於不常出現的特徵（稀疏資料），其學習率較高，因此特別適用於處理稀疏資料。"
    },
    {
      "id": "15",
      "content": "某零售公司希望利用顧客的年齡與每月消費金額,預測顧客是否為高價值顧客。提供相關資料 data.csv,包含欄位 Age、Spending、HighValue。請將下列程式碼片段依正確順序排序,以完成模型的建立與預測。",
      "A": "c→a→b→d",
      "B": "a→c→b→d",
      "C": "c→b→a→d",
      "D": "b→a→c→d",
      "Ans": "A",
      "exp": "機器學習流程的正確順序：* c. 資料載入與準備 (Import & Prepare)：讀取數據，定義特徵 X 和標籤 y。* a. 數據集分割 (Split)：將 X 和 y 分割為訓練集和測試集 (X_train, X_test, y_train, y_test)。* b. 模型訓練 (Train)：初始化模型，並使用訓練集進行擬合 (model.fit)。* d. 模型預測 (Predict)：使用訓練好的模型對測試集進行預測 (model.predict)。* 正確順序為 c→a→b→d。"
    }
  ]
}